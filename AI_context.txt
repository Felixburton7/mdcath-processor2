Working Directory: /home/s_felix/mdcath-processor

File Structure:
.
├── AI_context.sh
├── AI_context.txt
├── check_environment.py
├── LICENSE
├── main.py
├── mdcath_processing.log
├── msms_executables
│   ├── 1crn.pdb
│   ├── 1crn.xyzr
│   ├── 1crn.xyzrn
│   ├── atmtypenumbers
│   ├── msms.1
│   ├── msms.html
│   ├── msms_i86_64Linux2_2.6.1.tar.gz
│   ├── msms.x86_64Linux2.2.6.1
│   ├── msms.x86_64Linux2.2.6.1.staticgcc
│   ├── pdb_to_xyzr
│   ├── pdb_to_xyzrn
│   ├── README
│   ├── ReleaseNotes
│   ├── test.pdb
│   └── test.xyzr
├── outputs
│   ├── frames
│   │   ├── replica_0
│   │   │   ├── 320
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 348
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 379
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 413
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   └── 450
│   │   │       ├── 1a02F00_frame.pdb
│   │   │       └── 1a0aA00_frame.pdb
│   │   ├── replica_1
│   │   │   ├── 320
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 348
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 379
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 413
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   └── 450
│   │   │       ├── 1a02F00_frame.pdb
│   │   │       └── 1a0aA00_frame.pdb
│   │   ├── replica_2
│   │   │   ├── 320
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 348
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 379
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 413
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   └── 450
│   │   │       ├── 1a02F00_frame.pdb
│   │   │       └── 1a0aA00_frame.pdb
│   │   ├── replica_3
│   │   │   ├── 320
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 348
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 379
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 413
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   └── 450
│   │   │       ├── 1a02F00_frame.pdb
│   │   │       └── 1a0aA00_frame.pdb
│   │   └── replica_4
│   │       ├── 320
│   │       │   ├── 1a02F00_frame.pdb
│   │       │   └── 1a0aA00_frame.pdb
│   │       ├── 348
│   │       │   ├── 1a02F00_frame.pdb
│   │       │   └── 1a0aA00_frame.pdb
│   │       ├── 379
│   │       │   ├── 1a02F00_frame.pdb
│   │       │   └── 1a0aA00_frame.pdb
│   │       ├── 413
│   │       │   ├── 1a02F00_frame.pdb
│   │       │   └── 1a0aA00_frame.pdb
│   │       └── 450
│   │           ├── 1a02F00_frame.pdb
│   │           └── 1a0aA00_frame.pdb
│   ├── ML_features
│   │   ├── final_dataset_temperature_320.csv
│   │   ├── final_dataset_temperature_348.csv
│   │   ├── final_dataset_temperature_379.csv
│   │   ├── final_dataset_temperature_413.csv
│   │   ├── final_dataset_temperature_450.csv
│   │   └── final_dataset_temperature_average.csv
│   ├── pdbs
│   │   ├── 1a02F00.pdb
│   │   └── 1a0aA00.pdb
│   ├── RMSF
│   │   ├── replica_average
│   │   │   ├── 320
│   │   │   │   └── rmsf_replica_average_temperature320.csv
│   │   │   ├── 348
│   │   │   │   └── rmsf_replica_average_temperature348.csv
│   │   │   ├── 379
│   │   │   │   └── rmsf_replica_average_temperature379.csv
│   │   │   ├── 413
│   │   │   │   └── rmsf_replica_average_temperature413.csv
│   │   │   ├── 450
│   │   │   │   └── rmsf_replica_average_temperature450.csv
│   │   │   └── average
│   │   │       └── rmsf_all_temperatures_all_replicas.csv
│   │   └── replicas
│   │       ├── replica_0
│   │       │   ├── 320
│   │       │   │   └── rmsf_replica0_temperature320.csv
│   │       │   ├── 348
│   │       │   │   └── rmsf_replica0_temperature348.csv
│   │       │   ├── 379
│   │       │   │   └── rmsf_replica0_temperature379.csv
│   │       │   ├── 413
│   │       │   │   └── rmsf_replica0_temperature413.csv
│   │       │   └── 450
│   │       │       └── rmsf_replica0_temperature450.csv
│   │       ├── replica_1
│   │       │   ├── 320
│   │       │   │   └── rmsf_replica1_temperature320.csv
│   │       │   ├── 348
│   │       │   │   └── rmsf_replica1_temperature348.csv
│   │       │   ├── 379
│   │       │   │   └── rmsf_replica1_temperature379.csv
│   │       │   ├── 413
│   │       │   │   └── rmsf_replica1_temperature413.csv
│   │       │   └── 450
│   │       │       └── rmsf_replica1_temperature450.csv
│   │       ├── replica_2
│   │       │   ├── 320
│   │       │   │   └── rmsf_replica2_temperature320.csv
│   │       │   ├── 348
│   │       │   │   └── rmsf_replica2_temperature348.csv
│   │       │   ├── 379
│   │       │   │   └── rmsf_replica2_temperature379.csv
│   │       │   ├── 413
│   │       │   │   └── rmsf_replica2_temperature413.csv
│   │       │   └── 450
│   │       │       └── rmsf_replica2_temperature450.csv
│   │       ├── replica_3
│   │       │   ├── 320
│   │       │   │   └── rmsf_replica3_temperature320.csv
│   │       │   ├── 348
│   │       │   │   └── rmsf_replica3_temperature348.csv
│   │       │   ├── 379
│   │       │   │   └── rmsf_replica3_temperature379.csv
│   │       │   ├── 413
│   │       │   │   └── rmsf_replica3_temperature413.csv
│   │       │   └── 450
│   │       │       └── rmsf_replica3_temperature450.csv
│   │       └── replica_4
│   │           ├── 320
│   │           │   └── rmsf_replica4_temperature320.csv
│   │           ├── 348
│   │           │   └── rmsf_replica4_temperature348.csv
│   │           ├── 379
│   │           │   └── rmsf_replica4_temperature379.csv
│   │           ├── 413
│   │           │   └── rmsf_replica4_temperature413.csv
│   │           └── 450
│   │               └── rmsf_replica4_temperature450.csv
│   ├── visualizations
│   │   ├── amino_acid_rmsf_violin_plot.png
│   │   ├── dssp_rmsf_correlation_plot.png
│   │   ├── feature_correlation_plot.png
│   │   ├── replica_variance_plot.png
│   │   ├── rmsf_histogram.png
│   │   ├── rmsf_violin_plot.png
│   │   ├── temperature_average_summary.png
│   │   └── temperature_summary.png
│   └── voxelized
│       └── mdcath_voxelized.hdf5
├── README.md
├── requirements.txt
├── setup.py
├── setup.sh
├── src
│   ├── mdcath
│   │   ├── config
│   │   │   ├── default_config.yaml
│   │   │   └── __init__.py
│   │   ├── core
│   │   │   ├── data_loader.py
│   │   │   ├── __init__.py
│   │   │   └── __pycache__
│   │   │       ├── data_loader.cpython-39.pyc
│   │   │       └── __init__.cpython-39.pyc
│   │   ├── __init__.py
│   │   ├── processing
│   │   │   ├── core_exterior.py
│   │   │   ├── features.py
│   │   │   ├── __init__.py
│   │   │   ├── pdb.py
│   │   │   ├── __pycache__
│   │   │   │   ├── core_exterior.cpython-39.pyc
│   │   │   │   ├── features.cpython-39.pyc
│   │   │   │   ├── __init__.cpython-39.pyc
│   │   │   │   ├── pdb.cpython-39.pyc
│   │   │   │   ├── rmsf.cpython-39.pyc
│   │   │   │   ├── visualization.cpython-39.pyc
│   │   │   │   └── voxelizer.cpython-39.pyc
│   │   │   ├── rmsf.py
│   │   │   ├── visualization.py
│   │   │   └── voxelizer.py
│   │   └── __pycache__
│   │       └── __init__.cpython-39.pyc
│   └── mdcath.egg-info
│       ├── dependency_links.txt
│       ├── PKG-INFO
│       ├── requires.txt
│       ├── SOURCES.txt
│       └── top_level.txt
└── test_h5_loading.py

85 directories, 151 files

Contents of Relevant Files Below (Ignoring Binary Files):
---------------------------------------------------------
===== FILE: src/mdcath/config/default_config.yaml =====
input:
  mdcath_folder: "/mnt/datasets/MD_CATH/data"  # Path to the mdCATH folder
  domain_ids: ["1a02F00", "1a0aA00"]   # Empty means process default domain (12asA00)

temperatures: [320, 348, 379, 413, 450]
num_replicas: 5  # Number of replicas to process per temperature

output:
  base_dir: "./outputs"

processing:
  frame_selection:
    method: "rmsd"  # Options: regular, rmsd, gyration, random
    num_frames: 1   # Number of frames to extract per domain/temperature
    cluster_method: "kmeans"  # For RMSD-based selection

  pdb_cleaning:
    replace_chain_0_with_A: true
    fix_atom_numbering: true
    correct_unusual_residue_names: true
    add_cryst1_record: true  # Add CRYST1 record for MSMS compatibility
    remove_hydrogens: false  # Whether to remove hydrogen atoms
    remove_solvent_ions: true   # If set to true, skip TIP, HOH, SOD, CLA, chain 'W'
    stop_after_ter: true #Stop cleaning after the first TER (this is only if later you wanted to use solvent ions for any reason)


  ml_feature_extraction:
    min_residues_per_domain: 0
    max_residues_per_domain: 50000
    normalize_features: true
    include_secondary_structure: true
    include_core_exterior: true
    include_dssp: true  # Extract and include per-residue DSSP data

  core_exterior:
    method: "msms"  # Options: msms, biopython, fallback
    msms_executable_dir: "./msms_executables"  # Path to MSMS executables
    ses_threshold: 1.0  # Threshold for classifying residues (Å²)
    sasa_threshold: 20.0  # Threshold for Biopython SASA (Å²)

  voxelization:
    frame_edge_length: 12.0  # Physical size of the voxel grid (Å)
    voxels_per_side: 21  # Number of voxels along each dimension
    atom_encoder: "CNOCBCA"  # Atom types to include (options: CNO, CNOCB, CNOCBCA)
    encode_cb: true  # Whether to include CB atoms
    compression_gzip: true  # Whether to compress the output files
    voxelise_all_states: false  # Whether to voxelize all states in NMR structures
    process_frames: false  # Whether to also voxelize frame directories
    process_temps: [320, 348, 379, 413, 450]  # Temperatures to process for frame voxelization

performance:
  num_cores: 0  # 0 means auto-detect (use max available cores - 2)
  batch_size: 100
  memory_limit_gb: 0  # 0 means no limit
  use_gpu: true  # Whether to use GPU acceleration if available

logging:
  verbose: true
  level: "INFO"
  console_level: "INFO"
  file_level: "DEBUG"
  show_progress_bars: true
===== FILE: src/mdcath/config/__init__.py =====
"""
Configuration handling for mdCATH
"""

===== FILE: src/mdcath/core/data_loader.py =====


#!/usr/bin/env python3
"""
Core functionality for loading and processing H5 data from mdCATH dataset.
"""

import os
import h5py
import logging
import numpy as np
import pandas as pd
from typing import List, Dict, Tuple, Optional, Union, Any
from concurrent.futures import ProcessPoolExecutor, as_completed

class H5DataLoader:
    """
    Class for efficiently loading and extracting data from mdCATH H5 files.
    Uses chunking/streaming to handle large files.
    """

    def __init__(self, h5_path: str, config: Dict[str, Any]):
        """
        Initialize the H5 data loader.

        Args:
            h5_path: Path to H5 file
            config: Configuration dictionary
        """
        self.h5_path = h5_path
        self.config = config
        self.domain_id = os.path.basename(h5_path).replace("mdcath_dataset_", "").replace(".h5", "")
        self._validate_h5()

    def _validate_h5(self) -> bool:
        """
        Validate that the H5 file has the expected structure.
        
        Returns:
            Boolean indicating if the file is valid
        """
        try:
            with h5py.File(self.h5_path, 'r') as f:
                # Check if domain exists
                if self.domain_id not in f:
                    logging.error(f"Domain {self.domain_id} not found in {self.h5_path}")
                    return False
                
                # Check for required metadata fields
                required_metadata = ["resid", "resname"]
                for field in required_metadata:
                    if field not in f[self.domain_id]:
                        logging.error(f"Required metadata field '{field}' not found for domain {self.domain_id}")
                        return False
                
                # Check for required temperature groups
                temps = [str(t) for t in self.config.get("temperatures", [320, 348, 379, 413, 450])]
                num_replicas = self.config.get("num_replicas", 5)
                
                temp_found = False
                for temp in temps:
                    if temp in f[self.domain_id]:
                        temp_found = True
                        # Check for replica groups
                        for r in range(num_replicas):
                            replica = str(r)
                            if replica in f[self.domain_id][temp]:
                                # Check for specific datasets
                                required_datasets = ['rmsf', 'dssp', 'coords']
                                for dataset in required_datasets:
                                    if dataset not in f[self.domain_id][temp][replica]:
                                        logging.warning(f"Dataset {dataset} not found for temperature {temp}, " 
                                                    f"replica {replica} in domain {self.domain_id}")
                            else:
                                logging.warning(f"Replica {replica} not found for temperature {temp} in domain {self.domain_id}")
                    else:
                        logging.warning(f"Temperature {temp} not found for domain {self.domain_id}")
                
                if not temp_found:
                    logging.error(f"No valid temperature groups found for domain {self.domain_id}")
                    return False
                    
                return True
        except Exception as e:
            logging.error(f"Failed to validate H5 file {self.h5_path}: {e}")
            return False

    def extract_rmsf(self, temperature: str, replica: str) -> Optional[pd.DataFrame]:
        """
        Extract RMSF data for a specific temperature and replica.
        RMSF is per-residue, so we build a unique residue-level list
        from the full 'resid'/'resname' arrays (which may be per-atom).
        
        Args:
            temperature: Temperature (e.g., "320")
            replica: Replica (e.g., "0")
        
        Returns:
            DataFrame with columns: [domain_id, resid, resname, rmsf_{temperature}]
            or None if extraction fails
        """
        try:
            with h5py.File(self.h5_path, 'r') as f:
                # Check if temperature and replica exist
                if (temperature not in f[self.domain_id]) or (replica not in f[self.domain_id][temperature]):
                    logging.warning(f"Temperature {temperature} or replica {replica} not found for domain {self.domain_id}")
                    return None
                
                if 'rmsf' not in f[self.domain_id][temperature][replica]:
                    logging.warning(f"RMSF data not found for domain {self.domain_id}, temperature {temperature}, replica {replica}")
                    return None
                
                # RMSF data is typically length = number_of_residues
                rmsf_data = f[self.domain_id][temperature][replica]['rmsf'][:]

                # Extract the full, per-atom arrays
                resids_all = f[self.domain_id]['resid'][:]
                resnames_all = f[self.domain_id]['resname'][:]

                # Convert bytes -> string if needed
                resnames_all = [
                    rn.decode("utf-8") if isinstance(rn, bytes) else str(rn)
                    for rn in resnames_all
                ]

                # Build unique residue-level list
                # Map resid -> resname (the first occurrence of that resid)
                # This ensures one row per residue
                residue_dict = {}
                for i, resid_val in enumerate(resids_all):
                    if resid_val not in residue_dict:
                        residue_dict[resid_val] = resnames_all[i]

                unique_resids = sorted(residue_dict.keys())
                unique_resnames = [residue_dict[rid] for rid in unique_resids]

                # Check dimension mismatch
                if len(unique_resids) != len(rmsf_data):
                    logging.info(
                        f"Dimension mismatch: unique_resids {len(unique_resids)}, "
                        f"rmsf_data {len(rmsf_data)}"
                    )
                    # Attempt to align by length
                    if len(unique_resids) > len(rmsf_data):
                        logging.warning(
                            f"More unique residues ({len(unique_resids)}) than RMSF points ({len(rmsf_data)}) -- truncating residues"
                        )
                        unique_resids = unique_resids[:len(rmsf_data)]
                        unique_resnames = unique_resnames[:len(rmsf_data)]
                    else:
                        logging.warning(
                            f"Fewer unique residues ({len(unique_resids)}) than RMSF points ({len(rmsf_data)}) -- truncating RMSF"
                        )
                        rmsf_data = rmsf_data[:len(unique_resids)]
                    logging.info("Using unique residue-level alignment for RMSF data")

                # Create DataFrame with final 1:1 alignment
                df = pd.DataFrame({
                    'domain_id': self.domain_id,
                    'resid': unique_resids,
                    'resname': unique_resnames,
                    f'rmsf_{temperature}': rmsf_data
                })
                
                return df
        except Exception as e:
            logging.error(f"Failed to extract RMSF data: {e}")
            return None

    def extract_pdb(self) -> Optional[str]:
        """
        Extract PDB data from the H5 file.

        Returns:
            PDB string or None if extraction fails
        """
        try:
            with h5py.File(self.h5_path, 'r') as f:
                pdb_data = f[self.domain_id]['pdb'][()]
                if isinstance(pdb_data, bytes):
                    return pdb_data.decode('utf-8')
                return str(pdb_data)
        except Exception as e:
            logging.error(f"Failed to extract PDB data: {e}")
            return None

    def extract_dssp(self, temperature: str, replica: str, frame: int = -1) -> Optional[pd.DataFrame]:
        """
        Extract DSSP data for a specific temperature, replica, and frame.
        DSSP is per-residue, so we build a unique residue-level list
        from the full 'resid'/'resname' arrays. Then align to DSSP codes.
        
        Args:
            temperature: Temperature (e.g., "320")
            replica: Replica (e.g., "0")
            frame: Frame index (default: -1 for last frame)

        Returns:
            DataFrame [domain_id, resid, resname, dssp] or None if extraction fails
        """
        try:
            with h5py.File(self.h5_path, 'r') as f:
                if (temperature not in f[self.domain_id]) or (replica not in f[self.domain_id][temperature]):
                    logging.warning(f"Temperature {temperature} or replica {replica} not found for domain {self.domain_id}")
                    return None

                if 'dssp' not in f[self.domain_id][temperature][replica]:
                    logging.warning(f"DSSP data not found for domain {self.domain_id}, temperature {temperature}, replica {replica}")
                    return None
                    
                dssp_dataset = f[self.domain_id][temperature][replica]['dssp']

                # Number of frames
                num_frames = dssp_dataset.shape[0] if len(dssp_dataset.shape) > 0 else 0
                if num_frames == 0:
                    logging.warning(f"Empty DSSP dataset for domain {self.domain_id}, temperature {temperature}, replica {replica}")
                    return None

                # Convert negative frame index
                if frame < 0:
                    frame = num_frames + frame
                if frame < 0 or frame >= num_frames:
                    logging.warning(f"Frame index {frame} out of bounds (0-{num_frames-1}) for {self.domain_id}")
                    frame = max(0, min(frame, num_frames-1))  # clamp

                dssp_data = dssp_dataset[frame]

                # Full, per-atom arrays
                resids_all = f[self.domain_id]['resid'][:]
                resnames_all = f[self.domain_id]['resname'][:]
                resnames_all = [
                    rn.decode("utf-8") if isinstance(rn, bytes) else str(rn)
                    for rn in resnames_all
                ]

                # Build unique residue-level list
                residue_dict = {}
                for i, resid_val in enumerate(resids_all):
                    if resid_val not in residue_dict:
                        residue_dict[resid_val] = resnames_all[i]

                unique_resids = sorted(residue_dict.keys())
                unique_resnames = [residue_dict[rid] for rid in unique_resids]

                # DSSP codes might already be length = # of residues
                dssp_codes = [
                    c.decode("utf-8") if isinstance(c, bytes) else str(c)
                    for c in dssp_data
                ]

                if len(unique_resids) != len(dssp_codes):
                    logging.info(
                        f"Dimension mismatch in DSSP: unique_resids {len(unique_resids)}, dssp_codes {len(dssp_codes)}"
                    )
                    if len(unique_resids) > len(dssp_codes):
                        logging.warning(
                            f"More unique residues ({len(unique_resids)}) than DSSP codes ({len(dssp_codes)}) -- truncating residues"
                        )
                        unique_resids = unique_resids[:len(dssp_codes)]
                        unique_resnames = unique_resnames[:len(dssp_codes)]
                    else:
                        logging.warning(
                            f"Fewer unique residues ({len(unique_resids)}) than DSSP codes ({len(dssp_codes)}) -- truncating DSSP codes"
                        )
                        dssp_codes = dssp_codes[:len(unique_resids)]
                    logging.info("Using unique residue-level alignment for DSSP data")

                # Create final DataFrame
                df = pd.DataFrame({
                    'domain_id': self.domain_id,
                    'resid': unique_resids,
                    'resname': unique_resnames,
                    'dssp': dssp_codes
                })

                return df

        except Exception as e:
            logging.error(f"Failed to extract DSSP data: {e}")
            return None

    def extract_coordinates(self, temperature: str, replica: str, frame: int = -1) -> Optional[Tuple[np.ndarray, List[int], List[str]]]:
        """
        Extract coordinate data for a specific temperature, replica, and frame.

        Args:
            temperature: Temperature (e.g., "320")
            replica: Replica (e.g., "0")
            frame: Frame index (default: -1 for last frame)

        Returns:
            Tuple of (coords, resids, resnames) where coords shape is (n_atoms, 3),
            or None if extraction fails.
        """
        try:
            with h5py.File(self.h5_path, 'r') as f:
                if (temperature not in f[self.domain_id]) or (replica not in f[self.domain_id][temperature]):
                    logging.warning(f"Temperature {temperature} or replica {replica} not found for domain {self.domain_id}")
                    return None

                if 'coords' not in f[self.domain_id][temperature][replica]:
                    logging.warning(f"Coordinate data not found for domain {self.domain_id}, temperature {temperature}, replica {replica}")
                    return None

                coords_dataset = f[self.domain_id][temperature][replica]['coords']
                num_frames = coords_dataset.shape[0] if coords_dataset.ndim > 0 else 0
                if num_frames == 0:
                    logging.warning(f"Empty coords dataset for domain {self.domain_id}, temperature {temperature}, replica {replica}")
                    return None

                # Convert negative frame index
                if frame < 0:
                    frame = num_frames + frame
                if frame < 0 or frame >= num_frames:
                    logging.warning(f"Frame index {frame} out of bounds (0-{num_frames-1}) for domain {self.domain_id}")
                    frame = max(0, min(frame, num_frames - 1))

                coords = coords_dataset[frame]  # shape (n_atoms, 3)
                if coords.ndim != 2 or coords.shape[1] != 3:
                    logging.error(f"Unexpected coordinate shape: {coords.shape} for domain {self.domain_id}")
                    return None

                resids_all = f[self.domain_id]['resid'][:].tolist()
                resnames_all = f[self.domain_id]['resname'][:]
                resnames_all = [
                    rn.decode("utf-8") if isinstance(rn, bytes) else str(rn)
                    for rn in resnames_all
                ]

                # Check shape alignment
                if len(resids_all) != coords.shape[0]:
                    logging.warning(
                        f"Mismatch between residue IDs ({len(resids_all)}) and coords ({coords.shape[0]})"
                    )
                    min_size = min(len(resids_all), coords.shape[0])
                    resids_all = resids_all[:min_size]
                    resnames_all = resnames_all[:min_size]
                    coords = coords[:min_size]

                return coords, resids_all, resnames_all

        except Exception as e:
            logging.error(f"Failed to extract coordinate data: {e}")
            import traceback
            logging.error(traceback.format_exc())
            return None


def process_domains(domain_ids: List[str], data_dir: str, config: Dict[str, Any],
                    num_cores: int = 1) -> Dict[str, Any]:
    """
    Process multiple domains in parallel.
    """
    from concurrent.futures import ProcessPoolExecutor, as_completed

    max_cores = os.cpu_count() - 2 if os.cpu_count() > 2 else 1
    n_cores = min(num_cores if num_cores > 0 else max_cores, max_cores)

    results = {}
    with ProcessPoolExecutor(max_workers=n_cores) as executor:
        future_to_domain = {}
        for domain_id in domain_ids:
            h5_path = os.path.join(data_dir, f"mdcath_dataset_{domain_id}.h5")
            if not os.path.exists(h5_path):
                logging.warning(f"H5 file not found for domain {domain_id}")
                continue

            future = executor.submit(_process_single_domain, h5_path, config)
            future_to_domain[future] = domain_id

        for future in as_completed(future_to_domain):
            domain_id = future_to_domain[future]
            try:
                result = future.result()
                results[domain_id] = result
            except Exception as e:
                logging.error(f"Error processing domain {domain_id}: {e}")
                results[domain_id] = {"success": False, "error": str(e)}

    return results

def _process_single_domain(h5_path: str, config: Dict[str, Any]) -> Dict[str, Any]:
    """
    Process a single domain (helper function for parallel processing).
    """
    loader = H5DataLoader(h5_path, config)
    domain_id = loader.domain_id

    results = {"domain_id": domain_id, "success": False}

    # Extract RMSF data
    temps = [str(t) for t in config.get("temperatures", [320, 348, 379, 413, 450])]
    num_replicas = config.get("num_replicas", 5)

    rmsf_data = {}
    for temp in temps:
        rmsf_data[temp] = {}
        for r in range(num_replicas):
            replica = str(r)
            df_rmsf = loader.extract_rmsf(temp, replica)
            if df_rmsf is not None:
                rmsf_data[temp][replica] = df_rmsf
    results["rmsf_data"] = rmsf_data

    # Extract PDB data
    pdb_str = loader.extract_pdb()
    if pdb_str:
        results["pdb_data"] = pdb_str

    # Extract DSSP data
    dssp_data = {}
    for temp in temps:
        dssp_data[temp] = {}
        for r in range(num_replicas):
            replica = str(r)
            df_dssp = loader.extract_dssp(temp, replica)
            if df_dssp is not None:
                dssp_data[temp][replica] = df_dssp
    results["dssp_data"] = dssp_data

    results["success"] = True
    return results

===== FILE: src/mdcath/core/__init__.py =====
"""
Core data loading and processing functions
"""

===== FILE: src/mdcath/processing/core_exterior.py =====
#!/usr/bin/env python3
"""
Processing module for core/exterior classification.
"""

import os
import logging
import subprocess
import tempfile
import pandas as pd
import numpy as np
import Bio
import shutil
from Bio.PDB import PDBParser, DSSP, ShrakeRupley
from typing import Dict, Any, Optional, List, Tuple


def compute_core_exterior(pdb_file: str, config: Dict[str, Any]) -> Optional[pd.DataFrame]:
    """
    Classify residues as 'core' or 'exterior' based on solvent accessibility.

    Args:
        pdb_file: Path to the cleaned PDB file
        config: Configuration dictionary

    Returns:
        DataFrame with columns 'resid' and 'core_exterior' or None if classification fails
    """
    method = config.get("core_exterior", {}).get("method", "msms")

    if method == "msms":
        return compute_core_exterior_msms(pdb_file, config)
    else:
        return compute_core_exterior_biopython(pdb_file, config)

def compute_core_exterior_msms(pdb_file: str, config: Dict[str, Any]) -> Optional[pd.DataFrame]:
    """
    Use MSMS to classify residues as 'core' or 'exterior'.

    Args:
        pdb_file: Path to the cleaned PDB file
        config: Configuration dictionary

    Returns:
        DataFrame with columns 'resid' and 'core_exterior' or None if MSMS fails
    """
    msms_dir = config.get("core_exterior", {}).get("msms_executable_dir", "./msms_executables")
    # Convert to absolute path
    msms_dir = os.path.abspath(msms_dir)
    ses_threshold = config.get("core_exterior", {}).get("ses_threshold", 1.0)
    protein_name = os.path.basename(pdb_file).split('.')[0]

    try:
        # Create temporary directory for MSMS files
        with tempfile.TemporaryDirectory() as tmp_dir:
            # Paths to MSMS executables and output files
            pdb2xyzr_exe = os.path.join(msms_dir, "pdb_to_xyzr")
            msms_exe = os.path.join(msms_dir, "msms.x86_64Linux2.2.6.1")
            xyzr_file = os.path.join(tmp_dir, f"{protein_name}.xyzr")
            area_base = os.path.join(tmp_dir, f"{protein_name}")
            area_file = f"{area_base}.area"

            # Ensure executables have proper permissions
            try:
                os.chmod(pdb2xyzr_exe, 0o755)  # rwxr-xr-x
                os.chmod(msms_exe, 0o755)      # rwxr-xr-x
            except Exception as e:
                logging.warning(f"Failed to set executable permissions: {e}")

            # Check MSMS executables
            if not os.path.exists(pdb2xyzr_exe) or not os.path.exists(msms_exe):
                logging.warning(f"MSMS executables not found in {msms_dir}, falling back to Biopython")
                return compute_core_exterior_biopython(pdb_file, config)

            # Absolute path for input PDB
            abs_pdb_file = os.path.abspath(pdb_file)
            if not os.path.exists(abs_pdb_file):
                logging.warning(f"PDB file not found: {abs_pdb_file}")
                return compute_core_exterior_biopython(pdb_file, config)

            # Run pdb_to_xyzr with bash shell explicitly
            cmd_xyzr = f"bash {pdb2xyzr_exe} {abs_pdb_file} > {xyzr_file}"
            logging.info(f"Running command: {cmd_xyzr}")
            result = subprocess.run(cmd_xyzr, shell=True, check=False,
                                   stdout=subprocess.PIPE, stderr=subprocess.PIPE)

            if result.returncode != 0 or not os.path.exists(xyzr_file) or os.path.getsize(xyzr_file) == 0:
                logging.warning(f"pdb_to_xyzr failed: {result.stderr.decode()}, falling back to Biopython")
                return compute_core_exterior_biopython(pdb_file, config)

            # Run MSMS with bash shell explicitly
            cmd_msms = f"bash {msms_exe} -if {xyzr_file} -af {area_base}"
            logging.info(f"Running command: {cmd_msms}")
            result = subprocess.run(cmd_msms, shell=True, check=False,
                                   stdout=subprocess.PIPE, stderr=subprocess.PIPE)

            if result.returncode != 0 or not os.path.exists(area_file):
                logging.warning(f"MSMS failed: {result.stderr.decode()}, falling back to Biopython")
                return compute_core_exterior_biopython(pdb_file, config)

            # Rest of the function unchanged...
            # Parse atom-level PDB data
            per_atom_df = parse_pdb_atoms(pdb_file)
            if per_atom_df.empty:
                logging.warning(f"Failed to parse atoms from PDB, falling back to Biopython")
                return compute_core_exterior_biopython(pdb_file, config)

            # Parse MSMS area file
            area_df = parse_area_file(area_file)
            if area_df.empty:
                logging.warning(f"Failed to parse area file, falling back to Biopython")
                return compute_core_exterior_biopython(pdb_file, config)

            # Combine atom data with MSMS results
            if len(area_df) != len(per_atom_df):
                logging.warning(f"Atom count mismatch: {len(area_df)} vs {len(per_atom_df)}, falling back to Biopython")
                return compute_core_exterior_biopython(pdb_file, config)

            # Merge data
            per_atom_df = pd.concat([per_atom_df.reset_index(drop=True),
                                    area_df.reset_index(drop=True)], axis=1)

            # Calculate mean SES per residue
            mean_ses_per_res = per_atom_df.groupby("resid")["SES"].mean()

            # Classify residues as core or exterior
            exterior_residues = mean_ses_per_res[mean_ses_per_res > ses_threshold].index
            resids = mean_ses_per_res.index.tolist()
            core_exterior = ["exterior" if r in exterior_residues else "core" for r in resids]

            # Create final dataframe
            result_df = pd.DataFrame({
                "resid": resids,
                "core_exterior": core_exterior
            })

            return result_df
    except Exception as e:
        logging.warning(f"MSMS processing failed: {e}, falling back to Biopython")
        return compute_core_exterior_biopython(pdb_file, config)
    

def compute_core_exterior_biopython(pdb_file: str, config: Dict[str, Any]) -> pd.DataFrame:
    """
    Use Biopython's SASA calculation to classify residues as 'core' or 'exterior'.

    Args:
        pdb_file: Path to the cleaned PDB file
        config: Configuration dictionary

    Returns:
        DataFrame with columns 'resid' and 'core_exterior'
    """
    try:
        from Bio.PDB import PDBParser, Selection
        from Bio.PDB.SASA import ShrakeRupley

        # Set SASA threshold
        sasa_threshold = config.get("core_exterior", {}).get("sasa_threshold", 20.0)

        # Parse PDB - ensure CRYST1 record first
        try:
            # Fix PDB file to ensure proper CRYST1 record
            corrected_lines = []
            with open(pdb_file, 'r') as f:
                lines = f.readlines()
            
            has_cryst1 = False
            for line in lines:
                if line.startswith("CRYST1"):
                    has_cryst1 = True
                    corrected_lines.append("CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1\n")
                else:
                    corrected_lines.append(line)
            
            if not has_cryst1:
                corrected_lines.insert(0, "CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1\n")
            
            # Write to temporary file
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdb", mode="w") as tmp:
                tmp_pdb = tmp.name
                tmp.writelines(corrected_lines)
            
            parser = PDBParser(QUIET=True)
            structure = parser.get_structure("protein", tmp_pdb)
            model = structure[0]
        
        except Exception as e:
            logging.warning(f"Failed to fix CRYST1 record: {e}")
            parser = PDBParser(QUIET=True)
            structure = parser.get_structure("protein", pdb_file)
            model = structure[0]
        
        # Try DSSP first for better solvent accessibility calculation
        try:
            # Get the location of the DSSP executable
            dssp_executable = shutil.which("dssp") or shutil.which("mkdssp")
            if dssp_executable:
                logging.info(f"Using DSSP executable: {dssp_executable}")
                
                # Write fixed PDB to temporary file
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdb", mode="w") as tmp:
                    tmp_pdb = tmp.name
                    
                    # Add CRYST1 record if needed
                    with open(pdb_file, 'r') as f:
                        content = f.readlines()
                    
                    has_cryst1 = False
                    for i, line in enumerate(content):
                        if line.startswith("CRYST1"):
                            has_cryst1 = True
                            content[i] = "CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1\n"
                            break
                    
                    if not has_cryst1:
                        content.insert(0, "CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1\n")
                    
                    tmp.writelines(content)
                
                # Run DSSP on fixed PDB
                from Bio.PDB import DSSP
                dssp = DSSP(model, tmp_pdb, dssp=dssp_executable)
                
                # Extract results - DSSP gives accessibility values directly
                results = []
                for chain in model:
                    for residue in chain:
                        if residue.id[0] == " ":  # Standard residue
                            resid = residue.id[1]
                            try:
                                # DSSP key is (chain_id, residue_id)
                                key = (chain.id, (' ', residue.id[1], ' '))
                                if key in dssp:
                                    # Get relative solvent accessibility
                                    rel_acc = dssp[key][3]
                                    # A value > 0.2 (20%) is generally considered accessible
                                    core_exterior = "exterior" if rel_acc > 0.2 else "core"
                                    results.append({
                                        "resid": resid, 
                                        "core_exterior": core_exterior,
                                        "relative_accessibility": rel_acc
                                    })
                                else:
                                    # If residue not found in DSSP, use default
                                    results.append({
                                        "resid": resid, 
                                        "core_exterior": "core",
                                        "relative_accessibility": 0.0
                                    })
                            except Exception as e:
                                logging.warning(f"Error processing DSSP for residue {resid}: {e}")
                                results.append({
                                    "resid": resid, 
                                    "core_exterior": "core",
                                    "relative_accessibility": 0.0
                                })
                
                # Clean up temp file
                if os.path.exists(tmp_pdb):
                    os.remove(tmp_pdb)
                
                if results:
                    logging.info("Successfully used DSSP for core/exterior classification")
                    return pd.DataFrame(results)
            
            # If DSSP fails or no results, fall back to ShrakeRupley
            logging.info("DSSP failed or not available, falling back to ShrakeRupley SASA")
        
        except Exception as e:
            logging.warning(f"DSSP calculation failed: {e}, falling back to ShrakeRupley")
        
        # Fall back to ShrakeRupley SASA calculation
        sr = ShrakeRupley()
        sr.compute(model, level="R")  # Compute at residue level

        # Extract results
        results = []
        for chain in model:
            for residue in chain:
                if residue.id[0] == " ":  # Standard residue
                    resid = residue.id[1]
                    sasa = residue.sasa if hasattr(residue, 'sasa') else 0.0
                    # Normalize SASA to get approximation of relative accessibility
                    # Assuming max SASA is around 100 Å²
                    rel_acc = min(1.0, sasa / 100.0)
                    core_exterior = "exterior" if sasa > sasa_threshold else "core"
                    results.append({
                        "resid": resid, 
                        "core_exterior": core_exterior,
                        "relative_accessibility": rel_acc
                    })

        return pd.DataFrame(results)
    except Exception as e:
        logging.error(f"Biopython SASA calculation failed: {e}")
        import traceback
        logging.error(traceback.format_exc())
        return fallback_core_exterior(pdb_file)
    
def fallback_core_exterior(pdb_file: str) -> pd.DataFrame:
    """
    Fallback method to classify residues when other methods fail.
    Classifies outer 1/3 of residues as exterior, inner 2/3 as core.

    Args:
        pdb_file: Path to the cleaned PDB file

    Returns:
        DataFrame with columns 'resid' and 'core_exterior'
    """
    try:
        # Verify file exists and use absolute path
        abs_pdb_file = os.path.abspath(pdb_file)
        if not os.path.exists(abs_pdb_file):
            logging.error(f"PDB file not found: {abs_pdb_file}")
            # Create dummy data when PDB file is missing
            return pd.DataFrame({
                "resid": list(range(1, 21)),  # Create 20 dummy residues
                "core_exterior": ["core"] * 13 + ["exterior"] * 7,  # 2/3 core, 1/3 exterior
                "relative_accessibility": [0.1] * 13 + [0.7] * 7  # Low for core, high for exterior
            })

        # Parse PDB to get residue information
        residue_df = parse_pdb_residues(pdb_file)
        if residue_df.empty:
            # Create empty DataFrame with required columns
            return pd.DataFrame({
                "resid": list(range(1, 21)),
                "core_exterior": ["core"] * 13 + ["exterior"] * 7,
                "relative_accessibility": [0.1] * 13 + [0.7] * 7
            })

        # Sort by residue ID
        residue_df = residue_df.sort_values("resid")

        # Simple classification: outer 1/3 of residues as exterior, inner 2/3 as core
        total_residues = len(residue_df)
        boundary = int(total_residues * 2/3)

        residue_df["core_exterior"] = ["core"] * total_residues
        residue_df.loc[boundary:, "core_exterior"] = "exterior"
        
        # Add relative accessibility values (0-1 scale)
        residue_df["relative_accessibility"] = 0.1  # Default for core
        residue_df.loc[boundary:, "relative_accessibility"] = 0.7  # Higher for exterior

        return residue_df[["resid", "core_exterior", "relative_accessibility"]]
    except Exception as e:
        logging.error(f"Fallback classification failed: {e}")
        return pd.DataFrame({
            "resid": list(range(1, 21)),
            "core_exterior": ["core"] * 13 + ["exterior"] * 7,
            "relative_accessibility": [0.1] * 13 + [0.7] * 7
        })
        
        
def parse_pdb_residues(pdb_file: str) -> pd.DataFrame:
    """
    Parse a PDB file to extract residue-level information.

    Args:
        pdb_file: Path to the PDB file

    Returns:
        DataFrame with residue information
    """
    try:
        from Bio.PDB import PDBParser

        parser = PDBParser(QUIET=True)
        structure = parser.get_structure("protein", pdb_file)

        records = []
        for model in structure:
            for chain in model:
                chain_id = chain.id
                for residue in chain:
                    if residue.id[0] == " ":  # Standard residue
                        records.append({
                            "resid": residue.id[1],
                            "resname": residue.get_resname(),
                            "chain": chain_id
                        })

        return pd.DataFrame(records)
    except Exception as e:
        logging.error(f"Failed to parse PDB residues: {e}")
        return pd.DataFrame()

def parse_pdb_atoms(pdb_file: str) -> pd.DataFrame:
    """
    Parse a PDB file to extract atom-level information.

    Args:
        pdb_file: Path to the PDB file

    Returns:
        DataFrame with atom information
    """
    try:
        from Bio.PDB import PDBParser

        parser = PDBParser(QUIET=True)
        structure = parser.get_structure("protein", pdb_file)

        records = []
        atom_idx = 0
        for model in structure:
            for chain in model:
                for residue in chain:
                    if residue.id[0] == " ":  # Standard residue
                        res_id = residue.id[1]
                        res_name = residue.get_resname()
                        for atom in residue:
                            atom_idx += 1
                            records.append({
                                "atom_idx": atom_idx,
                                "resid": res_id,
                                "resname": res_name,
                                "atom_name": atom.get_name()
                            })

        return pd.DataFrame(records)
    except Exception as e:
        logging.error(f"Failed to parse PDB atoms: {e}")
        return pd.DataFrame()

def parse_area_file(area_file: str) -> pd.DataFrame:
    """
    Parse an MSMS .area file to extract SES values per atom.

    Args:
        area_file: Path to the MSMS .area file

    Returns:
        DataFrame with SES values
    """
    try:
        atom_idx = []
        ses = []

        with open(area_file, "r") as f:
            for line in f:
                if "Atom" in line or not line.strip():
                    continue

                cols = line.split()
                if len(cols) >= 2:
                    atom_idx.append(int(cols[0]))
                    ses.append(float(cols[1]))

        return pd.DataFrame({"atom_idx": atom_idx, "SES": ses})
    except Exception as e:
        logging.error(f"Failed to parse area file: {e}")
        return pd.DataFrame()

def run_dssp_analysis(pdb_file: str) -> pd.DataFrame:
    """
    Run DSSP using a temporary PDB file with correct CRYST1 record,
    then parse the resulting DSSP object.
    
    Args:
        pdb_file: Path to the PDB file
        
    Returns:
        DataFrame with columns: resid, chain, secondary_structure, relative_accessibility
    """
    logging.info(f"Running DSSP on {pdb_file}")
    
    # First, verify the PDB file exists
    abs_pdb_file = os.path.abspath(pdb_file)
    if not os.path.exists(abs_pdb_file):
        logging.error(f"PDB file not found: {abs_pdb_file}")
        return use_fallback_dssp(pdb_file)
    
    try:
        # Create a properly formatted CRYST1 record
        corrected_lines = []
        
        # Read original PDB file
        with open(abs_pdb_file, 'r') as f:
            lines = f.readlines()
        
        # Check if CRYST1 record exists and is properly formatted
        has_cryst1 = False
        for i, line in enumerate(lines):
            if line.startswith("CRYST1"):
                has_cryst1 = True
                # Replace with properly formatted CRYST1 record
                corrected_lines.append("CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1\n")
            else:
                corrected_lines.append(line)
        
        # Add CRYST1 if missing
        if not has_cryst1:
            corrected_lines.insert(0, "CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1\n")
        
        # Write corrected PDB to temporary file
        tmp_pdb = None
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdb", mode="w") as tmp_file:
                tmp_pdb = tmp_file.name
                tmp_file.writelines(corrected_lines)
            
            # Run DSSP on corrected file
            from Bio.PDB import PDBParser, DSSP
            parser = PDBParser(QUIET=True)
            structure = parser.get_structure("protein", tmp_pdb)
            model = structure[0]
            
            # Try different DSSP executables
            dssp_found = False
            for dssp_exec in ["dssp", "mkdssp"]:
                dssp_path = shutil.which(dssp_exec)
                if dssp_path:
                    try:
                        logging.info(f"Trying DSSP executable: {dssp_path}")
                        dssp = DSSP(model, tmp_pdb, dssp=dssp_path)
                        dssp_found = True
                        break
                    except Exception as e:
                        logging.warning(f"Failed with {dssp_exec}: {e}")
            
            if not dssp_found:
                logging.warning("No DSSP executable found or all failed")
                return use_fallback_dssp(pdb_file)
            
            # Extract DSSP results
            records = []
            for key in dssp.keys():
                chain_id = key[0]
                resid = key[1][1]  # residue number
                dssp_tuple = dssp[key]
                
                # Extract secondary structure and relative accessibility
                ss_code = dssp_tuple[2]  # Secondary structure code
                rel_acc = dssp_tuple[3]  # Relative accessibility
                
                # Ensure secondary structure is never empty
                if not ss_code or ss_code == ' ' or ss_code == '-':
                    ss_code = 'C'  # Default to coil
                
                records.append({
                    "resid": resid,
                    "chain": chain_id,
                    "secondary_structure": ss_code,
                    "relative_accessibility": rel_acc
                })
            
            if not records:
                logging.warning("DSSP returned no records")
                return use_fallback_dssp(pdb_file)
                
            dssp_df = pd.DataFrame(records)
            logging.info(f"DSSP successfully extracted data for {len(dssp_df)} residues")
            
            return dssp_df
        
        finally:
            # Clean up temporary file
            if tmp_pdb and os.path.exists(tmp_pdb):
                try:
                    os.remove(tmp_pdb)
                except:
                    pass
    
    except Exception as e:
        logging.error(f"Failed to run DSSP analysis: {e}")
        return use_fallback_dssp(pdb_file)


def use_fallback_dssp(pdb_file: str) -> pd.DataFrame:
    """
    Fallback method when DSSP fails.
    Provides default secondary structure and accessibility values.
    """
    logging.info(f"Using fallback secondary structure prediction for {pdb_file}")
    
    try:
        # First check if the PDB file exists
        abs_pdb_file = os.path.abspath(pdb_file)
        if not os.path.exists(abs_pdb_file):
            # Create dummy data for missing PDB
            return pd.DataFrame({
                "resid": list(range(1, 21)),  # 20 dummy residues
                "chain": ["A"] * 20,
                "secondary_structure": ["C"] * 20,  # All coil
                "relative_accessibility": [0.5] * 20  # Medium accessibility
            })
        
        # Parse PDB to get residue info
        try:
            from Bio.PDB import PDBParser
            parser = PDBParser(QUIET=True)
            structure = parser.get_structure("protein", abs_pdb_file)
            
            records = []
            for model in structure:
                for chain in model:
                    chain_id = chain.id
                    for residue in chain:
                        if residue.id[0] == " ":  # Standard residue
                            resid = residue.id[1]
                            records.append({
                                "resid": resid,
                                "chain": chain_id,
                                "secondary_structure": "C",  # Default to coil
                                "relative_accessibility": 0.5  # Default to moderate accessibility
                            })
            
            if records:
                return pd.DataFrame(records)
        except Exception as e:
            logging.warning(f"Failed to parse PDB structure: {e}")
        
        # If we get here, we couldn't parse the PDB, so create dummy data
        return pd.DataFrame({
            "resid": list(range(1, 21)),
            "chain": ["A"] * 20,
            "secondary_structure": ["C"] * 20,
            "relative_accessibility": [0.5] * 20
        })
        
    except Exception as e:
        logging.error(f"Fallback DSSP also failed: {e}")
        # Return minimal dataframe with required columns
        return pd.DataFrame({
            "resid": list(range(1, 21)),
            "chain": ["A"] * 20,
            "secondary_structure": ["C"] * 20,
            "relative_accessibility": [0.5] * 20
        })
===== FILE: src/mdcath/processing/voxelizer.py =====
#!/usr/bin/env python3
"""
Processing module for voxelizing protein structures using aposteriori.
"""

import os
import logging
import subprocess
import traceback
import sys
from typing import Dict, Any, Optional, List, Tuple
from concurrent.futures import ProcessPoolExecutor, as_completed

def voxelize_domains(pdb_results: Dict[str, Any], config: Dict[str, Any]) -> Dict[str, Any]:
    """
    Voxelize multiple domains by processing the PDB directory directly.
    Handles the interactive confirmation prompt automatically.
    
    Args:
        pdb_results: Dictionary with PDB processing results
        config: Configuration dictionary
    
    Returns:
        Dictionary with voxelization results
    """
    from tqdm import tqdm
    import glob
    import shutil
    
    output_dir = config.get("output", {}).get("base_dir", "./outputs")
    voxel_dir = os.path.join(output_dir, "voxelized")
    pdb_dir = os.path.join(output_dir, "pdbs")
    
    os.makedirs(voxel_dir, exist_ok=True)
    
    # Check if aposteriori's make-frame-dataset is available
    aposteriori_path = shutil.which("make-frame-dataset")
    aposteriori_available = aposteriori_path is not None
    
    if not aposteriori_available:
        logging.error("make-frame-dataset command not found. Please install aposteriori with: pip install aposteriori")
        return {"success": False, "error": "aposteriori not available"}
    
    logging.info(f"Using aposteriori's make-frame-dataset from: {aposteriori_path}")
    
    # Count valid PDB files
    pdb_files = glob.glob(os.path.join(pdb_dir, "*.pdb"))
    
    if not pdb_files:
        logging.error(f"No PDB files found for voxelization in directory: {pdb_dir}")
        return {"success": False, "error": "No PDB files found"}
    
    logging.info(f"Found {len(pdb_files)} PDB files for voxelization in {pdb_dir}")
    
    # Get voxelization parameters from config
    voxel_config = config.get("processing", {}).get("voxelization", {})
    frame_edge_length = voxel_config.get("frame_edge_length", 12.0)
    voxels_per_side = voxel_config.get("voxels_per_side", 21)
    atom_encoder = voxel_config.get("atom_encoder", "CNOCBCA")
    encode_cb = voxel_config.get("encode_cb", True)
    compression_gzip = voxel_config.get("compression_gzip", True)
    voxelise_all_states = voxel_config.get("voxelise_all_states", False)
    
    # Create output name
    output_name = "mdcath_voxelized"
    
    # Build aposteriori command to process the PDB directory
    cmd = [
        aposteriori_path,
        "-o", voxel_dir,  # Output directory
        "-n", output_name,  # Output filename
        "-v",  # Enable verbose output
        "-e", ".pdb",  # File extension to look for
        "--frame-edge-length", str(frame_edge_length),
        "--voxels-per-side", str(voxels_per_side),
        "-ae", atom_encoder,
        "-cb", str(encode_cb).lower(),
        "-comp", str(compression_gzip).lower(),
        "-vas", str(voxelise_all_states).lower(),
        pdb_dir  # Directory containing PDB files
    ]
    
    # Log the exact command being run
    logging.info(f"Running aposteriori command: {' '.join(cmd)}")
    
    try:
        # Use Popen instead of run to handle interactive prompts
        process = subprocess.Popen(
            cmd,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        # Send 'y' to confirm when prompted, with a newline character
        stdout, stderr = process.communicate(input='y\n')
        
        # Log the output
        logging.info(f"aposteriori stdout:\n{stdout}")
        if stderr:
            logging.info(f"aposteriori stderr:\n{stderr}")
        
        # Check return code
        if process.returncode != 0:
            logging.error(f"aposteriori command failed with return code {process.returncode}")
        
        # Check for expected output files (try both .hdf5 and .h5 extensions)
        output_file_hdf5 = os.path.join(voxel_dir, f"{output_name}.hdf5")
        output_file_h5 = os.path.join(voxel_dir, f"{output_name}.h5")
        
        if os.path.exists(output_file_hdf5):
            logging.info(f"Voxelization complete. Output: {output_file_hdf5}")
            file_size_mb = os.path.getsize(output_file_hdf5) / (1024 * 1024)
            logging.info(f"Output file size: {file_size_mb:.2f} MB")
            
            # Count number of residue frames
            try:
                import h5py
                with h5py.File(output_file_hdf5, 'r') as f:
                    num_frames = 0
                    for pdb_code in f.keys():
                        for chain_id in f[pdb_code].keys():
                            num_frames += len(f[pdb_code][chain_id].keys())
                logging.info(f"Dataset contains {num_frames} residue frames")
            except Exception as e:
                logging.warning(f"Could not count frames in output file: {e}")
            
            return {
                "success": True,
                "output_file": output_file_hdf5,
                "file_size_mb": file_size_mb,
                "num_frames": num_frames if 'num_frames' in locals() else None
            }
        elif os.path.exists(output_file_h5):
            logging.info(f"Voxelization complete. Output: {output_file_h5}")
            file_size_mb = os.path.getsize(output_file_h5) / (1024 * 1024)
            logging.info(f"Output file size: {file_size_mb:.2f} MB")
            
            # Count number of residue frames
            try:
                import h5py
                with h5py.File(output_file_h5, 'r') as f:
                    num_frames = 0
                    for pdb_code in f.keys():
                        for chain_id in f[pdb_code].keys():
                            num_frames += len(f[pdb_code][chain_id].keys())
                logging.info(f"Dataset contains {num_frames} residue frames")
            except Exception as e:
                logging.warning(f"Could not count frames in output file: {e}")
            
            return {
                "success": True,
                "output_file": output_file_h5,
                "file_size_mb": file_size_mb,
                "num_frames": num_frames if 'num_frames' in locals() else None
            }
        else:
            logging.error(f"Voxelization failed: No output file generated")
            return {
                "success": False,
                "error": "Output file not found",
                "command": ' '.join(cmd),
                "stdout": stdout,
                "stderr": stderr
            }
        
    except Exception as e:
        logging.error(f"Voxelization error: {e}")
        logging.error(traceback.format_exc())
        return {
            "success": False, 
            "error": str(e)
        }
===== FILE: src/mdcath/processing/__init__.py =====
"""
Data processing modules for mdCATH
"""

===== FILE: src/mdcath/processing/rmsf.py =====
#!/usr/bin/env python3
"""
Processing module for RMSF data extraction and averaging.
"""

import os
import logging
import numpy as np
import pandas as pd
from typing import List, Dict, Optional, Any, Union
from concurrent.futures import ProcessPoolExecutor

def calculate_replica_averages(rmsf_data: Dict[str, Dict[str, pd.DataFrame]],
                              temperature: str) -> Optional[pd.DataFrame]:
    """
    Calculate average RMSF across all replicas for a specific temperature.

    Args:
        rmsf_data: Dictionary with RMSF data for all replicas
        temperature: Temperature to calculate average for

    Returns:
        DataFrame with average RMSF values or None if calculation fails
    """
    try:
        # Collect all dataframes for this temperature
        dfs = []
        for replica, df in rmsf_data.get(temperature, {}).items():
            if df is not None:
                dfs.append(df)

        if not dfs:
            logging.warning(f"No RMSF data found for temperature {temperature}")
            return None

        # Combine the first dataframe for residue information
        result_df = dfs[0][['domain_id', 'resid', 'resname']].copy()

        # Calculate average RMSF
        rmsf_values = []
        for df in dfs:
            rmsf_col = f"rmsf_{temperature}"
            if rmsf_col in df.columns:
                rmsf_values.append(df[rmsf_col].values)

        if not rmsf_values:
            logging.warning(f"No RMSF values found for temperature {temperature}")
            return None

        # Calculate average
        avg_rmsf = np.mean(rmsf_values, axis=0)
        result_df[f"rmsf_{temperature}"] = avg_rmsf

        return result_df
    except Exception as e:
        logging.error(f"Failed to calculate replica averages for temperature {temperature}: {e}")
        return None

def calculate_temperature_average(replica_averages: Dict[str, pd.DataFrame]) -> Optional[pd.DataFrame]:
    """
    Calculate average RMSF across all temperatures.

    Args:
        replica_averages: Dictionary with replica average RMSF data for all temperatures

    Returns:
        DataFrame with average RMSF values across all temperatures or None if calculation fails
    """
    try:
        if not replica_averages:
            logging.warning("No replica averages found")
            return None

        # Get the first dataframe for base structure
        temps = list(replica_averages.keys())
        first_temp = temps[0]
        result_df = replica_averages[first_temp][['domain_id', 'resid', 'resname']].copy()

        # Collect RMSF values for all temperatures
        rmsf_cols = []
        for temp, df in replica_averages.items():
            rmsf_col = f"rmsf_{temp}"
            if rmsf_col in df.columns:
                result_df[rmsf_col] = df[rmsf_col]
                rmsf_cols.append(rmsf_col)

        if not rmsf_cols:
            logging.warning("No RMSF columns found")
            return None

        # Calculate average across all temperatures
        result_df['rmsf_average'] = result_df[rmsf_cols].mean(axis=1)

        return result_df
    except Exception as e:
        logging.error(f"Failed to calculate temperature average: {e}")
        return None

def save_rmsf_data(rmsf_data: Dict[str, Dict[str, pd.DataFrame]],
                  replica_averages: Dict[str, pd.DataFrame],
                  temperature_average: pd.DataFrame,
                  output_dir: str) -> bool:
    """
    Save RMSF data to CSV files.

    Args:
        rmsf_data: Dictionary with RMSF data for all temperatures and replicas
        replica_averages: Dictionary with replica average RMSF data for all temperatures
        temperature_average: DataFrame with average RMSF values across all temperatures
        output_dir: Directory to save CSV files

    Returns:
        Boolean indicating if saving was successful
    """
    try:
        # Create output directory structure
        os.makedirs(os.path.join(output_dir, "RMSF", "replicas"), exist_ok=True)
        os.makedirs(os.path.join(output_dir, "RMSF", "replica_average", "average"), exist_ok=True)

        # Save replica data
        for temp, replicas in rmsf_data.items():
            for replica, df in replicas.items():
                replica_dir = os.path.join(output_dir, "RMSF", "replicas", f"replica_{replica}", temp)
                os.makedirs(replica_dir, exist_ok=True)

                output_file = os.path.join(replica_dir, f"rmsf_replica{replica}_temperature{temp}.csv")
                df.to_csv(output_file, index=False)
                logging.info(f"Saved RMSF data to {output_file}")

        # Save replica averages
        for temp, df in replica_averages.items():
            temp_dir = os.path.join(output_dir, "RMSF", "replica_average", temp)
            os.makedirs(temp_dir, exist_ok=True)

            output_file = os.path.join(temp_dir, f"rmsf_replica_average_temperature{temp}.csv")
            df.to_csv(output_file, index=False)
            logging.info(f"Saved replica average RMSF data to {output_file}")

        # Save temperature average
        output_file = os.path.join(output_dir, "RMSF", "replica_average", "average",
                                  "rmsf_all_temperatures_all_replicas.csv")
        temperature_average.to_csv(output_file, index=False)
        logging.info(f"Saved temperature average RMSF data to {output_file}")

        return True
    except Exception as e:
        logging.error(f"Failed to save RMSF data: {e}")
        return False

def process_rmsf_data(domain_results: Dict[str, Dict[str, Any]], config: Dict[str, Any]) -> Dict[str, Any]:
    """
    Process RMSF data for all domains.

    Args:
        domain_results: Dictionary with processing results for all domains
        config: Configuration dictionary

    Returns:
        Dictionary with RMSF processing results
    """
    temps = [str(t) for t in config.get("temperatures", [320, 348, 379, 413, 450])]
    output_dir = config.get("output", {}).get("base_dir", "./outputs")

    # Combine RMSF data from all domains
    combined_rmsf_data = {temp: {} for temp in temps}
    for domain_id, result in domain_results.items():
        if not result.get("success", False):
            continue

        rmsf_data = result.get("rmsf_data", {})
        for temp in temps:
            if temp in rmsf_data:
                for replica, df in rmsf_data[temp].items():
                    if replica not in combined_rmsf_data[temp]:
                        combined_rmsf_data[temp][replica] = []
                    combined_rmsf_data[temp][replica].append(df)

    # Concatenate dataframes for each temperature and replica
    for temp in combined_rmsf_data:
        for replica in combined_rmsf_data[temp]:
            if combined_rmsf_data[temp][replica]:
                combined_rmsf_data[temp][replica] = pd.concat(combined_rmsf_data[temp][replica], ignore_index=True)

    # Calculate replica averages
    replica_averages = {}
    for temp in temps:
        avg_df = calculate_replica_averages(combined_rmsf_data, temp)
        if avg_df is not None:
            replica_averages[temp] = avg_df

    # Calculate temperature average
    temperature_average = calculate_temperature_average(replica_averages)

    # Save RMSF data
    save_success = save_rmsf_data(combined_rmsf_data, replica_averages, temperature_average, output_dir)

    return {
        "combined_rmsf_data": combined_rmsf_data,
        "replica_averages": replica_averages,
        "temperature_average": temperature_average,
        "save_success": save_success
    }

===== FILE: src/mdcath/processing/pdb.py =====
#!/usr/bin/env python3
"""
Processing module for PDB data extraction and cleaning.
"""

import os
import logging
import numpy as np
from typing import Dict, Any, Optional, List, Tuple
from concurrent.futures import ProcessPoolExecutor, as_completed

# Import pdbUtils for better PDB handling
try:
    from pdbUtils import pdbUtils
    PDBUTILS_AVAILABLE = True
except ImportError:
    logging.warning("pdbUtils library not found. Installing fallback method for PDB cleaning.")
    PDBUTILS_AVAILABLE = False


def save_pdb_file(pdb_string: str, output_path: str, config: Dict[str, Any]) -> bool:
    """
    Save a PDB string to a file with cleaning applied.

    Args:
        pdb_string: PDB data as a string
        output_path: Path to save the cleaned PDB
        config: Configuration dictionary

    Returns:
        Boolean indicating if saving was successful
    """
    try:
        # Write original PDB to a temporary file
        temp_path = output_path + ".temp"
        with open(temp_path, 'w') as f:
            f.write(pdb_string)

        # Clean the PDB file
        success = fix_pdb(temp_path, output_path, config)

        # Remove temporary file
        if os.path.exists(temp_path):
            os.remove(temp_path)

        return success
    except Exception as e:
        logging.error(f"Failed to save PDB file: {e}")
        return False


def fix_pdb(input_pdb_path: str, output_pdb_path: str, config: Dict[str, Any]) -> bool:
    """
    Clean and fix a PDB file for downstream processing using pdbUtils or fallback.

    Args:
        input_pdb_path: Path to input PDB file
        output_pdb_path: Path to save the cleaned PDB file
        config: Configuration dictionary

    Returns:
        Boolean indicating if cleaning was successful
    """
    if not os.path.isfile(input_pdb_path):
        logging.error(f"PDB file not found: {input_pdb_path}")
        return False

    try:
        if PDBUTILS_AVAILABLE:
            return fix_pdb_with_pdbutils(input_pdb_path, output_pdb_path, config)
        else:
            return fix_pdb_fallback(input_pdb_path, output_pdb_path, config)
    except Exception as e:
        logging.error(f"Failed to clean PDB {input_pdb_path}: {e}")
        return False


def fix_pdb_with_pdbutils(input_pdb_path: str, output_pdb_path: str, config: Dict[str, Any]) -> bool:
    """
    Clean PDB file using the pdbUtils library for better compatibility with your pipeline.

    Args:
        input_pdb_path: Path to input PDB file
        output_pdb_path: Path to save the cleaned PDB file
        config: Configuration dictionary

    Returns:
        Boolean indicating if cleaning was successful
    """
    try:
        # First, check if we need to stop after TER
        stop_after_ter = config.get("pdb_cleaning", {}).get("stop_after_ter", True)
        
        # If we need to stop after TER, we need to process the file line by line first
        if stop_after_ter:
            with open(input_pdb_path, 'r') as f:
                lines = f.readlines()
                
            # Find the first TER marker
            ter_index = -1
            for i, line in enumerate(lines):
                if line.startswith("TER"):
                    ter_index = i
                    break
            
            # Create a temporary file with content up to TER marker (or all if no TER found)
            temp_input_path = input_pdb_path + ".preproc"
            with open(temp_input_path, 'w') as f:
                if ter_index > 0:
                    f.writelines(lines[:ter_index+1])  # Include the TER line
                    if not any(line.startswith("END") for line in lines[:ter_index+1]):
                        f.write("END\n")  # Add END if not present
                else:
                    f.writelines(lines)  # Use all lines if no TER found
                    
            # Now use this as our input
            actual_input = temp_input_path
        else:
            actual_input = input_pdb_path
            
        # Convert PDB to DataFrame using pdbUtils
        pdb_df = pdbUtils.pdb2df(actual_input)
        initial_atoms = len(pdb_df)

        clean_config = config.get("pdb_cleaning", {})

        # Fix ONLY the first CAY to N - more targeted approach
        if clean_config.get("fix_first_cay", True):
            atom_name_col = "ATOM_NAME" if "ATOM_NAME" in pdb_df.columns else "atom_name"
            if atom_name_col in pdb_df.columns:
                # Find the first CAY atom
                cay_rows = pdb_df[pdb_df[atom_name_col] == "CAY"]
                if not cay_rows.empty:
                    first_cay_idx = cay_rows.index[0]
                    # Change only the first CAY to N
                    pdb_df.at[first_cay_idx, atom_name_col] = "N"
                    logging.info("Changed first CAY atom to N")

        # Replace HSD/HSE/HSP with HIS
        if clean_config.get("correct_unusual_residue_names", True):
            if "RES_NAME" in pdb_df.columns:
                pdb_df["RES_NAME"] = pdb_df["RES_NAME"].apply(
                    lambda x: "HIS" if str(x).strip() in ["HSD", "HSE", "HSP"] else x
                )
            elif "resName" in pdb_df.columns:
                pdb_df["resName"] = pdb_df["resName"].apply(
                    lambda x: "HIS" if str(x).strip() in ["HSD", "HSE", "HSP"] else x
                )

        # Replace chain 0 with A
        if clean_config.get("replace_chain_0_with_A", True):
            chain_col = "CHAIN_ID" if "CHAIN_ID" in pdb_df.columns else "chainID"
            if chain_col in pdb_df.columns:
                pdb_df[chain_col] = pdb_df[chain_col].apply(
                    lambda x: "A" if str(x).strip() == "0" else x
                )

        # Fix atom numbering
        if clean_config.get("fix_atom_numbering", True):
            atom_num_col = "ATOM_NUM" if "ATOM_NUM" in pdb_df.columns else "atomNum"
            if atom_num_col in pdb_df.columns:
                pdb_df[atom_num_col] = range(1, len(pdb_df) + 1)

        # Remove hydrogens if specified
        if clean_config.get("remove_hydrogens", False):
            elem_col = "ELEMENT" if "ELEMENT" in pdb_df.columns else "element"
            if elem_col in pdb_df.columns:
                pdb_df = pdb_df[pdb_df[elem_col] != "H"]

        # Remove water/ions if config says so (TIP, WAT, HOH, SOD, CLA, chain W)
        if clean_config.get("remove_solvent_ions", False):
            skip_resnames = {"TIP", "WAT", "HOH", "SOD", "CLA"}
            res_col = "RES_NAME" if "RES_NAME" in pdb_df.columns else "resName"
            chain_col = "CHAIN_ID" if "CHAIN_ID" in pdb_df.columns else "chainID"
            if res_col in pdb_df.columns:
                pdb_df = pdb_df[~pdb_df[res_col].isin(skip_resnames)]
            if chain_col in pdb_df.columns:
                pdb_df = pdb_df[pdb_df[chain_col] != "W"]

        # Save cleaned PDB
        pdbUtils.df2pdb(pdb_df, output_pdb_path)

        # Add properly formatted CRYST1 record for DSSP compatibility
        # This is critical as the error logs show DSSP is failing due to malformed CRYST1
        with open(output_pdb_path, "r") as f:
            content = f.readlines()
        
        # Properly formatted CRYST1 record with proper spacing and floating point values
        cryst1_line = "CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1\n"
        
        # Check if CRYST1 already exists and modify/add as needed
        has_cryst1 = False
        for i, line in enumerate(content):
            if line.startswith("CRYST1"):
                has_cryst1 = True
                content[i] = cryst1_line
                break
        
        if not has_cryst1:
            content.insert(0, cryst1_line)
        
        with open(output_pdb_path, "w") as f:
            f.writelines(content)

        # Cleanup temporary file if created
        if stop_after_ter and os.path.exists(temp_input_path):
            os.remove(temp_input_path)

        final_atoms = len(pdb_df)
        logging.info(
            f"Cleaned PDB {os.path.basename(input_pdb_path)}: {initial_atoms} atoms → {final_atoms} atoms"
        )
        return True

    except Exception as e:
        logging.error(f"Failed to clean PDB with pdbUtils: {e}")
        import traceback
        logging.error(traceback.format_exc())
        return False

def fix_pdb_fallback(input_pdb_path: str, output_pdb_path: str, config: Dict[str, Any]) -> bool:
    """
    Fallback method to clean a PDB file when pdbUtils is not available.

    Args:
        input_pdb_path: Path to input PDB file
        output_pdb_path: Path to save the cleaned PDB file
        config: Configuration dictionary

    Returns:
        Boolean indicating if cleaning was successful
    """
    try:
        with open(input_pdb_path, 'r') as f:
            lines = f.readlines()

        clean_config = config.get("pdb_cleaning", {})
        has_cryst1 = any(line.strip().startswith("CRYST1") for line in lines)

        cleaned_lines = []
        # Add CRYST1 if missing
        if not has_cryst1 and clean_config.get("add_cryst1_record", True):
            # Properly formatted CRYST1 record with correct spacing
            cleaned_lines.append("CRYST1    100.000   100.000   100.000  90.00  90.00  90.00 P 1           1\n")

        # We can skip TIP, WAT, HOH, SOD, CLA, chain 'W' if remove_solvent_ions is True
        skip_solvent = clean_config.get("remove_solvent_ions", False)
        skip_resnames = {"TIP", "WAT", "HOH", "SOD", "CLA"}
        stop_after_ter = clean_config.get("stop_after_ter", True)
        
        # Track whether we've encountered TER
        ter_encountered = False
        
        # Fix atom numbering
        atom_num = 1

        for line in lines:
            # Check if we should stop processing (after TER marker)
            if stop_after_ter and ter_encountered:
                # Only keep certain record types after TER (like END)
                if line.startswith("END"):
                    cleaned_lines.append(line)
                continue
                
            # Process TER line if encountered
            if line.startswith("TER"):
                cleaned_lines.append(f"TER   {atom_num:5d}\n")
                if stop_after_ter:
                    ter_encountered = True
                continue
                
            if line.startswith("ATOM") or line.startswith("HETATM"):
                try:
                    record_type = line[0:6].strip()
                    # atom_num from the original is ignored, we use our counter
                    atom_name = line[12:16].strip()
                    alt_loc = line[16:17].strip()
                    res_name = line[17:20].strip()
                    chain_id = line[21:22].strip()
                    res_num = line[22:26].strip()
                    ins_code = line[26:27].strip()
                    x = float(line[30:38].strip())
                    y = float(line[38:46].strip())
                    z = float(line[46:54].strip())
                    occ = line[54:60].strip() or "0.00"
                    temp_factor = line[60:66].strip() or "0.00"
                    # Derive element from atom name if not present
                    element = line[76:78].strip() if len(line) >= 78 else atom_name[0:1]
                    
                    # Fix chain '0' → 'A'
                    if clean_config.get("replace_chain_0_with_A", True) and chain_id == "0":
                        chain_id = "A"

                    # Convert HSD/HSE/HSP → HIS
                    if clean_config.get("correct_unusual_residue_names", True):
                        if res_name in ["HSD", "HSE", "HSP"]:
                            res_name = "HIS"

                    # Remove hydrogens if desired
                    if clean_config.get("remove_hydrogens", False) and (
                        element == "H" or atom_name.startswith("H")
                    ):
                        continue

                    # Remove water/ions if configured
                    if skip_solvent:
                        # If residue name is in skip set OR chain is W, skip
                        if res_name in skip_resnames or chain_id == "W":
                            continue

                    # Format line
                    new_line = (
                        f"{record_type:<6s}{atom_num:5d} {atom_name:<4s}{alt_loc:1s}"
                        f"{res_name:3s} {chain_id:1s}{res_num:4s}{ins_code:1s}"
                        f"   {x:8.3f}{y:8.3f}{z:8.3f}"
                        f"{float(occ):6.2f}{float(temp_factor):6.2f}"
                        f"           {element:>2s}  \n"
                    )
                    cleaned_lines.append(new_line)
                    atom_num += 1
                    
                except ValueError as ve:
                    logging.warning(f"Error parsing line: {line.strip()} -> {ve}")
                    # Skip problematic lines
                    continue
                except Exception as e:
                    logging.warning(f"Other error processing line: {line.strip()} -> {e}")
                    # Skip problematic lines
                    continue
            elif not line.startswith("ATOM") and not line.startswith("HETATM"):
                # Keep non-ATOM lines as is (e.g. REMARK, unless it's after TER)
                cleaned_lines.append(line)

        # Add END record if not present
        if not any(line.startswith("END") for line in cleaned_lines):
            cleaned_lines.append("END\n")
            
        # Write cleaned PDB
        with open(output_pdb_path, 'w') as f:
            f.writelines(cleaned_lines)

        logging.info(f"Cleaned PDB {os.path.basename(input_pdb_path)} → {os.path.basename(output_pdb_path)}, {atom_num-1} atoms")
        return True

    except Exception as e:
        logging.error(f"Failed to clean PDB {input_pdb_path} with fallback method: {e}")
        import traceback
        logging.error(traceback.format_exc())
        return False
    
    
def extract_frames(coords: np.ndarray,
                   resids: List[int],
                   resnames: List[str],
                   domain_id: str,
                   output_dir: str,
                   temperature: str,
                   replica: str,
                   config: Dict[str, Any]) -> bool:
    """
    Extract frames from coordinate data and save as PDB files.
    Uses the cleaned PDB as a template and updates only the coordinates.

    Args:
        coords: Coordinate data
        resids: Residue IDs
        resnames: Residue names
        domain_id: Domain identifier
        output_dir: Directory to save frame PDBs
        temperature: Temperature
        replica: Replica index
        config: Configuration dictionary

    Returns:
        Boolean indicating if extraction was successful
    """
    frame_selection = config.get("processing", {}).get("frame_selection", {})
    method = frame_selection.get("method", "rmsd")
    num_frames = frame_selection.get("num_frames", 1)

    try:
        # Create output directory for frames
        frame_dir = os.path.join(output_dir, "frames", f"replica_{replica}", temperature)
        os.makedirs(frame_dir, exist_ok=True)
        
        # Get the source cleaned PDB path to use as a template
        pdb_dir = os.path.join(output_dir, "pdbs")
        pdb_path = os.path.join(pdb_dir, f"{domain_id}.pdb")
        
        # Check if the cleaned PDB exists
        if not os.path.exists(pdb_path):
            logging.error(f"Cleaned PDB file not found for domain {domain_id}: {pdb_path}")
            return False
            
        # Read the cleaned PDB template
        with open(pdb_path, 'r') as f:
            pdb_lines = f.readlines()
        
        # For simplicity, extract only the last frame if num_frames == 1
        if num_frames == 1:
            frame_idx = -1
            logging.debug(f"Coordinate shape for domain {domain_id}: {coords.shape}")

            # Handle shape differences
            if coords.ndim == 1:
                logging.warning(f"Coordinates shape {coords.shape} - expected 2D array.")
                if len(coords) == 3:  # Single XYZ
                    frame_coords = np.array([coords])
                else:
                    logging.error(f"Cannot reshape coords with length {len(coords)}")
                    return False
            elif coords.ndim == 2:
                # shape: (atoms, xyz)
                frame_coords = coords
            elif coords.ndim == 3:
                # shape: (frames, atoms, xyz)
                frame_coords = coords[frame_idx]
            else:
                logging.error(f"Unsupported coordinate dims: {coords.ndim}")
                return False

            # Verify final shape is (atoms, 3)
            if frame_coords.ndim != 2 or frame_coords.shape[1] != 3:
                logging.error(f"Coordinates have invalid shape {frame_coords.shape}")
                return False

            # Create a mapping from resid to coordinates index
            resid_to_coord = {}
            for i, resid in enumerate(resids):
                if i < len(frame_coords):
                    if resid not in resid_to_coord:
                        resid_to_coord[resid] = []
                    resid_to_coord[resid].append(i)
            
            # Track which atom indices in the PDB have been mapped to coordinates
            atom_coord_mapping = {}
            
            # First pass: Process lines and build atom_resid mapping
            atom_resid_mapping = {}
            for i, line in enumerate(pdb_lines):
                if line.startswith("ATOM") or line.startswith("HETATM"):
                    try:
                        atom_num = int(line[6:11].strip())
                        res_num = int(line[22:26].strip())
                        atom_resid_mapping[atom_num] = res_num
                    except ValueError:
                        continue
            
            # Second pass: Create new PDB with updated coordinates where possible
            new_pdb_lines = []
            for line in pdb_lines:
                if line.startswith("ATOM") or line.startswith("HETATM"):
                    try:
                        # Extract parts of the ATOM line we want to keep
                        record_type = line[0:6].strip()
                        atom_num = int(line[6:11].strip())
                        atom_name = line[12:16].strip()
                        alt_loc = line[16:17].strip()
                        res_name = line[17:20].strip()
                        chain_id = line[21:22].strip()
                        res_num = int(line[22:26].strip())
                        ins_code = line[26:27].strip()
                        
                        # Extract values from original line for fields we're not updating
                        occ = line[54:60].strip() or "0.00"
                        temp_factor = line[60:66].strip() or "0.00"
                        element = line[76:78].strip() if len(line) >= 78 else ""
                        
                        # Look up coordinates based on resid
                        if res_num in resid_to_coord and len(resid_to_coord[res_num]) > 0:
                            coord_idx = resid_to_coord[res_num][0]
                            # Update coordinates
                            x, y, z = frame_coords[coord_idx]
                            # Format new ATOM line with updated coordinates
                            new_line = (
                                f"{record_type:<6s}{atom_num:5d} {atom_name:<4s}{alt_loc:1s}"
                                f"{res_name:3s} {chain_id:1s}{res_num:4d}{ins_code:1s}"
                                f"   {x:8.3f}{y:8.3f}{z:8.3f}"
                                f"{float(occ):6.2f}{float(temp_factor):6.2f}"
                                f"           {element:>2s}  \n"
                            )
                            atom_coord_mapping[atom_num] = coord_idx
                        else:
                            # Keep original coordinates if resid not in coordinate data
                            new_line = line
                        
                        new_pdb_lines.append(new_line)
                    except ValueError:
                        # If we can't parse the line, keep it as is
                        new_pdb_lines.append(line)
                else:
                    # Non-ATOM lines (HEADER, REMARK, etc.) stay the same
                    new_pdb_lines.append(line)
            
            # Check if we've used all coordinates
            coords_used = len(atom_coord_mapping)
            logging.info(f"Used {coords_used}/{len(frame_coords)} coordinates for {domain_id}")
            
            # Write out the single-frame PDB
            frame_path = os.path.join(frame_dir, f"{domain_id}_frame.pdb")
            with open(frame_path, 'w') as f:
                f.writelines(new_pdb_lines)

            logging.info(f"Extracted 1-frame PDB for domain {domain_id} at T={temperature}, rep={replica}")
            return True

        else:
            # Not implemented
            logging.warning(f"Multiple-frame extraction not implemented; requested {num_frames}.")
            return False

    except Exception as e:
        logging.error(f"Failed to extract frames for domain {domain_id}: {e}")
        import traceback
        logging.error(traceback.format_exc())
        return False

def process_pdb_data(domain_results: Dict[str, Dict[str, Any]], config: Dict[str, Any]) -> Dict[str, Any]:
    """
    Process PDB data for all domains: save cleaned PDB, optionally extract frames, etc.

    Args:
        domain_results: Dictionary with processing results for all domains
        config: Configuration dictionary

    Returns:
        Dictionary with PDB processing results
    """
    from src.mdcath.core.data_loader import H5DataLoader
    from tqdm import tqdm

    output_dir = config.get("output", {}).get("base_dir", "./outputs")
    input_dir = config.get("input", {}).get("mdcath_folder", "/mnt/datasets/MD_CATH/data")

    # Create output directories
    pdb_dir = os.path.join(output_dir, "pdbs")
    frames_dir = os.path.join(output_dir, "frames")
    os.makedirs(pdb_dir, exist_ok=True)
    os.makedirs(frames_dir, exist_ok=True)

    results = {}

    # Check for pdbUtils
    if PDBUTILS_AVAILABLE:
        logging.info("Using pdbUtils for PDB cleaning (recommended).")
    else:
        logging.warning("pdbUtils not available, using fallback cleaning method.")

    # Save cleaned PDBs
    logging.info("Processing PDB data for domains...")
    for domain_id, result in tqdm(domain_results.items(), desc="Processing PDB files"):
        if not result.get("success", False):
            continue

        pdb_data = result.get("pdb_data", "")
        if pdb_data:
            pdb_path = os.path.join(pdb_dir, f"{domain_id}.pdb")
            success = save_pdb_file(pdb_data, pdb_path, config)
            if success:
                logging.info(f"Saved cleaned PDB for domain {domain_id}")
                results[domain_id] = {"pdb_saved": True, "pdb_path": pdb_path}
            else:
                logging.error(f"Failed to save cleaned PDB for domain {domain_id}")
                results[domain_id] = {"pdb_saved": False}

    # Extract frames from HDF5 trajectories
    temps = [str(t) for t in config.get("temperatures", [320, 348, 379, 413, 450])]
    num_replicas = config.get("num_replicas", 5)

    logging.info("Extracting frames from trajectories...")
    for domain_id, result in tqdm(results.items(), desc="Extracting frames"):
        if not result.get("pdb_saved", False):
            continue

        h5_path = os.path.join(input_dir, f"mdcath_dataset_{domain_id}.h5")
        if not os.path.exists(h5_path):
            logging.warning(f"H5 file not found for domain {domain_id}: {h5_path}")
            continue

        loader = H5DataLoader(h5_path, config)

        # For each temperature and replica
        for temp in temps:
            for r in range(num_replicas):
                replica = str(r)
                coords_result = loader.extract_coordinates(temp, replica)
                if coords_result is not None:
                    coords, resids, resnames = coords_result
                    extract_success = extract_frames(
                        coords, resids, resnames,
                        domain_id, output_dir, temp, replica, config
                    )
                    if extract_success:
                        if "frames" not in results[domain_id]:
                            results[domain_id]["frames"] = []
                        results[domain_id]["frames"].append((temp, replica))

    return results

===== FILE: src/mdcath/processing/features.py =====


#!/usr/bin/env python3
"""
Processing module for generating ML features.
"""

import os
import logging
import shutil  # <-- Added to fix "name 'shutil' is not defined" DSSP fallback error
import numpy as np
import pandas as pd
from typing import Dict, Any, Optional, List, Tuple, Union
from tqdm import tqdm

from src.mdcath.processing.core_exterior import compute_core_exterior


def generate_ml_features(rmsf_data: Dict[str, pd.DataFrame],
                         core_exterior_data: Dict[str, pd.DataFrame],
                         dssp_data: Dict[str, Dict[str, pd.DataFrame]],
                         config: Dict[str, Any]) -> Dict[str, pd.DataFrame]:
    """
    Generate ML features for all domains with improved handling of missing values.
    """
    try:
        # Get list of all domains
        domain_ids = set()
        for temp, df in rmsf_data.items():
            domain_ids.update(df["domain_id"].unique())

        domain_ids = list(domain_ids)
        logging.info(f"Generating ML features for {len(domain_ids)} domains")

        # Create feature dataframes for each temperature
        temps = [t for t in rmsf_data.keys() if t != "average"]
        feature_dfs = {}

        for temp in temps:
            # Start with RMSF data
            if temp not in rmsf_data:
                logging.warning(f"RMSF data not found for temperature {temp}")
                continue

            df = rmsf_data[temp].copy()

            # Ensure RMSF column is numeric
            rmsf_col = f"rmsf_{temp}"
            if rmsf_col in df.columns:
                df[rmsf_col] = pd.to_numeric(df[rmsf_col], errors='coerce').fillna(0.0)

            # Add protein size (number of residues for each domain)
            df["protein_size"] = df.groupby("domain_id")["resid"].transform("count")

            # Add normalized residue position
            df["normalized_resid"] = df.groupby("domain_id")["resid"].transform(
                lambda x: (x - x.min()) / max(x.max() - x.min(), 1)
            )

            # Create core_exterior column with default value
            if "core_exterior" not in df.columns:
                df["core_exterior"] = "core"  # Default to core (more conservative)
                
            # Create empty columns for missing data with default values
            if "relative_accessibility" not in df.columns:
                df["relative_accessibility"] = 0.5  # Default to moderate accessibility

            if "dssp" not in df.columns:
                df["dssp"] = "C"  # Default to coil

            # ---------------------------
            # MERGE CORE/EXTERIOR DATA
            # ---------------------------
            for domain_id in df["domain_id"].unique():
                if domain_id in core_exterior_data:
                    core_ext_df = core_exterior_data[domain_id]
                    
                    # Use regular merge to avoid dimension mismatch
                    domain_df = df[df["domain_id"] == domain_id][["domain_id", "resid"]].copy()
                    merged = pd.merge(domain_df, core_ext_df, on="resid", how="left")
                    
                    # Create mappings from resid to values
                    ce_mapping = dict(zip(merged["resid"], merged["core_exterior"]))
                    
                    # Apply the mapping to the original dataframe
                    domain_mask = df["domain_id"] == domain_id
                    df.loc[domain_mask, "core_exterior"] = df.loc[domain_mask, "resid"].map(ce_mapping).fillna("core")
                    
                    # If core_exterior_data contains relative_accessibility, use it
                    if "relative_accessibility" in core_ext_df.columns:
                        ra_mapping = dict(zip(core_ext_df["resid"], core_ext_df["relative_accessibility"]))
                        df.loc[domain_mask, "relative_accessibility"] = df.loc[domain_mask, "resid"].map(ra_mapping).fillna(0.5)

            # Ensure no missing values in core_exterior
            df["core_exterior"] = df["core_exterior"].fillna("core")

            # ---------------------------
            # ADD DSSP DATA
            # ---------------------------
            if temp in dssp_data:
                for replica, replica_dssp in dssp_data[temp].items():
                    if not replica_dssp.empty:
                        for domain_id in df["domain_id"].unique():
                            domain_dssp = replica_dssp[replica_dssp["domain_id"] == domain_id]
                            if not domain_dssp.empty:
                                # Convert resid to numeric carefully
                                domain_dssp.loc[:, "resid"] = pd.to_numeric(domain_dssp["resid"], errors='coerce')
                                
                                # Create mappings
                                dssp_mapping = dict(zip(domain_dssp["resid"], domain_dssp["dssp"]))
                                
                                # Apply mappings
                                domain_mask = df["domain_id"] == domain_id
                                df.loc[domain_mask, "dssp"] = df.loc[domain_mask, "resid"].map(dssp_mapping).fillna("C")
                                
                                # If relative_accessibility is present, use it
                                if "relative_accessibility" in domain_dssp.columns:
                                    ra_mapping = dict(zip(domain_dssp["resid"], domain_dssp["relative_accessibility"]))
                                    df.loc[domain_mask, "relative_accessibility"] = df.loc[domain_mask, "resid"].map(ra_mapping).fillna(0.5)
                                
                                # Break after first valid replica with data for this domain
                                break

            # Ensure no empty strings in DSSP
            df["dssp"] = df["dssp"].replace("", "C").replace(" ", "C").fillna("C")
            
            # Ensure relative_accessibility is numeric and not empty
            df["relative_accessibility"] = pd.to_numeric(df["relative_accessibility"], errors='coerce').fillna(0.5)

            # ---------------------------
            # ENCODE CATEGORICAL VARIABLES
            # ---------------------------
            # 1) Resname encoding: ensure all are strings
            if "resname" not in df.columns:
                # If resname is missing, create a placeholder
                df["resname"] = "UNK"

            # Convert to string and remove invalid placeholders
            df["resname"] = df["resname"].astype(str)
            filtered_resnames = [r for r in df["resname"].unique() if r not in ["nan", "None", ""]]
            unique_resnames = sorted(filtered_resnames)

            # Build mapping
            resname_mapping = {name: i+1 for i, name in enumerate(unique_resnames)}  # Start at 1
            df["resname_encoded"] = df["resname"].map(resname_mapping).fillna(0).astype(int)

            # 2) Core/Exterior encoding
            core_ext_mapping = {"core": 0, "exterior": 1, "unknown": 2}
            df["core_exterior_encoded"] = df["core_exterior"].map(core_ext_mapping).fillna(0).astype(int)

            # 3) DSSP encoding (3-state secondary structure)
            def encode_ss(ss):
                if ss in ["H", "G", "I"]:
                    return 0  # Helix
                elif ss in ["E", "B"]:
                    return 1  # Sheet
                else:
                    return 2  # Coil, Loop, or other

            df["secondary_structure_encoded"] = df["dssp"].apply(encode_ss)

            # Reorder columns to put domain_id first
            cols = df.columns.tolist()
            if "domain_id" in cols:
                cols.remove("domain_id")
                df = df[["domain_id"] + cols]

            # Final validation - ensure no NaN or empty values
            for col in df.columns:
                if df[col].dtype == 'object':
                    # For string columns, fill empty strings and NaNs with appropriate defaults
                    if col == 'dssp':
                        df[col] = df[col].replace('', 'C').replace(' ', 'C').fillna('C')
                    elif col == 'core_exterior':
                        df[col] = df[col].replace('', 'core').fillna('core')
                    elif col == 'resname':
                        df[col] = df[col].replace('', 'UNK').fillna('UNK')
                    else:
                        df[col] = df[col].fillna('unknown')
                else:
                    # For numeric columns, fill NaNs with appropriate defaults
                    if col == 'relative_accessibility':
                        df[col] = df[col].fillna(0.5)
                    else:
                        df[col] = df[col].fillna(0)

            # Store the feature dataframe
            feature_dfs[temp] = df

        # --------------------------------
        # CALCULATE AVERAGE FEATURES ACROSS TEMPS
        # --------------------------------
        if temps:
            avg_df = feature_dfs[temps[0]].copy(deep=True)

            # Calculate average RMSF across temperatures
            rmsf_cols = [f"rmsf_{temp}" for temp in temps]
            if all(col in avg_df.columns for col in rmsf_cols):
                avg_df["rmsf_average"] = avg_df[rmsf_cols].mean(axis=1)
            else:
                # If missing some temperature data
                available_cols = [col for col in rmsf_cols if col in avg_df.columns]
                if available_cols:
                    avg_df["rmsf_average"] = avg_df[available_cols].mean(axis=1)
                else:
                    # No RMSF data available
                    avg_df["rmsf_average"] = 0.0

            feature_dfs["average"] = avg_df

        return feature_dfs

    except Exception as e:
        logging.error(f"Failed to generate ML features: {e}")
        import traceback
        logging.error(traceback.format_exc())
        return {}
    
def save_ml_features(feature_dfs: Dict[str, pd.DataFrame], output_dir: str) -> bool:
    """
    Save ML features to CSV files.

    Args:
        feature_dfs: Dictionary with ML feature dataframes
        output_dir: Directory to save CSV files

    Returns:
        Boolean indicating if saving was successful
    """
    try:
        os.makedirs(output_dir, exist_ok=True)

        for temp, df in feature_dfs.items():
            if temp == "average":
                output_file = os.path.join(output_dir, "final_dataset_temperature_average.csv")
            else:
                output_file = os.path.join(output_dir, f"final_dataset_temperature_{temp}.csv")

            df.to_csv(output_file, index=False)
            logging.info(f"Saved ML features to {output_file}")

        return True
    except Exception as e:
        logging.error(f"Failed to save ML features: {e}")
        return False


def process_ml_features(rmsf_results: Dict[str, Any],
                        pdb_results: Dict[str, Any],
                        domain_results: Dict[str, Dict[str, Any]],
                        config: Dict[str, Any]) -> Dict[str, Any]:
    """
    Process ML features for all domains.
    """
    output_dir = config.get("output", {}).get("base_dir", "./outputs")

    # Extract RMSF data
    replica_averages = rmsf_results.get("replica_averages", {})
    temperature_average = rmsf_results.get("temperature_average")

    if not replica_averages:
        logging.error("No RMSF data available for ML feature generation")
        return {"success": False, "error": "No RMSF data available"}

    # Create dictionary with all RMSF data
    rmsf_data = replica_averages.copy()
    if temperature_average is not None:
        rmsf_data["average"] = temperature_average

    # Compute core/exterior data
    core_exterior_data = {}
    logging.info("Computing core/exterior classification for domains")
    for domain_id, result in tqdm(pdb_results.items(), desc="Core/exterior classification"):
        if not result.get("pdb_saved", False):
            continue

        pdb_path = result.get("pdb_path")
        if not pdb_path or not os.path.exists(pdb_path):
            logging.warning(f"PDB file not found for domain {domain_id}")
            continue

        core_ext_df = compute_core_exterior(pdb_path, config)
        if core_ext_df is not None:
            core_exterior_data[domain_id] = core_ext_df

    # Collect DSSP data
    dssp_data = {}
    temps = [str(t) for t in config.get("temperatures", [320, 348, 379, 413, 450])]

    logging.info("Collecting DSSP data")
    for domain_id, result in tqdm(domain_results.items(), desc="Processing DSSP data"):
        if not result.get("success", False):
            continue

        domain_dssp = result.get("dssp_data", {})
        for temp in temps:
            if temp in domain_dssp:
                if temp not in dssp_data:
                    dssp_data[temp] = {}

                for replica, df in domain_dssp[temp].items():
                    if replica not in dssp_data[temp]:
                        dssp_data[temp][replica] = []
                    dssp_data[temp][replica].append(df)

    # Concatenate DSSP dataframes
    logging.info("Concatenating DSSP data")
    for temp in temps:
        if temp in dssp_data:
            for replica in dssp_data[temp]:
                if dssp_data[temp][replica]:
                    dssp_data[temp][replica] = pd.concat(dssp_data[temp][replica], ignore_index=True)

    # Generate ML features
    logging.info("Generating ML features")
    feature_dfs = generate_ml_features(rmsf_data, core_exterior_data, dssp_data, config)

    if not feature_dfs:
        logging.error("Failed to generate ML features")
        return {"success": False, "error": "Feature generation failed"}

    # Save ML features
    ml_dir = os.path.join(output_dir, "ML_features")
    save_success = save_ml_features(feature_dfs, ml_dir)

    return {
        "success": save_success,
        "feature_dfs": feature_dfs,
        "output_dir": ml_dir
    }

===== FILE: src/mdcath/processing/visualization.py =====
#!/usr/bin/env python3
"""
Module for generating visualizations of processed mdCATH data.
"""

import os
import logging
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, Any, Optional, List, Tuple

def create_temperature_summary_heatmap(rmsf_data: Dict[str, pd.DataFrame], 
                                     output_dir: str) -> Optional[str]:
    """
    Create a heatmap showing RMSF values across temperatures for all domains.
    
    Args:
        rmsf_data: Dictionary with RMSF data for all temperatures
        output_dir: Directory to save visualization
        
    Returns:
        Path to the saved figure or None if creation fails
    """
    try:
        # Ensure output directory exists
        vis_dir = os.path.join(output_dir, "visualizations")
        os.makedirs(vis_dir, exist_ok=True)
        
        # Extract temperature values
        temps = [temp for temp in rmsf_data.keys() if temp != "average"]
        
        if not temps:
            logging.warning("No temperature data available for heatmap")
            return None
            
        # Prepare data for heatmap
        domain_ids = set()
        for temp in temps:
            if temp in rmsf_data:
                domain_ids.update(rmsf_data[temp]["domain_id"].unique())
        
        domain_ids = sorted(list(domain_ids))
        
        # Create a dataframe for the heatmap
        heatmap_data = []
        
        for domain_id in domain_ids:
            domain_data = {"domain_id": domain_id}
            
            for temp in temps:
                if temp in rmsf_data:
                    domain_temp_data = rmsf_data[temp][rmsf_data[temp]["domain_id"] == domain_id]
                    if not domain_temp_data.empty:
                        domain_data[f"rmsf_{temp}"] = domain_temp_data[f"rmsf_{temp}"].mean()
            
            heatmap_data.append(domain_data)
        
        if not heatmap_data:
            logging.warning("No data available for heatmap")
            return None
            
        # Create dataframe and pivot for heatmap
        heatmap_df = pd.DataFrame(heatmap_data)
        heatmap_pivot = heatmap_df.set_index("domain_id")
        
        # Create heatmap
        plt.figure(figsize=(12, len(domain_ids) * 0.4 + 2))
        sns.heatmap(heatmap_pivot, annot=True, cmap="viridis", fmt=".3f")
        plt.title("Average RMSF by Domain and Temperature")
        plt.xlabel("Temperature (K)")
        plt.ylabel("Domain ID")
        plt.tight_layout()
        
        # Save figure
        output_path = os.path.join(vis_dir, "temperature_summary.png")
        plt.savefig(output_path, dpi=300)
        plt.close()
        
        logging.info(f"Temperature summary heatmap saved to {output_path}")
        return output_path
    except Exception as e:
        logging.error(f"Failed to create temperature summary heatmap: {e}")
        return None

def create_temperature_average_summary(temperature_average: pd.DataFrame, 
                                     output_dir: str) -> Optional[str]:
    """
    Create a visualization showing average RMSF across temperatures.
    
    Args:
        temperature_average: DataFrame with average RMSF values across all temperatures
        output_dir: Directory to save visualization
        
    Returns:
        Path to the saved figure or None if creation fails
    """
    try:
        # Ensure output directory exists
        vis_dir = os.path.join(output_dir, "visualizations")
        os.makedirs(vis_dir, exist_ok=True)
        
        if temperature_average is None or temperature_average.empty:
            logging.warning("No temperature average data available for summary")
            return None
            
        # Group by domain_id and calculate statistics
        domain_stats = temperature_average.groupby("domain_id")["rmsf_average"].agg(
            ["mean", "std", "min", "max"]).reset_index()
        
        # Sort by mean RMSF
        domain_stats = domain_stats.sort_values("mean", ascending=False)
        
        # Create bar plot
        plt.figure(figsize=(12, 8))
        plt.bar(domain_stats["domain_id"], domain_stats["mean"], yerr=domain_stats["std"])
        plt.xticks(rotation=90)
        plt.title("Average RMSF by Domain (Across All Temperatures)")
        plt.xlabel("Domain ID")
        plt.ylabel("Average RMSF (nm)")
        plt.tight_layout()
        
        # Save figure
        output_path = os.path.join(vis_dir, "temperature_average_summary.png")
        plt.savefig(output_path, dpi=300)
        plt.close()
        
        logging.info(f"Temperature average summary saved to {output_path}")
        return output_path
    except Exception as e:
        logging.error(f"Failed to create temperature average summary: {e}")
        return None

def create_rmsf_distribution_plots(rmsf_data: Dict[str, pd.DataFrame], 
                                  output_dir: str) -> Optional[str]:
    """
    Create distribution plots (violin plot and histogram) showing RMSF distribution by temperature.
    
    Args:
        rmsf_data: Dictionary with RMSF data for all temperatures
        output_dir: Directory to save visualization
        
    Returns:
        Path to the saved figure or None if creation fails
    """
    try:
        # Ensure output directory exists
        vis_dir = os.path.join(output_dir, "visualizations")
        os.makedirs(vis_dir, exist_ok=True)
        
        # Extract temperature values
        temps = [temp for temp in rmsf_data.keys() if temp != "average"]
        
        if not temps:
            logging.warning("No temperature data available for distribution plots")
            return None
            
        # Prepare data for plotting
        dist_data = []
        
        for temp in temps:
            if temp in rmsf_data:
                temp_df = rmsf_data[temp]
                rmsf_col = f"rmsf_{temp}"
                
                if rmsf_col in temp_df.columns:
                    for _, row in temp_df.iterrows():
                        dist_data.append({
                            "Temperature": temp,
                            "RMSF": row[rmsf_col]
                        })
        
        if not dist_data:
            logging.warning("No data available for distribution plots")
            return None
            
        # Create dataframe for plotting
        dist_df = pd.DataFrame(dist_data)
        
        # Create violin plot
        plt.figure(figsize=(10, 6))
        sns.violinplot(x="Temperature", y="RMSF", data=dist_df)
        plt.title("RMSF Distribution by Temperature")
        plt.xlabel("Temperature (K)")
        plt.ylabel("RMSF (nm)")
        plt.tight_layout()
        
        # Save violin plot
        violin_path = os.path.join(vis_dir, "rmsf_violin_plot.png")
        plt.savefig(violin_path, dpi=300)
        plt.close()
        
        # Create histogram
        plt.figure(figsize=(10, 6))
        for temp in temps:
            temp_data = dist_df[dist_df["Temperature"] == temp]["RMSF"]
            if not temp_data.empty:
                sns.histplot(temp_data, kde=True, label=f"{temp}K")
        
        plt.title("RMSF Histogram by Temperature")
        plt.xlabel("RMSF (nm)")
        plt.ylabel("Frequency")
        plt.legend()
        plt.tight_layout()
        
        # Save histogram
        hist_path = os.path.join(vis_dir, "rmsf_histogram.png")
        plt.savefig(hist_path, dpi=300)
        plt.close()
        
        logging.info(f"RMSF distribution plots saved to {violin_path} and {hist_path}")
        return violin_path
    except Exception as e:
        logging.error(f"Failed to create RMSF distribution plots: {e}")
        return None

def create_amino_acid_rmsf_plot(rmsf_data: Dict[str, pd.DataFrame], 
                              output_dir: str) -> Optional[str]:
    """
    Create a violin plot showing RMSF distribution by amino acid type.
    
    Args:
        rmsf_data: Dictionary with RMSF data for all temperatures
        output_dir: Directory to save visualization
        
    Returns:
        Path to the saved figure or None if creation fails
    """
    try:
        # Ensure output directory exists
        vis_dir = os.path.join(output_dir, "visualizations")
        os.makedirs(vis_dir, exist_ok=True)
        
        # Use temperature average if available
        if "average" in rmsf_data and not rmsf_data["average"].empty:
            aa_data = []
            
            avg_df = rmsf_data["average"]
            for _, row in avg_df.iterrows():
                aa_data.append({
                    "Residue": row["resname"],
                    "RMSF": row["rmsf_average"]
                })
                
            # Create dataframe for plotting
            aa_df = pd.DataFrame(aa_data)
            
            # Create violin plot
            plt.figure(figsize=(14, 8))
            sns.violinplot(x="Residue", y="RMSF", data=aa_df, order=sorted(aa_df["Residue"].unique()))
            plt.title("RMSF Distribution by Amino Acid Type")
            plt.xlabel("Amino Acid")
            plt.ylabel("RMSF (nm)")
            plt.xticks(rotation=45)
            plt.tight_layout()
            
            # Save figure
            output_path = os.path.join(vis_dir, "amino_acid_rmsf_violin_plot.png")
            plt.savefig(output_path, dpi=300)
            plt.close()
            
            logging.info(f"Amino acid RMSF violin plot saved to {output_path}")
            return output_path
        else:
            logging.warning("No average temperature data available for amino acid plot")
            return None
    except Exception as e:
        logging.error(f"Failed to create amino acid RMSF plot: {e}")
        return None

def create_replica_variance_plot(rmsf_data: Dict[str, Dict[str, pd.DataFrame]],
                               output_dir: str) -> Optional[str]:
    """
    Create a plot showing variance of RMSF values across different replicas.
    
    Args:
        rmsf_data: Dictionary with RMSF data for all temperatures and replicas
        output_dir: Directory to save visualization
        
    Returns:
        Path to the saved figure or None if creation fails
    """
    try:
        # Ensure output directory exists
        vis_dir = os.path.join(output_dir, "visualizations")
        os.makedirs(vis_dir, exist_ok=True)
        
        # Extract temperatures
        temps = list(rmsf_data.keys())
        
        if not temps:
            logging.warning("No temperature data available for replica variance plot")
            return None
            
        # Calculate variance for each temperature
        variance_data = []
        
        for temp in temps:
            replicas = rmsf_data.get(temp, {})
            
            if replicas:
                # Get all domain_ids and resids
                domain_resids = set()
                
                for replica, df in replicas.items():
                    if df is not None and not df.empty:
                        for _, row in df.iterrows():
                            domain_resids.add((row["domain_id"], row["resid"]))
                
                # Calculate variance for each domain_id and resid
                for domain_id, resid in domain_resids:
                    rmsf_values = []
                    
                    for replica, df in replicas.items():
                        if df is not None and not df.empty:
                            mask = (df["domain_id"] == domain_id) & (df["resid"] == resid)
                            if mask.any():
                                rmsf_values.append(df.loc[mask, f"rmsf_{temp}"].values[0])
                    
                    if len(rmsf_values) > 1:
                        variance_data.append({
                            "Temperature": temp,
                            "Domain": domain_id,
                            "Resid": resid,
                            "Variance": np.var(rmsf_values)
                        })
        
        if not variance_data:
            logging.warning("No data available for replica variance plot")
            return None
            
        # Create dataframe for plotting
        variance_df = pd.DataFrame(variance_data)
        
        # Create box plot
        plt.figure(figsize=(10, 6))
        sns.boxplot(x="Temperature", y="Variance", data=variance_df)
        plt.title("RMSF Variance Across Replicas")
        plt.xlabel("Temperature (K)")
        plt.ylabel("Variance of RMSF (nm²)")
        plt.tight_layout()
        
        # Save figure
        output_path = os.path.join(vis_dir, "replica_variance_plot.png")
        plt.savefig(output_path, dpi=300)
        plt.close()
        
        logging.info(f"Replica variance plot saved to {output_path}")
        return output_path
    except Exception as e:
        logging.error(f"Failed to create replica variance plot: {e}")
        return None

def create_dssp_rmsf_correlation_plot(feature_dfs: Dict[str, pd.DataFrame],
                                    output_dir: str) -> Optional[str]:
    """
    Create a visualization showing the relationship between secondary structure and RMSF values.
    
    Args:
        feature_dfs: Dictionary with ML feature dataframes
        output_dir: Directory to save visualization
        
    Returns:
        Path to the saved figure or None if creation fails
    """
    try:
        # Ensure output directory exists
        vis_dir = os.path.join(output_dir, "visualizations")
        os.makedirs(vis_dir, exist_ok=True)
        
        # Use average temperature data if available
        if "average" in feature_dfs and not feature_dfs["average"].empty:
            avg_df = feature_dfs["average"]
            
            if "dssp" in avg_df.columns and "rmsf_average" in avg_df.columns:
                # Group by DSSP code and calculate statistics
                dssp_stats = avg_df.groupby("dssp")["rmsf_average"].agg(
                    ["mean", "std", "count"]).reset_index()
                
                # Sort by count (to prioritize common secondary structures)
                dssp_stats = dssp_stats.sort_values("count", ascending=False)
                
                # Create bar plot
                plt.figure(figsize=(12, 8))
                plt.bar(dssp_stats["dssp"], dssp_stats["mean"], yerr=dssp_stats["std"])
                
                # Add count as text on each bar
                for i, row in dssp_stats.iterrows():
                    plt.text(i, row["mean"] + row["std"] + 0.01, 
                            f"n={int(row['count'])}", 
                            ha='center', va='bottom', rotation=0)
                
                plt.title("Average RMSF by Secondary Structure (DSSP)")
                plt.xlabel("DSSP Code")
                plt.ylabel("Average RMSF (nm)")
                plt.tight_layout()
                
                # Save figure
                output_path = os.path.join(vis_dir, "dssp_rmsf_correlation_plot.png")
                plt.savefig(output_path, dpi=300)
                plt.close()
                
                logging.info(f"DSSP vs RMSF correlation plot saved to {output_path}")
                return output_path
            else:
                logging.warning("DSSP or RMSF data not found in feature dataframe")
                return None
        else:
            logging.warning("No average temperature data available for DSSP correlation plot")
            return None
    except Exception as e:
        logging.error(f"Failed to create DSSP vs RMSF correlation plot: {e}")
        return None

def create_feature_correlation_plot(feature_dfs: Dict[str, pd.DataFrame],
                                  output_dir: str) -> Optional[str]:
    """
    Create a visualization highlighting relationships between structural features and RMSF.
    
    Args:
        feature_dfs: Dictionary with ML feature dataframes
        output_dir: Directory to save visualization
        
    Returns:
        Path to the saved figure or None if creation fails
    """
    try:
        # Ensure output directory exists
        vis_dir = os.path.join(output_dir, "visualizations")
        os.makedirs(vis_dir, exist_ok=True)
        
        # Use average temperature data if available
        if "average" in feature_dfs and not feature_dfs["average"].empty:
            avg_df = feature_dfs["average"]
            
            # Select numerical columns for correlation
            numerical_cols = []
            for col in avg_df.columns:
                if col.startswith("rmsf_") or col == "normalized_resid" or col.endswith("_encoded"):
                    numerical_cols.append(col)
            
            if not numerical_cols:
                logging.warning("No numerical feature columns found for correlation plot")
                return None
                
            # Calculate correlation
            corr_df = avg_df[numerical_cols].corr()
            
            # Create heatmap
            plt.figure(figsize=(10, 8))
            sns.heatmap(corr_df, annot=True, cmap="coolwarm", fmt=".2f", 
                       vmin=-1, vmax=1, center=0)
            plt.title("Correlation Between Features and RMSF")
            plt.tight_layout()
            
            # Save figure
            output_path = os.path.join(vis_dir, "feature_correlation_plot.png")
            plt.savefig(output_path, dpi=300)
            plt.close()
            
            logging.info(f"Feature correlation plot saved to {output_path}")
            return output_path
        else:
            logging.warning("No average temperature data available for feature correlation plot")
            return None
    except Exception as e:
        logging.error(f"Failed to create feature correlation plot: {e}")
        return None

def generate_visualizations(rmsf_results: Dict[str, Any], 
                          ml_results: Dict[str, Any],
                          domain_results: Dict[str, Dict[str, Any]],
                          config: Dict[str, Any]) -> Dict[str, Any]:
    """
    Generate all required visualizations.
    
    Args:
        rmsf_results: Dictionary with RMSF processing results
        ml_results: Dictionary with ML feature processing results
        domain_results: Dictionary with processing results for all domains
        config: Configuration dictionary
        
    Returns:
        Dictionary with visualization results
    """
    output_dir = config.get("output", {}).get("base_dir", "./outputs")
    
    # Extract required data
    replica_averages = rmsf_results.get("replica_averages", {})
    temperature_average = rmsf_results.get("temperature_average")
    combined_rmsf_data = rmsf_results.get("combined_rmsf_data", {})
    feature_dfs = ml_results.get("feature_dfs", {})
    
    # Generate visualizations
    results = {}
    
    # Temperature summary heatmap
    results["temperature_summary"] = create_temperature_summary_heatmap(
        replica_averages, output_dir)
        
    # Temperature average summary
    results["temperature_average_summary"] = create_temperature_average_summary(
        temperature_average, output_dir)
        
    # RMSF distribution plots
    results["rmsf_distribution"] = create_rmsf_distribution_plots(
        replica_averages, output_dir)
        
    # Amino acid RMSF plot
    results["amino_acid_rmsf"] = create_amino_acid_rmsf_plot(
        {"average": temperature_average}, output_dir)
        
    # Replica variance plot
    results["replica_variance"] = create_replica_variance_plot(
        combined_rmsf_data, output_dir)
        
    # DSSP vs RMSF correlation plot
    results["dssp_rmsf_correlation"] = create_dssp_rmsf_correlation_plot(
        feature_dfs, output_dir)
        
    # Feature correlation plot
    results["feature_correlation"] = create_feature_correlation_plot(
        feature_dfs, output_dir)
    
    return results


=======================================
Extracting First 10 Lines from Data Directory (Ignoring Binary Files)
=======================================

Data directory /home/s_felix/mdcath-processor/data6 does not exist.
Data Directory: /home/s_felix/mdcath-processor

Folder Structure in Data Directory:
.
├── AI_context.sh
├── AI_context.txt
├── check_environment.py
├── LICENSE
├── main.py
├── mdcath_processing.log
├── msms_executables
│   ├── 1crn.pdb
│   ├── 1crn.xyzr
│   ├── 1crn.xyzrn
│   ├── atmtypenumbers
│   ├── msms.1
│   ├── msms.html
│   ├── msms_i86_64Linux2_2.6.1.tar.gz
│   ├── msms.x86_64Linux2.2.6.1
│   ├── msms.x86_64Linux2.2.6.1.staticgcc
│   ├── pdb_to_xyzr
│   ├── pdb_to_xyzrn
│   ├── README
│   ├── ReleaseNotes
│   ├── test.pdb
│   └── test.xyzr
├── outputs
│   ├── frames
│   │   ├── replica_0
│   │   │   ├── 320
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 348
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 379
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 413
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   └── 450
│   │   │       ├── 1a02F00_frame.pdb
│   │   │       └── 1a0aA00_frame.pdb
│   │   ├── replica_1
│   │   │   ├── 320
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 348
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 379
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 413
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   └── 450
│   │   │       ├── 1a02F00_frame.pdb
│   │   │       └── 1a0aA00_frame.pdb
│   │   ├── replica_2
│   │   │   ├── 320
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 348
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 379
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 413
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   └── 450
│   │   │       ├── 1a02F00_frame.pdb
│   │   │       └── 1a0aA00_frame.pdb
│   │   ├── replica_3
│   │   │   ├── 320
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 348
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 379
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   ├── 413
│   │   │   │   ├── 1a02F00_frame.pdb
│   │   │   │   └── 1a0aA00_frame.pdb
│   │   │   └── 450
│   │   │       ├── 1a02F00_frame.pdb
│   │   │       └── 1a0aA00_frame.pdb
│   │   └── replica_4
│   │       ├── 320
│   │       │   ├── 1a02F00_frame.pdb
│   │       │   └── 1a0aA00_frame.pdb
│   │       ├── 348
│   │       │   ├── 1a02F00_frame.pdb
│   │       │   └── 1a0aA00_frame.pdb
│   │       ├── 379
│   │       │   ├── 1a02F00_frame.pdb
│   │       │   └── 1a0aA00_frame.pdb
│   │       ├── 413
│   │       │   ├── 1a02F00_frame.pdb
│   │       │   └── 1a0aA00_frame.pdb
│   │       └── 450
│   │           ├── 1a02F00_frame.pdb
│   │           └── 1a0aA00_frame.pdb
│   ├── ML_features
│   │   ├── final_dataset_temperature_320.csv
│   │   ├── final_dataset_temperature_348.csv
│   │   ├── final_dataset_temperature_379.csv
│   │   ├── final_dataset_temperature_413.csv
│   │   ├── final_dataset_temperature_450.csv
│   │   └── final_dataset_temperature_average.csv
│   ├── pdbs
│   │   ├── 1a02F00.pdb
│   │   └── 1a0aA00.pdb
│   ├── RMSF
│   │   ├── replica_average
│   │   │   ├── 320
│   │   │   │   └── rmsf_replica_average_temperature320.csv
│   │   │   ├── 348
│   │   │   │   └── rmsf_replica_average_temperature348.csv
│   │   │   ├── 379
│   │   │   │   └── rmsf_replica_average_temperature379.csv
│   │   │   ├── 413
│   │   │   │   └── rmsf_replica_average_temperature413.csv
│   │   │   ├── 450
│   │   │   │   └── rmsf_replica_average_temperature450.csv
│   │   │   └── average
│   │   │       └── rmsf_all_temperatures_all_replicas.csv
│   │   └── replicas
│   │       ├── replica_0
│   │       │   ├── 320
│   │       │   │   └── rmsf_replica0_temperature320.csv
│   │       │   ├── 348
│   │       │   │   └── rmsf_replica0_temperature348.csv
│   │       │   ├── 379
│   │       │   │   └── rmsf_replica0_temperature379.csv
│   │       │   ├── 413
│   │       │   │   └── rmsf_replica0_temperature413.csv
│   │       │   └── 450
│   │       │       └── rmsf_replica0_temperature450.csv
│   │       ├── replica_1
│   │       │   ├── 320
│   │       │   │   └── rmsf_replica1_temperature320.csv
│   │       │   ├── 348
│   │       │   │   └── rmsf_replica1_temperature348.csv
│   │       │   ├── 379
│   │       │   │   └── rmsf_replica1_temperature379.csv
│   │       │   ├── 413
│   │       │   │   └── rmsf_replica1_temperature413.csv
│   │       │   └── 450
│   │       │       └── rmsf_replica1_temperature450.csv
│   │       ├── replica_2
│   │       │   ├── 320
│   │       │   │   └── rmsf_replica2_temperature320.csv
│   │       │   ├── 348
│   │       │   │   └── rmsf_replica2_temperature348.csv
│   │       │   ├── 379
│   │       │   │   └── rmsf_replica2_temperature379.csv
│   │       │   ├── 413
│   │       │   │   └── rmsf_replica2_temperature413.csv
│   │       │   └── 450
│   │       │       └── rmsf_replica2_temperature450.csv
│   │       ├── replica_3
│   │       │   ├── 320
│   │       │   │   └── rmsf_replica3_temperature320.csv
│   │       │   ├── 348
│   │       │   │   └── rmsf_replica3_temperature348.csv
│   │       │   ├── 379
│   │       │   │   └── rmsf_replica3_temperature379.csv
│   │       │   ├── 413
│   │       │   │   └── rmsf_replica3_temperature413.csv
│   │       │   └── 450
│   │       │       └── rmsf_replica3_temperature450.csv
│   │       └── replica_4
│   │           ├── 320
│   │           │   └── rmsf_replica4_temperature320.csv
│   │           ├── 348
│   │           │   └── rmsf_replica4_temperature348.csv
│   │           ├── 379
│   │           │   └── rmsf_replica4_temperature379.csv
│   │           ├── 413
│   │           │   └── rmsf_replica4_temperature413.csv
│   │           └── 450
│   │               └── rmsf_replica4_temperature450.csv
│   ├── visualizations
│   │   ├── amino_acid_rmsf_violin_plot.png
│   │   ├── dssp_rmsf_correlation_plot.png
│   │   ├── feature_correlation_plot.png
│   │   ├── replica_variance_plot.png
│   │   ├── rmsf_histogram.png
│   │   ├── rmsf_violin_plot.png
│   │   ├── temperature_average_summary.png
│   │   └── temperature_summary.png
│   └── voxelized
│       └── mdcath_voxelized.hdf5
├── README.md
├── requirements.txt
├── setup.py
├── setup.sh
├── src
│   ├── mdcath
│   │   ├── config
│   │   │   ├── default_config.yaml
│   │   │   └── __init__.py
│   │   ├── core
│   │   │   ├── data_loader.py
│   │   │   ├── __init__.py
│   │   │   └── __pycache__
│   │   │       ├── data_loader.cpython-39.pyc
│   │   │       └── __init__.cpython-39.pyc
│   │   ├── __init__.py
│   │   ├── processing
│   │   │   ├── core_exterior.py
│   │   │   ├── features.py
│   │   │   ├── __init__.py
│   │   │   ├── pdb.py
│   │   │   ├── __pycache__
│   │   │   │   ├── core_exterior.cpython-39.pyc
│   │   │   │   ├── features.cpython-39.pyc
│   │   │   │   ├── __init__.cpython-39.pyc
│   │   │   │   ├── pdb.cpython-39.pyc
│   │   │   │   ├── rmsf.cpython-39.pyc
│   │   │   │   ├── visualization.cpython-39.pyc
│   │   │   │   └── voxelizer.cpython-39.pyc
│   │   │   ├── rmsf.py
│   │   │   ├── visualization.py
│   │   │   └── voxelizer.py
│   │   └── __pycache__
│   │       └── __init__.cpython-39.pyc
│   └── mdcath.egg-info
│       ├── dependency_links.txt
│       ├── PKG-INFO
│       ├── requires.txt
│       ├── SOURCES.txt
│       └── top_level.txt
└── test_h5_loading.py

85 directories, 151 files

Extracting First 10 Lines from Each File in Data Directory (Excluding Binary & pipeline.log):
-------------------------------------------------------------------------------------
===== FILE: ./msms_executables/pdb_to_xyzrn =====
#! /bin/sh
# extract x,y,z from PDB file, generate radius of each atom
# Hydrogens are presumed to be missing ("united atom" approach) unless -h given
# later: options for alternate radius and pattern files
# --- Mike Pique, The Scripps Research Institute
#
# input: pdb file as argument or stdin
# output: new xyzr file to stdout
#
# Options:

===== FILE: ./msms_executables/pdb_to_xyzr =====
#! /bin/sh
# extract x,y,z from PDB file, generate radius of each atom
# Hydrogens are presumed to be missing ("united atom" approach) unless -h given
# later: options for alternate radius and pattern files
# --- Mike Pique, The Scripps Research Institute
#
# input: pdb file as argument or stdin
# output: new xyzr file to stdout
#
# Options:

===== FILE: ./msms_executables/test.xyzr =====
  -3.917    0.791   -0.042 1.70
  -2.616    0.112   -0.179 2.00
  -1.490    1.102   -0.001 1.74
  -1.699    2.154    0.594 1.40
  -2.440   -0.950   -1.300 2.00
  -2.544   -0.372    0.751 1.20
  -3.250   -1.657   -1.300 1.20

===== FILE: ./msms_executables/test.pdb =====
ATOM      1  N   ALA A   1      -3.917   0.791  -0.042  1.00  0.00           N  
ATOM      2  CA  ALA A   1      -2.616   0.112  -0.179  1.00  0.00           C  
ATOM      3  C   ALA A   1      -1.490   1.102  -0.001  1.00  0.00           C  
ATOM      4  O   ALA A   1      -1.699   2.154   0.594  1.00  0.00           O  
ATOM      5  CB  ALA A   1      -2.440  -0.950  -1.300  1.00  0.00           C  
ATOM      6  HA  ALA A   1      -2.544  -0.372   0.751  1.00  0.00           H  
ATOM      7  HB1 ALA A   1      -3.250  -1.657  -1.300  1.00  0.00           H  
TER
END

===== FILE: ./msms_executables/msms.html =====
<html>
<head>
<title>
MSMS man page
</title>
</head>

<body>
<pre>
<H3>MSMS(1)                   User Commands                   MSMS(1)</H3>

===== FILE: ./msms_executables/atmtypenumbers =====
# atmtypenumber 
# $Revision: 1.13 $
# Maps residue type and atom name pairs into Connolly ".atm" numeric codes
#  as used in MS and AMS, and into actual radius values
#
# Format: (blank lines and lines beginning with # are ignored)
#  Any number of blanks or tabs separate fields.
#
# Format of "radius" entries
# Field 1: keyword "radius"

===== FILE: ./msms_executables/ReleaseNotes =====
Version 2.6.1
- modified find_free_edges to continue when an atom is found to
  be completely inside another atom

Version 2.6.0
- Dual density support:
  It is now possible to compute a molecular surface with 2 densities of 
  vertices.
  The command line accepts a new keyword "hdensity" for specifying the vertex 
  density to be used in the high density region.

===== FILE: ./msms_executables/1crn.xyzr =====
  17.047   14.099    3.625 1.70
  16.967   12.784    4.338 2.00
  15.685   12.755    5.133 1.74
  15.268   13.825    5.594 1.40
  18.170   12.703    5.337 2.00
  19.334   12.829    4.463 1.60
  18.150   11.546    6.304 2.00
  15.115   11.555    5.265 1.70
  13.856   11.469    6.066 2.00
  14.164   10.785    7.379 1.74

===== FILE: ./msms_executables/1crn.xyzrn =====
17.047000 14.099000 3.625000 1.700000 1 N_THR_1
16.967000 12.784000 4.338000 2.000000 1 CA_THR_1
15.685000 12.755000 5.133000 1.740000 1 C_THR_1
15.268000 13.825000 5.594000 1.400000 1 O_THR_1
18.170000 12.703000 5.337000 2.000000 1 CB_THR_1
19.334000 12.829000 4.463000 1.600000 1 OG1_THR_1
18.150000 11.546000 6.304000 2.000000 1 CG2_THR_1
15.115000 11.555000 5.265000 1.700000 1 N_THR_2
13.856000 11.469000 6.066000 2.000000 1 CA_THR_2
14.164000 10.785000 7.379000 1.740000 1 C_THR_2

===== FILE: ./msms_executables/msms.1 =====
.\" @(#)nroff.1 1.33 90/02/15 SMI;
.TH MSMS 1 v2.5 "Nov. 3 1999"
.SH NAME
msms 
.SH SYNOPSIS
.B msms
[
.BI \-if \ filename
] [
.BI \-of \ filename

===== FILE: ./msms_executables/README =====
MSMS v2.5.7 (Michel F. SANNER Jan. 2006)

MSMS computes, for a given probe radius, the reduced surface of a set of
spheres. An analytical description of the solvent excluded surface is
computed from the reduced surface. Special attention is paid to the proper
handling of self-intersecting parts of the surface called singularities.
This analytical model of the solvent excluded surface can be triangulated
with a user specified vertex density (see references for more information).

############################################################################

===== FILE: ./AI_context.txt =====
Working Directory: /home/s_felix/mdcath-processor

File Structure:
.
├── AI_context.sh
├── AI_context.txt
├── check_environment.py
├── LICENSE
├── main.py
├── mdcath_processing.log

===== FILE: ./setup.sh =====
# #!/bin/bash

# # Make the script exit on error
# set -e

# echo "Generating code files for mdCATH project..."

# # ------------------------------------
# # INIT FILES
# # ------------------------------------

===== FILE: ./AI_context.sh =====
#!/bin/bash

# Define output file (adjusted to the current project structure)
OUTPUT_FILE="/home/s_felix/mdcath-processor/AI_context.txt"

# Start writing to output file
{
    echo "Working Directory: $(pwd)"
    echo ""
    echo "File Structure:"

===== FILE: ./setup.py =====
#!/usr/bin/env python3
"""
Setup script for mdCATH
"""

from setuptools import setup, find_packages

setup(
    name="mdcath",
    version="0.1.0",

===== FILE: ./mdcath_processing.log =====
2025-03-19 22:50:56,352 - h5py._conv - DEBUG - Creating converter from 3 to 5
2025-03-19 22:50:56,659 - h5py._conv - DEBUG - Creating converter from 3 to 5
2025-03-19 23:10:27,327 - h5py._conv - DEBUG - Creating converter from 3 to 5
2025-03-19 23:10:27,634 - h5py._conv - DEBUG - Creating converter from 3 to 5
2025-03-19 23:23:12,817 - h5py._conv - DEBUG - Creating converter from 3 to 5
2025-03-19 23:23:13,126 - h5py._conv - DEBUG - Creating converter from 3 to 5
2025-03-19 23:23:20,300 - matplotlib.pyplot - DEBUG - Loaded backend agg version v2.2.
2025-03-19 23:23:20,302 - matplotlib.font_manager - DEBUG - findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2025-03-19 23:23:20,302 - matplotlib.font_manager - DEBUG - findfont: score(FontEntry(fname='/home/s_felix/.conda/envs/apo_env/lib/python3.9/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2025-03-19 23:23:20,302 - matplotlib.font_manager - DEBUG - findfont: score(FontEntry(fname='/home/s_felix/.conda/envs/apo_env/lib/python3.9/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05

===== FILE: ./.git/config =====
[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
[remote "origin"]
	url = https://github.com/Felixburton7/mdcath-processor2.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[branch "main"]
	remote = origin

===== FILE: ./.git/description =====
Unnamed repository; edit this file 'description' to name the repository.

===== FILE: ./.git/HEAD =====
ref: refs/heads/main

===== FILE: ./.git/refs/remotes/origin/main =====
16dc0354d39edebbe7342eed9cad9d8e1e2b5ca7

===== FILE: ./.git/refs/heads/main =====
16dc0354d39edebbe7342eed9cad9d8e1e2b5ca7

===== FILE: ./.git/info/exclude =====
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~

===== FILE: ./.git/COMMIT_EDITMSG =====
fixed bugs

===== FILE: ./.git/hooks/pre-applypatch.sample =====
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".


===== FILE: ./.git/hooks/pre-commit.sample =====
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1

===== FILE: ./.git/hooks/fsmonitor-watchman.sample =====
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#

===== FILE: ./.git/hooks/applypatch-msg.sample =====
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

===== FILE: ./.git/hooks/push-to-checkout.sample =====
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#

===== FILE: ./.git/hooks/pre-receive.sample =====
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then

===== FILE: ./.git/hooks/update.sample =====
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated

===== FILE: ./.git/hooks/pre-merge-commit.sample =====
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup

===== FILE: ./.git/hooks/pre-push.sample =====
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done

===== FILE: ./.git/hooks/post-update.sample =====
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info

===== FILE: ./.git/hooks/commit-msg.sample =====
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".


===== FILE: ./.git/hooks/pre-rebase.sample =====
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#

===== FILE: ./.git/hooks/prepare-commit-msg.sample =====
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

===== FILE: ./.git/logs/HEAD =====
0000000000000000000000000000000000000000 e5d234b3768d56a714b360b82486d7dcf1c1daf9 Felix Burton <felixburton2002@gmail.com> 1742428799 +0000	commit (initial): first commit
e5d234b3768d56a714b360b82486d7dcf1c1daf9 0000000000000000000000000000000000000000 Felix Burton <felixburton2002@gmail.com> 1742428799 +0000	Branch: renamed refs/heads/master to refs/heads/main
0000000000000000000000000000000000000000 e5d234b3768d56a714b360b82486d7dcf1c1daf9 Felix Burton <felixburton2002@gmail.com> 1742428799 +0000	Branch: renamed refs/heads/master to refs/heads/main
e5d234b3768d56a714b360b82486d7dcf1c1daf9 e7829511d2beaccc14b25cd651bbef6837f0ef10 Felix Burton <felixburton2002@gmail.com> 1742428809 +0000	commit: initial commit
e7829511d2beaccc14b25cd651bbef6837f0ef10 16dc0354d39edebbe7342eed9cad9d8e1e2b5ca7 Felix Burton <felixburton2002@gmail.com> 1742603805 +0000	commit: fixed bugs

===== FILE: ./.git/logs/refs/remotes/origin/main =====
0000000000000000000000000000000000000000 e5d234b3768d56a714b360b82486d7dcf1c1daf9 Felix Burton <felixburton2002@gmail.com> 1742428801 +0000	update by push
e5d234b3768d56a714b360b82486d7dcf1c1daf9 e7829511d2beaccc14b25cd651bbef6837f0ef10 Felix Burton <felixburton2002@gmail.com> 1742428813 +0000	update by push
e7829511d2beaccc14b25cd651bbef6837f0ef10 16dc0354d39edebbe7342eed9cad9d8e1e2b5ca7 Felix Burton <felixburton2002@gmail.com> 1742603810 +0000	update by push

===== FILE: ./.git/logs/refs/heads/main =====
0000000000000000000000000000000000000000 e5d234b3768d56a714b360b82486d7dcf1c1daf9 Felix Burton <felixburton2002@gmail.com> 1742428799 +0000	commit (initial): first commit
e5d234b3768d56a714b360b82486d7dcf1c1daf9 e5d234b3768d56a714b360b82486d7dcf1c1daf9 Felix Burton <felixburton2002@gmail.com> 1742428799 +0000	Branch: renamed refs/heads/master to refs/heads/main
e5d234b3768d56a714b360b82486d7dcf1c1daf9 e7829511d2beaccc14b25cd651bbef6837f0ef10 Felix Burton <felixburton2002@gmail.com> 1742428809 +0000	commit: initial commit
e7829511d2beaccc14b25cd651bbef6837f0ef10 16dc0354d39edebbe7342eed9cad9d8e1e2b5ca7 Felix Burton <felixburton2002@gmail.com> 1742603805 +0000	commit: fixed bugs

===== FILE: ./LICENSE =====
MIT License

Copyright (c) 2025 mdCATH Processing Project

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

===== FILE: ./outputs/ML_features/final_dataset_temperature_320.csv =====
domain_id,resid,resname,rmsf_320,protein_size,normalized_resid,core_exterior,relative_accessibility,dssp,resname_encoded,core_exterior_encoded,secondary_structure_encoded
1a0aA00,0,MET,1.3483024,63,0.0,exterior,0.9521276595744681,C,13,1,2
1a0aA00,1,LYS,1.1942909,63,0.016129032258064516,exterior,0.6341463414634146,T,12,1,2
1a0aA00,2,ARG,1.0236586,63,0.03225806451612903,exterior,0.7258064516129032,T,2,1,2
1a0aA00,3,GLU,0.88456726,63,0.04838709677419355,exterior,0.5154639175257731,C,7,1,2
1a0aA00,4,SER,0.80763894,63,0.06451612903225806,exterior,0.5461538461538461,C,15,1,2
1a0aA00,5,HSD,0.727569,63,0.08064516129032258,exterior,0.4782608695652174,H,9,1,0
1a0aA00,6,LYS,0.65099525,63,0.0967741935483871,exterior,0.7073170731707317,H,12,1,0
1a0aA00,7,HSD,0.57902086,63,0.11290322580645161,exterior,0.7663043478260869,H,9,1,0
1a0aA00,8,ALA,0.5618905,63,0.12903225806451613,exterior,0.3867924528301887,H,1,1,0

===== FILE: ./outputs/ML_features/final_dataset_temperature_average.csv =====
domain_id,resid,resname,rmsf_320,protein_size,normalized_resid,core_exterior,relative_accessibility,dssp,resname_encoded,core_exterior_encoded,secondary_structure_encoded,rmsf_average
1a0aA00,0,MET,1.3483024,63,0.0,exterior,0.9521276595744681,C,13,1,2,1.3483024
1a0aA00,1,LYS,1.1942909,63,0.016129032258064516,exterior,0.6341463414634146,T,12,1,2,1.1942909
1a0aA00,2,ARG,1.0236586,63,0.03225806451612903,exterior,0.7258064516129032,T,2,1,2,1.0236586
1a0aA00,3,GLU,0.88456726,63,0.04838709677419355,exterior,0.5154639175257731,C,7,1,2,0.88456726
1a0aA00,4,SER,0.80763894,63,0.06451612903225806,exterior,0.5461538461538461,C,15,1,2,0.80763894
1a0aA00,5,HSD,0.727569,63,0.08064516129032258,exterior,0.4782608695652174,H,9,1,0,0.727569
1a0aA00,6,LYS,0.65099525,63,0.0967741935483871,exterior,0.7073170731707317,H,12,1,0,0.65099525
1a0aA00,7,HSD,0.57902086,63,0.11290322580645161,exterior,0.7663043478260869,H,9,1,0,0.57902086
1a0aA00,8,ALA,0.5618905,63,0.12903225806451613,exterior,0.3867924528301887,H,1,1,0,0.5618905

===== FILE: ./outputs/ML_features/final_dataset_temperature_379.csv =====
domain_id,resid,resname,rmsf_379,protein_size,normalized_resid,core_exterior,relative_accessibility,dssp,resname_encoded,core_exterior_encoded,secondary_structure_encoded
1a0aA00,0,MET,1.4772995,63,0.0,exterior,0.9521276595744681,C,13,1,2
1a0aA00,1,LYS,1.3467977,63,0.016129032258064516,exterior,0.6341463414634146,C,12,1,2
1a0aA00,2,ARG,1.2123555,63,0.03225806451612903,exterior,0.7258064516129032,C,2,1,2
1a0aA00,3,GLU,1.0923307,63,0.04838709677419355,exterior,0.5154639175257731,C,7,1,2
1a0aA00,4,SER,0.9989087,63,0.06451612903225806,exterior,0.5461538461538461,C,15,1,2
1a0aA00,5,HSD,0.9201416,63,0.08064516129032258,exterior,0.4782608695652174,S,9,1,2
1a0aA00,6,LYS,0.86415035,63,0.0967741935483871,exterior,0.7073170731707317,C,12,1,2
1a0aA00,7,HSD,0.8167307,63,0.11290322580645161,exterior,0.7663043478260869,H,9,1,0
1a0aA00,8,ALA,0.8115508,63,0.12903225806451613,exterior,0.3867924528301887,H,1,1,0

===== FILE: ./outputs/ML_features/final_dataset_temperature_348.csv =====
domain_id,resid,resname,rmsf_348,protein_size,normalized_resid,core_exterior,relative_accessibility,dssp,resname_encoded,core_exterior_encoded,secondary_structure_encoded
1a0aA00,0,MET,1.4334629,63,0.0,exterior,0.9521276595744681,C,13,1,2
1a0aA00,1,LYS,1.2852292,63,0.016129032258064516,exterior,0.6341463414634146,C,12,1,2
1a0aA00,2,ARG,1.1520655,63,0.03225806451612903,exterior,0.7258064516129032,S,2,1,2
1a0aA00,3,GLU,1.0097101,63,0.04838709677419355,exterior,0.5154639175257731,S,7,1,2
1a0aA00,4,SER,0.9123613,63,0.06451612903225806,exterior,0.5461538461538461,S,15,1,2
1a0aA00,5,HSD,0.83743477,63,0.08064516129032258,exterior,0.4782608695652174,S,9,1,2
1a0aA00,6,LYS,0.7914341,63,0.0967741935483871,exterior,0.7073170731707317,C,12,1,2
1a0aA00,7,HSD,0.72878,63,0.11290322580645161,exterior,0.7663043478260869,C,9,1,2
1a0aA00,8,ALA,0.7131204,63,0.12903225806451613,exterior,0.3867924528301887,C,1,1,2

===== FILE: ./outputs/ML_features/final_dataset_temperature_450.csv =====
domain_id,resid,resname,rmsf_450,protein_size,normalized_resid,core_exterior,relative_accessibility,dssp,resname_encoded,core_exterior_encoded,secondary_structure_encoded
1a0aA00,0,MET,1.5951369,63,0.0,exterior,0.9521276595744681,C,13,1,2
1a0aA00,1,LYS,1.4604483,63,0.016129032258064516,exterior,0.6341463414634146,T,12,1,2
1a0aA00,2,ARG,1.3335836,63,0.03225806451612903,exterior,0.7258064516129032,T,2,1,2
1a0aA00,3,GLU,1.2270706,63,0.04838709677419355,exterior,0.5154639175257731,T,7,1,2
1a0aA00,4,SER,1.1463414,63,0.06451612903225806,exterior,0.5461538461538461,C,15,1,2
1a0aA00,5,HSD,1.0700214,63,0.08064516129032258,exterior,0.4782608695652174,T,9,1,2
1a0aA00,6,LYS,1.0232189,63,0.0967741935483871,exterior,0.7073170731707317,T,12,1,2
1a0aA00,7,HSD,0.9782146,63,0.11290322580645161,exterior,0.7663043478260869,S,9,1,2
1a0aA00,8,ALA,0.9594307,63,0.12903225806451613,exterior,0.3867924528301887,S,1,1,2

===== FILE: ./outputs/ML_features/final_dataset_temperature_413.csv =====
domain_id,resid,resname,rmsf_413,protein_size,normalized_resid,core_exterior,relative_accessibility,dssp,resname_encoded,core_exterior_encoded,secondary_structure_encoded
1a0aA00,0,MET,1.535583,63,0.0,exterior,0.9521276595744681,C,13,1,2
1a0aA00,1,LYS,1.3957214,63,0.016129032258064516,exterior,0.6341463414634146,C,12,1,2
1a0aA00,2,ARG,1.2685184,63,0.03225806451612903,exterior,0.7258064516129032,C,2,1,2
1a0aA00,3,GLU,1.1422019,63,0.04838709677419355,exterior,0.5154639175257731,C,7,1,2
1a0aA00,4,SER,1.065963,63,0.06451612903225806,exterior,0.5461538461538461,S,15,1,2
1a0aA00,5,HSD,1.0004411,63,0.08064516129032258,exterior,0.4782608695652174,S,9,1,2
1a0aA00,6,LYS,0.96211654,63,0.0967741935483871,exterior,0.7073170731707317,C,12,1,2
1a0aA00,7,HSD,0.92500556,63,0.11290322580645161,exterior,0.7663043478260869,S,9,1,2
1a0aA00,8,ALA,0.90814066,63,0.12903225806451613,exterior,0.3867924528301887,C,1,1,2

===== FILE: ./outputs/RMSF/replicas/replica_2/450/rmsf_replica2_temperature450.csv =====
domain_id,resid,resname,rmsf_450
1a0aA00,0,MET,1.576657
1a0aA00,1,LYS,1.449326
1a0aA00,2,ARG,1.3184797
1a0aA00,3,GLU,1.2020646
1a0aA00,4,SER,1.1092825
1a0aA00,5,HSD,1.03165
1a0aA00,6,LYS,0.9916885
1a0aA00,7,HSD,0.9476638
1a0aA00,8,ALA,0.9263482

===== FILE: ./outputs/RMSF/replicas/replica_2/379/rmsf_replica2_temperature379.csv =====
domain_id,resid,resname,rmsf_379
1a0aA00,0,MET,1.486446
1a0aA00,1,LYS,1.3436912
1a0aA00,2,ARG,1.2161818
1a0aA00,3,GLU,1.1121883
1a0aA00,4,SER,1.0212007
1a0aA00,5,HSD,0.95545167
1a0aA00,6,LYS,0.93970597
1a0aA00,7,HSD,0.8710641
1a0aA00,8,ALA,0.85942423

===== FILE: ./outputs/RMSF/replicas/replica_2/348/rmsf_replica2_temperature348.csv =====
domain_id,resid,resname,rmsf_348
1a0aA00,0,MET,1.3438317
1a0aA00,1,LYS,1.1628337
1a0aA00,2,ARG,0.98899806
1a0aA00,3,GLU,0.78073865
1a0aA00,4,SER,0.66014934
1a0aA00,5,HSD,0.5683823
1a0aA00,6,LYS,0.5556865
1a0aA00,7,HSD,0.54684573
1a0aA00,8,ALA,0.5087722

===== FILE: ./outputs/RMSF/replicas/replica_2/413/rmsf_replica2_temperature413.csv =====
domain_id,resid,resname,rmsf_413
1a0aA00,0,MET,1.5180621
1a0aA00,1,LYS,1.3557527
1a0aA00,2,ARG,1.2430704
1a0aA00,3,GLU,1.084986
1a0aA00,4,SER,0.9785675
1a0aA00,5,HSD,0.8939153
1a0aA00,6,LYS,0.8452332
1a0aA00,7,HSD,0.82844514
1a0aA00,8,ALA,0.8422664

===== FILE: ./outputs/RMSF/replicas/replica_2/320/rmsf_replica2_temperature320.csv =====
domain_id,resid,resname,rmsf_320
1a0aA00,0,MET,1.1646829
1a0aA00,1,LYS,1.0131446
1a0aA00,2,ARG,0.8290087
1a0aA00,3,GLU,0.72083545
1a0aA00,4,SER,0.69494045
1a0aA00,5,HSD,0.6436807
1a0aA00,6,LYS,0.5260527
1a0aA00,7,HSD,0.5048531
1a0aA00,8,ALA,0.57275873

===== FILE: ./outputs/RMSF/replicas/replica_4/450/rmsf_replica4_temperature450.csv =====
domain_id,resid,resname,rmsf_450
1a0aA00,0,MET,1.5668608
1a0aA00,1,LYS,1.4300203
1a0aA00,2,ARG,1.2976882
1a0aA00,3,GLU,1.1884801
1a0aA00,4,SER,1.113481
1a0aA00,5,HSD,1.037043
1a0aA00,6,LYS,0.9926844
1a0aA00,7,HSD,0.95811844
1a0aA00,8,ALA,0.9481535

===== FILE: ./outputs/RMSF/replicas/replica_4/379/rmsf_replica4_temperature379.csv =====
domain_id,resid,resname,rmsf_379
1a0aA00,0,MET,1.7543902
1a0aA00,1,LYS,1.6238198
1a0aA00,2,ARG,1.4525822
1a0aA00,3,GLU,1.333633
1a0aA00,4,SER,1.2282166
1a0aA00,5,HSD,1.126744
1a0aA00,6,LYS,1.0666938
1a0aA00,7,HSD,1.02929
1a0aA00,8,ALA,0.97728163

===== FILE: ./outputs/RMSF/replicas/replica_4/348/rmsf_replica4_temperature348.csv =====
domain_id,resid,resname,rmsf_348
1a0aA00,0,MET,1.4582078
1a0aA00,1,LYS,1.3222756
1a0aA00,2,ARG,1.2127962
1a0aA00,3,GLU,1.1044127
1a0aA00,4,SER,1.0218058
1a0aA00,5,HSD,0.9168606
1a0aA00,6,LYS,0.873983
1a0aA00,7,HSD,0.744759
1a0aA00,8,ALA,0.71165997

===== FILE: ./outputs/RMSF/replicas/replica_4/413/rmsf_replica4_temperature413.csv =====
domain_id,resid,resname,rmsf_413
1a0aA00,0,MET,1.5753905
1a0aA00,1,LYS,1.4575608
1a0aA00,2,ARG,1.3407844
1a0aA00,3,GLU,1.2185456
1a0aA00,4,SER,1.1469868
1a0aA00,5,HSD,1.0841664
1a0aA00,6,LYS,1.0452274
1a0aA00,7,HSD,0.96590567
1a0aA00,8,ALA,0.9230095

===== FILE: ./outputs/RMSF/replicas/replica_4/320/rmsf_replica4_temperature320.csv =====
domain_id,resid,resname,rmsf_320
1a0aA00,0,MET,1.2959518
1a0aA00,1,LYS,1.1318272
1a0aA00,2,ARG,0.937099
1a0aA00,3,GLU,0.78042084
1a0aA00,4,SER,0.662699
1a0aA00,5,HSD,0.60237837
1a0aA00,6,LYS,0.58158493
1a0aA00,7,HSD,0.52150637
1a0aA00,8,ALA,0.5021656

===== FILE: ./outputs/RMSF/replicas/replica_0/450/rmsf_replica0_temperature450.csv =====
domain_id,resid,resname,rmsf_450
1a0aA00,0,MET,1.6510745
1a0aA00,1,LYS,1.511354
1a0aA00,2,ARG,1.3840455
1a0aA00,3,GLU,1.2687927
1a0aA00,4,SER,1.1770655
1a0aA00,5,HSD,1.0775056
1a0aA00,6,LYS,1.0026208
1a0aA00,7,HSD,0.92482156
1a0aA00,8,ALA,0.87528

===== FILE: ./outputs/RMSF/replicas/replica_0/379/rmsf_replica0_temperature379.csv =====
domain_id,resid,resname,rmsf_379
1a0aA00,0,MET,1.3748816
1a0aA00,1,LYS,1.204677
1a0aA00,2,ARG,1.0503837
1a0aA00,3,GLU,0.9162814
1a0aA00,4,SER,0.8170538
1a0aA00,5,HSD,0.75173515
1a0aA00,6,LYS,0.7013601
1a0aA00,7,HSD,0.67923796
1a0aA00,8,ALA,0.7133326

===== FILE: ./outputs/RMSF/replicas/replica_0/348/rmsf_replica0_temperature348.csv =====
domain_id,resid,resname,rmsf_348
1a0aA00,0,MET,1.5692973
1a0aA00,1,LYS,1.4050725
1a0aA00,2,ARG,1.2579968
1a0aA00,3,GLU,1.0861257
1a0aA00,4,SER,0.95714736
1a0aA00,5,HSD,0.870287
1a0aA00,6,LYS,0.7932945
1a0aA00,7,HSD,0.72311026
1a0aA00,8,ALA,0.72987825

===== FILE: ./outputs/RMSF/replicas/replica_0/413/rmsf_replica0_temperature413.csv =====
domain_id,resid,resname,rmsf_413
1a0aA00,0,MET,1.5348728
1a0aA00,1,LYS,1.383954
1a0aA00,2,ARG,1.2424289
1a0aA00,3,GLU,1.124453
1a0aA00,4,SER,1.0636528
1a0aA00,5,HSD,0.9922364
1a0aA00,6,LYS,0.96015614
1a0aA00,7,HSD,0.9305036
1a0aA00,8,ALA,0.93326944

===== FILE: ./outputs/RMSF/replicas/replica_0/320/rmsf_replica0_temperature320.csv =====
domain_id,resid,resname,rmsf_320
1a0aA00,0,MET,1.5170379
1a0aA00,1,LYS,1.3901875
1a0aA00,2,ARG,1.2544051
1a0aA00,3,GLU,1.0989321
1a0aA00,4,SER,1.01632
1a0aA00,5,HSD,0.873037
1a0aA00,6,LYS,0.7593873
1a0aA00,7,HSD,0.6777895
1a0aA00,8,ALA,0.58092916

===== FILE: ./outputs/RMSF/replicas/replica_1/450/rmsf_replica1_temperature450.csv =====
domain_id,resid,resname,rmsf_450
1a0aA00,0,MET,1.5921198
1a0aA00,1,LYS,1.4617525
1a0aA00,2,ARG,1.343816
1a0aA00,3,GLU,1.2477936
1a0aA00,4,SER,1.1704543
1a0aA00,5,HSD,1.0975823
1a0aA00,6,LYS,1.0598528
1a0aA00,7,HSD,1.0091052
1a0aA00,8,ALA,1.0253049

===== FILE: ./outputs/RMSF/replicas/replica_1/379/rmsf_replica1_temperature379.csv =====
domain_id,resid,resname,rmsf_379
1a0aA00,0,MET,1.4234052
1a0aA00,1,LYS,1.3028092
1a0aA00,2,ARG,1.1737462
1a0aA00,3,GLU,1.0883411
1a0aA00,4,SER,1.0238752
1a0aA00,5,HSD,0.9739617
1a0aA00,6,LYS,0.9107688
1a0aA00,7,HSD,0.850515
1a0aA00,8,ALA,0.82572573

===== FILE: ./outputs/RMSF/replicas/replica_1/348/rmsf_replica1_temperature348.csv =====
domain_id,resid,resname,rmsf_348
1a0aA00,0,MET,1.4276665
1a0aA00,1,LYS,1.3018955
1a0aA00,2,ARG,1.2027749
1a0aA00,3,GLU,1.0919421
1a0aA00,4,SER,1.0101075
1a0aA00,5,HSD,0.94147146
1a0aA00,6,LYS,0.8805832
1a0aA00,7,HSD,0.8448707
1a0aA00,8,ALA,0.83776975

===== FILE: ./outputs/RMSF/replicas/replica_1/413/rmsf_replica1_temperature413.csv =====
domain_id,resid,resname,rmsf_413
1a0aA00,0,MET,1.5977552
1a0aA00,1,LYS,1.4646237
1a0aA00,2,ARG,1.3380047
1a0aA00,3,GLU,1.2248296
1a0aA00,4,SER,1.1503581
1a0aA00,5,HSD,1.0700762
1a0aA00,6,LYS,1.0123969
1a0aA00,7,HSD,0.9607783
1a0aA00,8,ALA,0.917867

===== FILE: ./outputs/RMSF/replicas/replica_1/320/rmsf_replica1_temperature320.csv =====
domain_id,resid,resname,rmsf_320
1a0aA00,0,MET,1.3012784
1a0aA00,1,LYS,1.114217
1a0aA00,2,ARG,0.926238
1a0aA00,3,GLU,0.80870616
1a0aA00,4,SER,0.7295469
1a0aA00,5,HSD,0.6783448
1a0aA00,6,LYS,0.6098052
1a0aA00,7,HSD,0.502893
1a0aA00,8,ALA,0.48675847

===== FILE: ./outputs/RMSF/replicas/replica_3/450/rmsf_replica3_temperature450.csv =====
domain_id,resid,resname,rmsf_450
1a0aA00,0,MET,1.5889727
1a0aA00,1,LYS,1.4497886
1a0aA00,2,ARG,1.3238894
1a0aA00,3,GLU,1.2282224
1a0aA00,4,SER,1.1614239
1a0aA00,5,HSD,1.1063261
1a0aA00,6,LYS,1.0692474
1a0aA00,7,HSD,1.051364
1a0aA00,8,ALA,1.0220671

===== FILE: ./outputs/RMSF/replicas/replica_3/379/rmsf_replica3_temperature379.csv =====
domain_id,resid,resname,rmsf_379
1a0aA00,0,MET,1.3473746
1a0aA00,1,LYS,1.2589906
1a0aA00,2,ARG,1.1688836
1a0aA00,3,GLU,1.0112096
1a0aA00,4,SER,0.90419716
1a0aA00,5,HSD,0.79281574
1a0aA00,6,LYS,0.70222276
1a0aA00,7,HSD,0.65354645
1a0aA00,8,ALA,0.68198967

===== FILE: ./outputs/RMSF/replicas/replica_3/348/rmsf_replica3_temperature348.csv =====
domain_id,resid,resname,rmsf_348
1a0aA00,0,MET,1.3683108
1a0aA00,1,LYS,1.2340688
1a0aA00,2,ARG,1.0977619
1a0aA00,3,GLU,0.985331
1a0aA00,4,SER,0.9125965
1a0aA00,5,HSD,0.8901723
1a0aA00,6,LYS,0.8536232
1a0aA00,7,HSD,0.78431404
1a0aA00,8,ALA,0.77752215

===== FILE: ./outputs/RMSF/replicas/replica_3/413/rmsf_replica3_temperature413.csv =====
domain_id,resid,resname,rmsf_413
1a0aA00,0,MET,1.4518346
1a0aA00,1,LYS,1.3167164
1a0aA00,2,ARG,1.1783038
1a0aA00,3,GLU,1.0581955
1a0aA00,4,SER,0.99025
1a0aA00,5,HSD,0.9618113
1a0aA00,6,LYS,0.9475691
1a0aA00,7,HSD,0.9393947
1a0aA00,8,ALA,0.92429096

===== FILE: ./outputs/RMSF/replicas/replica_3/320/rmsf_replica3_temperature320.csv =====
domain_id,resid,resname,rmsf_320
1a0aA00,0,MET,1.462561
1a0aA00,1,LYS,1.3220783
1a0aA00,2,ARG,1.1715425
1a0aA00,3,GLU,1.0139415
1a0aA00,4,SER,0.93468857
1a0aA00,5,HSD,0.84040415
1a0aA00,6,LYS,0.7781459
1a0aA00,7,HSD,0.68806225
1a0aA00,8,ALA,0.66684055

===== FILE: ./outputs/RMSF/replica_average/450/rmsf_replica_average_temperature450.csv =====
domain_id,resid,resname,rmsf_450
1a0aA00,0,MET,1.5951369
1a0aA00,1,LYS,1.4604483
1a0aA00,2,ARG,1.3335836
1a0aA00,3,GLU,1.2270706
1a0aA00,4,SER,1.1463414
1a0aA00,5,HSD,1.0700214
1a0aA00,6,LYS,1.0232189
1a0aA00,7,HSD,0.9782146
1a0aA00,8,ALA,0.9594307

===== FILE: ./outputs/RMSF/replica_average/379/rmsf_replica_average_temperature379.csv =====
domain_id,resid,resname,rmsf_379
1a0aA00,0,MET,1.4772995
1a0aA00,1,LYS,1.3467977
1a0aA00,2,ARG,1.2123555
1a0aA00,3,GLU,1.0923307
1a0aA00,4,SER,0.9989087
1a0aA00,5,HSD,0.9201416
1a0aA00,6,LYS,0.86415035
1a0aA00,7,HSD,0.8167307
1a0aA00,8,ALA,0.8115508

===== FILE: ./outputs/RMSF/replica_average/348/rmsf_replica_average_temperature348.csv =====
domain_id,resid,resname,rmsf_348
1a0aA00,0,MET,1.4334629
1a0aA00,1,LYS,1.2852292
1a0aA00,2,ARG,1.1520655
1a0aA00,3,GLU,1.0097101
1a0aA00,4,SER,0.9123613
1a0aA00,5,HSD,0.83743477
1a0aA00,6,LYS,0.7914341
1a0aA00,7,HSD,0.72878
1a0aA00,8,ALA,0.7131204

===== FILE: ./outputs/RMSF/replica_average/413/rmsf_replica_average_temperature413.csv =====
domain_id,resid,resname,rmsf_413
1a0aA00,0,MET,1.535583
1a0aA00,1,LYS,1.3957214
1a0aA00,2,ARG,1.2685184
1a0aA00,3,GLU,1.1422019
1a0aA00,4,SER,1.065963
1a0aA00,5,HSD,1.0004411
1a0aA00,6,LYS,0.96211654
1a0aA00,7,HSD,0.92500556
1a0aA00,8,ALA,0.90814066

===== FILE: ./outputs/RMSF/replica_average/average/rmsf_all_temperatures_all_replicas.csv =====
domain_id,resid,resname,rmsf_320,rmsf_348,rmsf_379,rmsf_413,rmsf_450,rmsf_average
1a0aA00,0,MET,1.3483024,1.4334629,1.4772995,1.535583,1.5951369,1.477957
1a0aA00,1,LYS,1.1942909,1.2852292,1.3467977,1.3957214,1.4604483,1.3364975
1a0aA00,2,ARG,1.0236586,1.1520655,1.2123555,1.2685184,1.3335836,1.1980364
1a0aA00,3,GLU,0.88456726,1.0097101,1.0923307,1.1422019,1.2270706,1.0711762
1a0aA00,4,SER,0.80763894,0.9123613,0.9989087,1.065963,1.1463414,0.98624265
1a0aA00,5,HSD,0.727569,0.83743477,0.9201416,1.0004411,1.0700214,0.91112155
1a0aA00,6,LYS,0.65099525,0.7914341,0.86415035,0.96211654,1.0232189,0.858383
1a0aA00,7,HSD,0.57902086,0.72878,0.8167307,0.92500556,0.9782146,0.8055504
1a0aA00,8,ALA,0.5618905,0.7131204,0.8115508,0.90814066,0.9594307,0.7908266

===== FILE: ./outputs/RMSF/replica_average/320/rmsf_replica_average_temperature320.csv =====
domain_id,resid,resname,rmsf_320
1a0aA00,0,MET,1.3483024
1a0aA00,1,LYS,1.1942909
1a0aA00,2,ARG,1.0236586
1a0aA00,3,GLU,0.88456726
1a0aA00,4,SER,0.80763894
1a0aA00,5,HSD,0.727569
1a0aA00,6,LYS,0.65099525
1a0aA00,7,HSD,0.57902086
1a0aA00,8,ALA,0.5618905

===== FILE: ./outputs/pdbs/1a0aA00.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0     -13.223 -22.589  20.858  0.00  0.00           C  
ATOM      2 HY1  MET A   0     -13.643 -23.328  21.385  0.00  0.00           H  
ATOM      3 HY2  MET A   0     -13.780 -22.385  20.054  0.00  0.00           H  
ATOM      4 HY3  MET A   0     -13.134 -21.772  21.428  0.00  0.00           H  
ATOM      5 CY   MET A   0     -12.313 -22.879  20.560  0.00  0.00           C  
ATOM      6 OY   MET A   0     -11.893 -22.140  20.033  0.00  0.00           O  
ATOM      7 N    MET A   0     -12.141 -23.806  20.892  1.00  0.00           N  
ATOM      8 HN   MET A   0     -12.561 -24.545  21.419  0.00  0.00           H  
ATOM      9 CA   MET A   0     -10.786 -24.237  20.447  1.00  0.00           C  

===== FILE: ./outputs/pdbs/1a02F00.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140      16.299   1.661 -33.895  0.00  0.00           C  
ATOM      2 HY1  ARG A 140      17.097   2.095 -33.477  0.00  0.00           H  
ATOM      3 HY2  ARG A 140      15.484   1.847 -33.347  0.00  0.00           H  
ATOM      4 HY3  ARG A 140      16.171   2.006 -34.825  0.00  0.00           H  
ATOM      5 CY   ARG A 140      16.448   0.673 -33.933  0.00  0.00           C  
ATOM      6 OY   ARG A 140      15.650   0.239 -34.350  0.00  0.00           O  
ATOM      7 N    ARG A 140      17.343   0.463 -33.539  1.00  0.00           N  
ATOM      8 HN   ARG A 140      18.141   0.897 -33.121  0.00  0.00           H  
ATOM      9 CA   ARG A 140      17.565  -1.011 -33.595  1.00  0.00           C  

===== FILE: ./outputs/frames/replica_2/450/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140      38.150-224.830 126.690  0.00  0.00            C  
ATOM      2 HY1  ARG A 140      38.150-224.830 126.690  0.00  0.00            H  
ATOM      3 HY2  ARG A 140      38.150-224.830 126.690  0.00  0.00            H  
ATOM      4 HY3  ARG A 140      38.150-224.830 126.690  0.00  0.00            H  
ATOM      5 CY   ARG A 140      38.150-224.830 126.690  0.00  0.00            C  
ATOM      6 OY   ARG A 140      38.150-224.830 126.690  0.00  0.00            O  
ATOM      7 N    ARG A 140      38.150-224.830 126.690  1.00  0.00            N  
ATOM      8 HN   ARG A 140      38.150-224.830 126.690  0.00  0.00            H  
ATOM      9 CA   ARG A 140      38.150-224.830 126.690  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_2/450/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0      49.450   9.460 145.460  0.00  0.00            C  
ATOM      2 HY1  MET A   0      49.450   9.460 145.460  0.00  0.00            H  
ATOM      3 HY2  MET A   0      49.450   9.460 145.460  0.00  0.00            H  
ATOM      4 HY3  MET A   0      49.450   9.460 145.460  0.00  0.00            H  
ATOM      5 CY   MET A   0      49.450   9.460 145.460  0.00  0.00            C  
ATOM      6 OY   MET A   0      49.450   9.460 145.460  0.00  0.00            O  
ATOM      7 N    MET A   0      49.450   9.460 145.460  1.00  0.00            N  
ATOM      8 HN   MET A   0      49.450   9.460 145.460  0.00  0.00            H  
ATOM      9 CA   MET A   0      49.450   9.460 145.460  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_2/379/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140      76.490  98.920 145.990  0.00  0.00            C  
ATOM      2 HY1  ARG A 140      76.490  98.920 145.990  0.00  0.00            H  
ATOM      3 HY2  ARG A 140      76.490  98.920 145.990  0.00  0.00            H  
ATOM      4 HY3  ARG A 140      76.490  98.920 145.990  0.00  0.00            H  
ATOM      5 CY   ARG A 140      76.490  98.920 145.990  0.00  0.00            C  
ATOM      6 OY   ARG A 140      76.490  98.920 145.990  0.00  0.00            O  
ATOM      7 N    ARG A 140      76.490  98.920 145.990  1.00  0.00            N  
ATOM      8 HN   ARG A 140      76.490  98.920 145.990  0.00  0.00            H  
ATOM      9 CA   ARG A 140      76.490  98.920 145.990  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_2/379/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0     105.530 164.810 -14.970  0.00  0.00            C  
ATOM      2 HY1  MET A   0     105.530 164.810 -14.970  0.00  0.00            H  
ATOM      3 HY2  MET A   0     105.530 164.810 -14.970  0.00  0.00            H  
ATOM      4 HY3  MET A   0     105.530 164.810 -14.970  0.00  0.00            H  
ATOM      5 CY   MET A   0     105.530 164.810 -14.970  0.00  0.00            C  
ATOM      6 OY   MET A   0     105.530 164.810 -14.970  0.00  0.00            O  
ATOM      7 N    MET A   0     105.530 164.810 -14.970  1.00  0.00            N  
ATOM      8 HN   MET A   0     105.530 164.810 -14.970  0.00  0.00            H  
ATOM      9 CA   MET A   0     105.530 164.810 -14.970  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_2/348/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140     114.820  94.070 -38.730  0.00  0.00            C  
ATOM      2 HY1  ARG A 140     114.820  94.070 -38.730  0.00  0.00            H  
ATOM      3 HY2  ARG A 140     114.820  94.070 -38.730  0.00  0.00            H  
ATOM      4 HY3  ARG A 140     114.820  94.070 -38.730  0.00  0.00            H  
ATOM      5 CY   ARG A 140     114.820  94.070 -38.730  0.00  0.00            C  
ATOM      6 OY   ARG A 140     114.820  94.070 -38.730  0.00  0.00            O  
ATOM      7 N    ARG A 140     114.820  94.070 -38.730  1.00  0.00            N  
ATOM      8 HN   ARG A 140     114.820  94.070 -38.730  0.00  0.00            H  
ATOM      9 CA   ARG A 140     114.820  94.070 -38.730  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_2/348/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0      -6.600 -69.240 106.550  0.00  0.00            C  
ATOM      2 HY1  MET A   0      -6.600 -69.240 106.550  0.00  0.00            H  
ATOM      3 HY2  MET A   0      -6.600 -69.240 106.550  0.00  0.00            H  
ATOM      4 HY3  MET A   0      -6.600 -69.240 106.550  0.00  0.00            H  
ATOM      5 CY   MET A   0      -6.600 -69.240 106.550  0.00  0.00            C  
ATOM      6 OY   MET A   0      -6.600 -69.240 106.550  0.00  0.00            O  
ATOM      7 N    MET A   0      -6.600 -69.240 106.550  1.00  0.00            N  
ATOM      8 HN   MET A   0      -6.600 -69.240 106.550  0.00  0.00            H  
ATOM      9 CA   MET A   0      -6.600 -69.240 106.550  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_2/413/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140     358.730 -67.080 192.100  0.00  0.00            C  
ATOM      2 HY1  ARG A 140     358.730 -67.080 192.100  0.00  0.00            H  
ATOM      3 HY2  ARG A 140     358.730 -67.080 192.100  0.00  0.00            H  
ATOM      4 HY3  ARG A 140     358.730 -67.080 192.100  0.00  0.00            H  
ATOM      5 CY   ARG A 140     358.730 -67.080 192.100  0.00  0.00            C  
ATOM      6 OY   ARG A 140     358.730 -67.080 192.100  0.00  0.00            O  
ATOM      7 N    ARG A 140     358.730 -67.080 192.100  1.00  0.00            N  
ATOM      8 HN   ARG A 140     358.730 -67.080 192.100  0.00  0.00            H  
ATOM      9 CA   ARG A 140     358.730 -67.080 192.100  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_2/413/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0     -35.500 -23.390  26.430  0.00  0.00            C  
ATOM      2 HY1  MET A   0     -35.500 -23.390  26.430  0.00  0.00            H  
ATOM      3 HY2  MET A   0     -35.500 -23.390  26.430  0.00  0.00            H  
ATOM      4 HY3  MET A   0     -35.500 -23.390  26.430  0.00  0.00            H  
ATOM      5 CY   MET A   0     -35.500 -23.390  26.430  0.00  0.00            C  
ATOM      6 OY   MET A   0     -35.500 -23.390  26.430  0.00  0.00            O  
ATOM      7 N    MET A   0     -35.500 -23.390  26.430  1.00  0.00            N  
ATOM      8 HN   MET A   0     -35.500 -23.390  26.430  0.00  0.00            H  
ATOM      9 CA   MET A   0     -35.500 -23.390  26.430  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_2/320/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140     351.100 -37.860 224.700  0.00  0.00            C  
ATOM      2 HY1  ARG A 140     351.100 -37.860 224.700  0.00  0.00            H  
ATOM      3 HY2  ARG A 140     351.100 -37.860 224.700  0.00  0.00            H  
ATOM      4 HY3  ARG A 140     351.100 -37.860 224.700  0.00  0.00            H  
ATOM      5 CY   ARG A 140     351.100 -37.860 224.700  0.00  0.00            C  
ATOM      6 OY   ARG A 140     351.100 -37.860 224.700  0.00  0.00            O  
ATOM      7 N    ARG A 140     351.100 -37.860 224.700  1.00  0.00            N  
ATOM      8 HN   ARG A 140     351.100 -37.860 224.700  0.00  0.00            H  
ATOM      9 CA   ARG A 140     351.100 -37.860 224.700  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_2/320/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0     -70.770 142.130 -99.930  0.00  0.00            C  
ATOM      2 HY1  MET A   0     -70.770 142.130 -99.930  0.00  0.00            H  
ATOM      3 HY2  MET A   0     -70.770 142.130 -99.930  0.00  0.00            H  
ATOM      4 HY3  MET A   0     -70.770 142.130 -99.930  0.00  0.00            H  
ATOM      5 CY   MET A   0     -70.770 142.130 -99.930  0.00  0.00            C  
ATOM      6 OY   MET A   0     -70.770 142.130 -99.930  0.00  0.00            O  
ATOM      7 N    MET A   0     -70.770 142.130 -99.930  1.00  0.00            N  
ATOM      8 HN   MET A   0     -70.770 142.130 -99.930  0.00  0.00            H  
ATOM      9 CA   MET A   0     -70.770 142.130 -99.930  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_4/450/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140    -115.450 208.680 -52.340  0.00  0.00            C  
ATOM      2 HY1  ARG A 140    -115.450 208.680 -52.340  0.00  0.00            H  
ATOM      3 HY2  ARG A 140    -115.450 208.680 -52.340  0.00  0.00            H  
ATOM      4 HY3  ARG A 140    -115.450 208.680 -52.340  0.00  0.00            H  
ATOM      5 CY   ARG A 140    -115.450 208.680 -52.340  0.00  0.00            C  
ATOM      6 OY   ARG A 140    -115.450 208.680 -52.340  0.00  0.00            O  
ATOM      7 N    ARG A 140    -115.450 208.680 -52.340  1.00  0.00            N  
ATOM      8 HN   ARG A 140    -115.450 208.680 -52.340  0.00  0.00            H  
ATOM      9 CA   ARG A 140    -115.450 208.680 -52.340  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_4/450/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0      80.350-105.930-213.540  0.00  0.00            C  
ATOM      2 HY1  MET A   0      80.350-105.930-213.540  0.00  0.00            H  
ATOM      3 HY2  MET A   0      80.350-105.930-213.540  0.00  0.00            H  
ATOM      4 HY3  MET A   0      80.350-105.930-213.540  0.00  0.00            H  
ATOM      5 CY   MET A   0      80.350-105.930-213.540  0.00  0.00            C  
ATOM      6 OY   MET A   0      80.350-105.930-213.540  0.00  0.00            O  
ATOM      7 N    MET A   0      80.350-105.930-213.540  1.00  0.00            N  
ATOM      8 HN   MET A   0      80.350-105.930-213.540  0.00  0.00            H  
ATOM      9 CA   MET A   0      80.350-105.930-213.540  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_4/379/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140      25.150 338.900 229.660  0.00  0.00            C  
ATOM      2 HY1  ARG A 140      25.150 338.900 229.660  0.00  0.00            H  
ATOM      3 HY2  ARG A 140      25.150 338.900 229.660  0.00  0.00            H  
ATOM      4 HY3  ARG A 140      25.150 338.900 229.660  0.00  0.00            H  
ATOM      5 CY   ARG A 140      25.150 338.900 229.660  0.00  0.00            C  
ATOM      6 OY   ARG A 140      25.150 338.900 229.660  0.00  0.00            O  
ATOM      7 N    ARG A 140      25.150 338.900 229.660  1.00  0.00            N  
ATOM      8 HN   ARG A 140      25.150 338.900 229.660  0.00  0.00            H  
ATOM      9 CA   ARG A 140      25.150 338.900 229.660  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_4/379/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0    -117.290  32.370-268.500  0.00  0.00            C  
ATOM      2 HY1  MET A   0    -117.290  32.370-268.500  0.00  0.00            H  
ATOM      3 HY2  MET A   0    -117.290  32.370-268.500  0.00  0.00            H  
ATOM      4 HY3  MET A   0    -117.290  32.370-268.500  0.00  0.00            H  
ATOM      5 CY   MET A   0    -117.290  32.370-268.500  0.00  0.00            C  
ATOM      6 OY   MET A   0    -117.290  32.370-268.500  0.00  0.00            O  
ATOM      7 N    MET A   0    -117.290  32.370-268.500  1.00  0.00            N  
ATOM      8 HN   MET A   0    -117.290  32.370-268.500  0.00  0.00            H  
ATOM      9 CA   MET A   0    -117.290  32.370-268.500  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_4/348/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140      18.870  56.840 270.850  0.00  0.00            C  
ATOM      2 HY1  ARG A 140      18.870  56.840 270.850  0.00  0.00            H  
ATOM      3 HY2  ARG A 140      18.870  56.840 270.850  0.00  0.00            H  
ATOM      4 HY3  ARG A 140      18.870  56.840 270.850  0.00  0.00            H  
ATOM      5 CY   ARG A 140      18.870  56.840 270.850  0.00  0.00            C  
ATOM      6 OY   ARG A 140      18.870  56.840 270.850  0.00  0.00            O  
ATOM      7 N    ARG A 140      18.870  56.840 270.850  1.00  0.00            N  
ATOM      8 HN   ARG A 140      18.870  56.840 270.850  0.00  0.00            H  
ATOM      9 CA   ARG A 140      18.870  56.840 270.850  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_4/348/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0     157.580 106.370 185.640  0.00  0.00            C  
ATOM      2 HY1  MET A   0     157.580 106.370 185.640  0.00  0.00            H  
ATOM      3 HY2  MET A   0     157.580 106.370 185.640  0.00  0.00            H  
ATOM      4 HY3  MET A   0     157.580 106.370 185.640  0.00  0.00            H  
ATOM      5 CY   MET A   0     157.580 106.370 185.640  0.00  0.00            C  
ATOM      6 OY   MET A   0     157.580 106.370 185.640  0.00  0.00            O  
ATOM      7 N    MET A   0     157.580 106.370 185.640  1.00  0.00            N  
ATOM      8 HN   MET A   0     157.580 106.370 185.640  0.00  0.00            H  
ATOM      9 CA   MET A   0     157.580 106.370 185.640  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_4/413/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140     -54.000 -56.960  55.780  0.00  0.00            C  
ATOM      2 HY1  ARG A 140     -54.000 -56.960  55.780  0.00  0.00            H  
ATOM      3 HY2  ARG A 140     -54.000 -56.960  55.780  0.00  0.00            H  
ATOM      4 HY3  ARG A 140     -54.000 -56.960  55.780  0.00  0.00            H  
ATOM      5 CY   ARG A 140     -54.000 -56.960  55.780  0.00  0.00            C  
ATOM      6 OY   ARG A 140     -54.000 -56.960  55.780  0.00  0.00            O  
ATOM      7 N    ARG A 140     -54.000 -56.960  55.780  1.00  0.00            N  
ATOM      8 HN   ARG A 140     -54.000 -56.960  55.780  0.00  0.00            H  
ATOM      9 CA   ARG A 140     -54.000 -56.960  55.780  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_4/413/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0      -2.040  39.200  90.030  0.00  0.00            C  
ATOM      2 HY1  MET A   0      -2.040  39.200  90.030  0.00  0.00            H  
ATOM      3 HY2  MET A   0      -2.040  39.200  90.030  0.00  0.00            H  
ATOM      4 HY3  MET A   0      -2.040  39.200  90.030  0.00  0.00            H  
ATOM      5 CY   MET A   0      -2.040  39.200  90.030  0.00  0.00            C  
ATOM      6 OY   MET A   0      -2.040  39.200  90.030  0.00  0.00            O  
ATOM      7 N    MET A   0      -2.040  39.200  90.030  1.00  0.00            N  
ATOM      8 HN   MET A   0      -2.040  39.200  90.030  0.00  0.00            H  
ATOM      9 CA   MET A   0      -2.040  39.200  90.030  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_4/320/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140       7.090-117.960  45.340  0.00  0.00            C  
ATOM      2 HY1  ARG A 140       7.090-117.960  45.340  0.00  0.00            H  
ATOM      3 HY2  ARG A 140       7.090-117.960  45.340  0.00  0.00            H  
ATOM      4 HY3  ARG A 140       7.090-117.960  45.340  0.00  0.00            H  
ATOM      5 CY   ARG A 140       7.090-117.960  45.340  0.00  0.00            C  
ATOM      6 OY   ARG A 140       7.090-117.960  45.340  0.00  0.00            O  
ATOM      7 N    ARG A 140       7.090-117.960  45.340  1.00  0.00            N  
ATOM      8 HN   ARG A 140       7.090-117.960  45.340  0.00  0.00            H  
ATOM      9 CA   ARG A 140       7.090-117.960  45.340  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_4/320/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0     126.180  28.310 -31.350  0.00  0.00            C  
ATOM      2 HY1  MET A   0     126.180  28.310 -31.350  0.00  0.00            H  
ATOM      3 HY2  MET A   0     126.180  28.310 -31.350  0.00  0.00            H  
ATOM      4 HY3  MET A   0     126.180  28.310 -31.350  0.00  0.00            H  
ATOM      5 CY   MET A   0     126.180  28.310 -31.350  0.00  0.00            C  
ATOM      6 OY   MET A   0     126.180  28.310 -31.350  0.00  0.00            O  
ATOM      7 N    MET A   0     126.180  28.310 -31.350  1.00  0.00            N  
ATOM      8 HN   MET A   0     126.180  28.310 -31.350  0.00  0.00            H  
ATOM      9 CA   MET A   0     126.180  28.310 -31.350  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_0/450/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140     119.490  53.590 205.540  0.00  0.00            C  
ATOM      2 HY1  ARG A 140     119.490  53.590 205.540  0.00  0.00            H  
ATOM      3 HY2  ARG A 140     119.490  53.590 205.540  0.00  0.00            H  
ATOM      4 HY3  ARG A 140     119.490  53.590 205.540  0.00  0.00            H  
ATOM      5 CY   ARG A 140     119.490  53.590 205.540  0.00  0.00            C  
ATOM      6 OY   ARG A 140     119.490  53.590 205.540  0.00  0.00            O  
ATOM      7 N    ARG A 140     119.490  53.590 205.540  1.00  0.00            N  
ATOM      8 HN   ARG A 140     119.490  53.590 205.540  0.00  0.00            H  
ATOM      9 CA   ARG A 140     119.490  53.590 205.540  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_0/450/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0     277.330 -46.270  -6.970  0.00  0.00            C  
ATOM      2 HY1  MET A   0     277.330 -46.270  -6.970  0.00  0.00            H  
ATOM      3 HY2  MET A   0     277.330 -46.270  -6.970  0.00  0.00            H  
ATOM      4 HY3  MET A   0     277.330 -46.270  -6.970  0.00  0.00            H  
ATOM      5 CY   MET A   0     277.330 -46.270  -6.970  0.00  0.00            C  
ATOM      6 OY   MET A   0     277.330 -46.270  -6.970  0.00  0.00            O  
ATOM      7 N    MET A   0     277.330 -46.270  -6.970  1.00  0.00            N  
ATOM      8 HN   MET A   0     277.330 -46.270  -6.970  0.00  0.00            H  
ATOM      9 CA   MET A   0     277.330 -46.270  -6.970  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_0/379/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140     286.190  53.910-119.060  0.00  0.00            C  
ATOM      2 HY1  ARG A 140     286.190  53.910-119.060  0.00  0.00            H  
ATOM      3 HY2  ARG A 140     286.190  53.910-119.060  0.00  0.00            H  
ATOM      4 HY3  ARG A 140     286.190  53.910-119.060  0.00  0.00            H  
ATOM      5 CY   ARG A 140     286.190  53.910-119.060  0.00  0.00            C  
ATOM      6 OY   ARG A 140     286.190  53.910-119.060  0.00  0.00            O  
ATOM      7 N    ARG A 140     286.190  53.910-119.060  1.00  0.00            N  
ATOM      8 HN   ARG A 140     286.190  53.910-119.060  0.00  0.00            H  
ATOM      9 CA   ARG A 140     286.190  53.910-119.060  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_0/379/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0     115.500  -7.610-138.030  0.00  0.00            C  
ATOM      2 HY1  MET A   0     115.500  -7.610-138.030  0.00  0.00            H  
ATOM      3 HY2  MET A   0     115.500  -7.610-138.030  0.00  0.00            H  
ATOM      4 HY3  MET A   0     115.500  -7.610-138.030  0.00  0.00            H  
ATOM      5 CY   MET A   0     115.500  -7.610-138.030  0.00  0.00            C  
ATOM      6 OY   MET A   0     115.500  -7.610-138.030  0.00  0.00            O  
ATOM      7 N    MET A   0     115.500  -7.610-138.030  1.00  0.00            N  
ATOM      8 HN   MET A   0     115.500  -7.610-138.030  0.00  0.00            H  
ATOM      9 CA   MET A   0     115.500  -7.610-138.030  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_0/348/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140       7.010 158.680 111.020  0.00  0.00            C  
ATOM      2 HY1  ARG A 140       7.010 158.680 111.020  0.00  0.00            H  
ATOM      3 HY2  ARG A 140       7.010 158.680 111.020  0.00  0.00            H  
ATOM      4 HY3  ARG A 140       7.010 158.680 111.020  0.00  0.00            H  
ATOM      5 CY   ARG A 140       7.010 158.680 111.020  0.00  0.00            C  
ATOM      6 OY   ARG A 140       7.010 158.680 111.020  0.00  0.00            O  
ATOM      7 N    ARG A 140       7.010 158.680 111.020  1.00  0.00            N  
ATOM      8 HN   ARG A 140       7.010 158.680 111.020  0.00  0.00            H  
ATOM      9 CA   ARG A 140       7.010 158.680 111.020  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_0/348/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0     204.940  27.560  92.320  0.00  0.00            C  
ATOM      2 HY1  MET A   0     204.940  27.560  92.320  0.00  0.00            H  
ATOM      3 HY2  MET A   0     204.940  27.560  92.320  0.00  0.00            H  
ATOM      4 HY3  MET A   0     204.940  27.560  92.320  0.00  0.00            H  
ATOM      5 CY   MET A   0     204.940  27.560  92.320  0.00  0.00            C  
ATOM      6 OY   MET A   0     204.940  27.560  92.320  0.00  0.00            O  
ATOM      7 N    MET A   0     204.940  27.560  92.320  1.00  0.00            N  
ATOM      8 HN   MET A   0     204.940  27.560  92.320  0.00  0.00            H  
ATOM      9 CA   MET A   0     204.940  27.560  92.320  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_0/413/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140      45.730 114.660-103.630  0.00  0.00            C  
ATOM      2 HY1  ARG A 140      45.730 114.660-103.630  0.00  0.00            H  
ATOM      3 HY2  ARG A 140      45.730 114.660-103.630  0.00  0.00            H  
ATOM      4 HY3  ARG A 140      45.730 114.660-103.630  0.00  0.00            H  
ATOM      5 CY   ARG A 140      45.730 114.660-103.630  0.00  0.00            C  
ATOM      6 OY   ARG A 140      45.730 114.660-103.630  0.00  0.00            O  
ATOM      7 N    ARG A 140      45.730 114.660-103.630  1.00  0.00            N  
ATOM      8 HN   ARG A 140      45.730 114.660-103.630  0.00  0.00            H  
ATOM      9 CA   ARG A 140      45.730 114.660-103.630  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_0/413/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0     131.150 -26.510 -96.150  0.00  0.00            C  
ATOM      2 HY1  MET A   0     131.150 -26.510 -96.150  0.00  0.00            H  
ATOM      3 HY2  MET A   0     131.150 -26.510 -96.150  0.00  0.00            H  
ATOM      4 HY3  MET A   0     131.150 -26.510 -96.150  0.00  0.00            H  
ATOM      5 CY   MET A   0     131.150 -26.510 -96.150  0.00  0.00            C  
ATOM      6 OY   MET A   0     131.150 -26.510 -96.150  0.00  0.00            O  
ATOM      7 N    MET A   0     131.150 -26.510 -96.150  1.00  0.00            N  
ATOM      8 HN   MET A   0     131.150 -26.510 -96.150  0.00  0.00            H  
ATOM      9 CA   MET A   0     131.150 -26.510 -96.150  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_0/320/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140     180.840 -42.240  96.420  0.00  0.00            C  
ATOM      2 HY1  ARG A 140     180.840 -42.240  96.420  0.00  0.00            H  
ATOM      3 HY2  ARG A 140     180.840 -42.240  96.420  0.00  0.00            H  
ATOM      4 HY3  ARG A 140     180.840 -42.240  96.420  0.00  0.00            H  
ATOM      5 CY   ARG A 140     180.840 -42.240  96.420  0.00  0.00            C  
ATOM      6 OY   ARG A 140     180.840 -42.240  96.420  0.00  0.00            O  
ATOM      7 N    ARG A 140     180.840 -42.240  96.420  1.00  0.00            N  
ATOM      8 HN   ARG A 140     180.840 -42.240  96.420  0.00  0.00            H  
ATOM      9 CA   ARG A 140     180.840 -42.240  96.420  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_0/320/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0     195.640  59.670-110.600  0.00  0.00            C  
ATOM      2 HY1  MET A   0     195.640  59.670-110.600  0.00  0.00            H  
ATOM      3 HY2  MET A   0     195.640  59.670-110.600  0.00  0.00            H  
ATOM      4 HY3  MET A   0     195.640  59.670-110.600  0.00  0.00            H  
ATOM      5 CY   MET A   0     195.640  59.670-110.600  0.00  0.00            C  
ATOM      6 OY   MET A   0     195.640  59.670-110.600  0.00  0.00            O  
ATOM      7 N    MET A   0     195.640  59.670-110.600  1.00  0.00            N  
ATOM      8 HN   MET A   0     195.640  59.670-110.600  0.00  0.00            H  
ATOM      9 CA   MET A   0     195.640  59.670-110.600  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_1/450/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140      36.020 -76.710-109.780  0.00  0.00            C  
ATOM      2 HY1  ARG A 140      36.020 -76.710-109.780  0.00  0.00            H  
ATOM      3 HY2  ARG A 140      36.020 -76.710-109.780  0.00  0.00            H  
ATOM      4 HY3  ARG A 140      36.020 -76.710-109.780  0.00  0.00            H  
ATOM      5 CY   ARG A 140      36.020 -76.710-109.780  0.00  0.00            C  
ATOM      6 OY   ARG A 140      36.020 -76.710-109.780  0.00  0.00            O  
ATOM      7 N    ARG A 140      36.020 -76.710-109.780  1.00  0.00            N  
ATOM      8 HN   ARG A 140      36.020 -76.710-109.780  0.00  0.00            H  
ATOM      9 CA   ARG A 140      36.020 -76.710-109.780  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_1/450/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0     300.360 -39.740 140.290  0.00  0.00            C  
ATOM      2 HY1  MET A   0     300.360 -39.740 140.290  0.00  0.00            H  
ATOM      3 HY2  MET A   0     300.360 -39.740 140.290  0.00  0.00            H  
ATOM      4 HY3  MET A   0     300.360 -39.740 140.290  0.00  0.00            H  
ATOM      5 CY   MET A   0     300.360 -39.740 140.290  0.00  0.00            C  
ATOM      6 OY   MET A   0     300.360 -39.740 140.290  0.00  0.00            O  
ATOM      7 N    MET A   0     300.360 -39.740 140.290  1.00  0.00            N  
ATOM      8 HN   MET A   0     300.360 -39.740 140.290  0.00  0.00            H  
ATOM      9 CA   MET A   0     300.360 -39.740 140.290  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_1/379/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140      32.830-100.760  97.990  0.00  0.00            C  
ATOM      2 HY1  ARG A 140      32.830-100.760  97.990  0.00  0.00            H  
ATOM      3 HY2  ARG A 140      32.830-100.760  97.990  0.00  0.00            H  
ATOM      4 HY3  ARG A 140      32.830-100.760  97.990  0.00  0.00            H  
ATOM      5 CY   ARG A 140      32.830-100.760  97.990  0.00  0.00            C  
ATOM      6 OY   ARG A 140      32.830-100.760  97.990  0.00  0.00            O  
ATOM      7 N    ARG A 140      32.830-100.760  97.990  1.00  0.00            N  
ATOM      8 HN   ARG A 140      32.830-100.760  97.990  0.00  0.00            H  
ATOM      9 CA   ARG A 140      32.830-100.760  97.990  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_1/379/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0      40.420   9.130 254.430  0.00  0.00            C  
ATOM      2 HY1  MET A   0      40.420   9.130 254.430  0.00  0.00            H  
ATOM      3 HY2  MET A   0      40.420   9.130 254.430  0.00  0.00            H  
ATOM      4 HY3  MET A   0      40.420   9.130 254.430  0.00  0.00            H  
ATOM      5 CY   MET A   0      40.420   9.130 254.430  0.00  0.00            C  
ATOM      6 OY   MET A   0      40.420   9.130 254.430  0.00  0.00            O  
ATOM      7 N    MET A   0      40.420   9.130 254.430  1.00  0.00            N  
ATOM      8 HN   MET A   0      40.420   9.130 254.430  0.00  0.00            H  
ATOM      9 CA   MET A   0      40.420   9.130 254.430  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_1/348/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140      92.600 -51.830  88.910  0.00  0.00            C  
ATOM      2 HY1  ARG A 140      92.600 -51.830  88.910  0.00  0.00            H  
ATOM      3 HY2  ARG A 140      92.600 -51.830  88.910  0.00  0.00            H  
ATOM      4 HY3  ARG A 140      92.600 -51.830  88.910  0.00  0.00            H  
ATOM      5 CY   ARG A 140      92.600 -51.830  88.910  0.00  0.00            C  
ATOM      6 OY   ARG A 140      92.600 -51.830  88.910  0.00  0.00            O  
ATOM      7 N    ARG A 140      92.600 -51.830  88.910  1.00  0.00            N  
ATOM      8 HN   ARG A 140      92.600 -51.830  88.910  0.00  0.00            H  
ATOM      9 CA   ARG A 140      92.600 -51.830  88.910  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_1/348/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0      -1.820 -48.950  94.020  0.00  0.00            C  
ATOM      2 HY1  MET A   0      -1.820 -48.950  94.020  0.00  0.00            H  
ATOM      3 HY2  MET A   0      -1.820 -48.950  94.020  0.00  0.00            H  
ATOM      4 HY3  MET A   0      -1.820 -48.950  94.020  0.00  0.00            H  
ATOM      5 CY   MET A   0      -1.820 -48.950  94.020  0.00  0.00            C  
ATOM      6 OY   MET A   0      -1.820 -48.950  94.020  0.00  0.00            O  
ATOM      7 N    MET A   0      -1.820 -48.950  94.020  1.00  0.00            N  
ATOM      8 HN   MET A   0      -1.820 -48.950  94.020  0.00  0.00            H  
ATOM      9 CA   MET A   0      -1.820 -48.950  94.020  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_1/413/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140      37.560  98.880 236.320  0.00  0.00            C  
ATOM      2 HY1  ARG A 140      37.560  98.880 236.320  0.00  0.00            H  
ATOM      3 HY2  ARG A 140      37.560  98.880 236.320  0.00  0.00            H  
ATOM      4 HY3  ARG A 140      37.560  98.880 236.320  0.00  0.00            H  
ATOM      5 CY   ARG A 140      37.560  98.880 236.320  0.00  0.00            C  
ATOM      6 OY   ARG A 140      37.560  98.880 236.320  0.00  0.00            O  
ATOM      7 N    ARG A 140      37.560  98.880 236.320  1.00  0.00            N  
ATOM      8 HN   ARG A 140      37.560  98.880 236.320  0.00  0.00            H  
ATOM      9 CA   ARG A 140      37.560  98.880 236.320  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_1/413/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0      35.810 -78.840 -40.590  0.00  0.00            C  
ATOM      2 HY1  MET A   0      35.810 -78.840 -40.590  0.00  0.00            H  
ATOM      3 HY2  MET A   0      35.810 -78.840 -40.590  0.00  0.00            H  
ATOM      4 HY3  MET A   0      35.810 -78.840 -40.590  0.00  0.00            H  
ATOM      5 CY   MET A   0      35.810 -78.840 -40.590  0.00  0.00            C  
ATOM      6 OY   MET A   0      35.810 -78.840 -40.590  0.00  0.00            O  
ATOM      7 N    MET A   0      35.810 -78.840 -40.590  1.00  0.00            N  
ATOM      8 HN   MET A   0      35.810 -78.840 -40.590  0.00  0.00            H  
ATOM      9 CA   MET A   0      35.810 -78.840 -40.590  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_1/320/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140     -33.380 139.920 -25.280  0.00  0.00            C  
ATOM      2 HY1  ARG A 140     -33.380 139.920 -25.280  0.00  0.00            H  
ATOM      3 HY2  ARG A 140     -33.380 139.920 -25.280  0.00  0.00            H  
ATOM      4 HY3  ARG A 140     -33.380 139.920 -25.280  0.00  0.00            H  
ATOM      5 CY   ARG A 140     -33.380 139.920 -25.280  0.00  0.00            C  
ATOM      6 OY   ARG A 140     -33.380 139.920 -25.280  0.00  0.00            O  
ATOM      7 N    ARG A 140     -33.380 139.920 -25.280  1.00  0.00            N  
ATOM      8 HN   ARG A 140     -33.380 139.920 -25.280  0.00  0.00            H  
ATOM      9 CA   ARG A 140     -33.380 139.920 -25.280  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_1/320/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0      35.600  56.340 -21.860  0.00  0.00            C  
ATOM      2 HY1  MET A   0      35.600  56.340 -21.860  0.00  0.00            H  
ATOM      3 HY2  MET A   0      35.600  56.340 -21.860  0.00  0.00            H  
ATOM      4 HY3  MET A   0      35.600  56.340 -21.860  0.00  0.00            H  
ATOM      5 CY   MET A   0      35.600  56.340 -21.860  0.00  0.00            C  
ATOM      6 OY   MET A   0      35.600  56.340 -21.860  0.00  0.00            O  
ATOM      7 N    MET A   0      35.600  56.340 -21.860  1.00  0.00            N  
ATOM      8 HN   MET A   0      35.600  56.340 -21.860  0.00  0.00            H  
ATOM      9 CA   MET A   0      35.600  56.340 -21.860  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_3/450/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140     -31.150 226.830   2.110  0.00  0.00            C  
ATOM      2 HY1  ARG A 140     -31.150 226.830   2.110  0.00  0.00            H  
ATOM      3 HY2  ARG A 140     -31.150 226.830   2.110  0.00  0.00            H  
ATOM      4 HY3  ARG A 140     -31.150 226.830   2.110  0.00  0.00            H  
ATOM      5 CY   ARG A 140     -31.150 226.830   2.110  0.00  0.00            C  
ATOM      6 OY   ARG A 140     -31.150 226.830   2.110  0.00  0.00            O  
ATOM      7 N    ARG A 140     -31.150 226.830   2.110  1.00  0.00            N  
ATOM      8 HN   ARG A 140     -31.150 226.830   2.110  0.00  0.00            H  
ATOM      9 CA   ARG A 140     -31.150 226.830   2.110  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_3/450/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0      59.180 112.900  98.670  0.00  0.00            C  
ATOM      2 HY1  MET A   0      59.180 112.900  98.670  0.00  0.00            H  
ATOM      3 HY2  MET A   0      59.180 112.900  98.670  0.00  0.00            H  
ATOM      4 HY3  MET A   0      59.180 112.900  98.670  0.00  0.00            H  
ATOM      5 CY   MET A   0      59.180 112.900  98.670  0.00  0.00            C  
ATOM      6 OY   MET A   0      59.180 112.900  98.670  0.00  0.00            O  
ATOM      7 N    MET A   0      59.180 112.900  98.670  1.00  0.00            N  
ATOM      8 HN   MET A   0      59.180 112.900  98.670  0.00  0.00            H  
ATOM      9 CA   MET A   0      59.180 112.900  98.670  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_3/379/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140     -15.060  74.050  87.110  0.00  0.00            C  
ATOM      2 HY1  ARG A 140     -15.060  74.050  87.110  0.00  0.00            H  
ATOM      3 HY2  ARG A 140     -15.060  74.050  87.110  0.00  0.00            H  
ATOM      4 HY3  ARG A 140     -15.060  74.050  87.110  0.00  0.00            H  
ATOM      5 CY   ARG A 140     -15.060  74.050  87.110  0.00  0.00            C  
ATOM      6 OY   ARG A 140     -15.060  74.050  87.110  0.00  0.00            O  
ATOM      7 N    ARG A 140     -15.060  74.050  87.110  1.00  0.00            N  
ATOM      8 HN   ARG A 140     -15.060  74.050  87.110  0.00  0.00            H  
ATOM      9 CA   ARG A 140     -15.060  74.050  87.110  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_3/379/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0     282.160  11.220-202.430  0.00  0.00            C  
ATOM      2 HY1  MET A   0     282.160  11.220-202.430  0.00  0.00            H  
ATOM      3 HY2  MET A   0     282.160  11.220-202.430  0.00  0.00            H  
ATOM      4 HY3  MET A   0     282.160  11.220-202.430  0.00  0.00            H  
ATOM      5 CY   MET A   0     282.160  11.220-202.430  0.00  0.00            C  
ATOM      6 OY   MET A   0     282.160  11.220-202.430  0.00  0.00            O  
ATOM      7 N    MET A   0     282.160  11.220-202.430  1.00  0.00            N  
ATOM      8 HN   MET A   0     282.160  11.220-202.430  0.00  0.00            H  
ATOM      9 CA   MET A   0     282.160  11.220-202.430  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_3/348/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140     150.710  13.520  48.820  0.00  0.00            C  
ATOM      2 HY1  ARG A 140     150.710  13.520  48.820  0.00  0.00            H  
ATOM      3 HY2  ARG A 140     150.710  13.520  48.820  0.00  0.00            H  
ATOM      4 HY3  ARG A 140     150.710  13.520  48.820  0.00  0.00            H  
ATOM      5 CY   ARG A 140     150.710  13.520  48.820  0.00  0.00            C  
ATOM      6 OY   ARG A 140     150.710  13.520  48.820  0.00  0.00            O  
ATOM      7 N    ARG A 140     150.710  13.520  48.820  1.00  0.00            N  
ATOM      8 HN   ARG A 140     150.710  13.520  48.820  0.00  0.00            H  
ATOM      9 CA   ARG A 140     150.710  13.520  48.820  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_3/348/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0      55.400-148.450  42.270  0.00  0.00            C  
ATOM      2 HY1  MET A   0      55.400-148.450  42.270  0.00  0.00            H  
ATOM      3 HY2  MET A   0      55.400-148.450  42.270  0.00  0.00            H  
ATOM      4 HY3  MET A   0      55.400-148.450  42.270  0.00  0.00            H  
ATOM      5 CY   MET A   0      55.400-148.450  42.270  0.00  0.00            C  
ATOM      6 OY   MET A   0      55.400-148.450  42.270  0.00  0.00            O  
ATOM      7 N    MET A   0      55.400-148.450  42.270  1.00  0.00            N  
ATOM      8 HN   MET A   0      55.400-148.450  42.270  0.00  0.00            H  
ATOM      9 CA   MET A   0      55.400-148.450  42.270  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_3/413/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140     -60.170-126.820 224.170  0.00  0.00            C  
ATOM      2 HY1  ARG A 140     -60.170-126.820 224.170  0.00  0.00            H  
ATOM      3 HY2  ARG A 140     -60.170-126.820 224.170  0.00  0.00            H  
ATOM      4 HY3  ARG A 140     -60.170-126.820 224.170  0.00  0.00            H  
ATOM      5 CY   ARG A 140     -60.170-126.820 224.170  0.00  0.00            C  
ATOM      6 OY   ARG A 140     -60.170-126.820 224.170  0.00  0.00            O  
ATOM      7 N    ARG A 140     -60.170-126.820 224.170  1.00  0.00            N  
ATOM      8 HN   ARG A 140     -60.170-126.820 224.170  0.00  0.00            H  
ATOM      9 CA   ARG A 140     -60.170-126.820 224.170  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_3/413/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0     510.430 -78.580 -88.660  0.00  0.00            C  
ATOM      2 HY1  MET A   0     510.430 -78.580 -88.660  0.00  0.00            H  
ATOM      3 HY2  MET A   0     510.430 -78.580 -88.660  0.00  0.00            H  
ATOM      4 HY3  MET A   0     510.430 -78.580 -88.660  0.00  0.00            H  
ATOM      5 CY   MET A   0     510.430 -78.580 -88.660  0.00  0.00            C  
ATOM      6 OY   MET A   0     510.430 -78.580 -88.660  0.00  0.00            O  
ATOM      7 N    MET A   0     510.430 -78.580 -88.660  1.00  0.00            N  
ATOM      8 HN   MET A   0     510.430 -78.580 -88.660  0.00  0.00            H  
ATOM      9 CA   MET A   0     510.430 -78.580 -88.660  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_3/320/1a02F00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    ARG A 140     -14.750 194.240 -36.580  0.00  0.00            C  
ATOM      2 HY1  ARG A 140     -14.750 194.240 -36.580  0.00  0.00            H  
ATOM      3 HY2  ARG A 140     -14.750 194.240 -36.580  0.00  0.00            H  
ATOM      4 HY3  ARG A 140     -14.750 194.240 -36.580  0.00  0.00            H  
ATOM      5 CY   ARG A 140     -14.750 194.240 -36.580  0.00  0.00            C  
ATOM      6 OY   ARG A 140     -14.750 194.240 -36.580  0.00  0.00            O  
ATOM      7 N    ARG A 140     -14.750 194.240 -36.580  1.00  0.00            N  
ATOM      8 HN   ARG A 140     -14.750 194.240 -36.580  0.00  0.00            H  
ATOM      9 CA   ARG A 140     -14.750 194.240 -36.580  1.00  0.00            C  

===== FILE: ./outputs/frames/replica_3/320/1a0aA00_frame.pdb =====
CRYST1  100.000  100.000  100.000  90.00  90.00  90.00 P 1           1
ATOM      1 N    MET A   0       1.320  70.200 131.660  0.00  0.00            C  
ATOM      2 HY1  MET A   0       1.320  70.200 131.660  0.00  0.00            H  
ATOM      3 HY2  MET A   0       1.320  70.200 131.660  0.00  0.00            H  
ATOM      4 HY3  MET A   0       1.320  70.200 131.660  0.00  0.00            H  
ATOM      5 CY   MET A   0       1.320  70.200 131.660  0.00  0.00            C  
ATOM      6 OY   MET A   0       1.320  70.200 131.660  0.00  0.00            O  
ATOM      7 N    MET A   0       1.320  70.200 131.660  1.00  0.00            N  
ATOM      8 HN   MET A   0       1.320  70.200 131.660  0.00  0.00            H  
ATOM      9 CA   MET A   0       1.320  70.200 131.660  1.00  0.00            C  

===== FILE: ./src/mdcath.egg-info/SOURCES.txt =====
LICENSE
README.md
setup.py
src/mdcath/__init__.py
src/mdcath.egg-info/PKG-INFO
src/mdcath.egg-info/SOURCES.txt
src/mdcath.egg-info/dependency_links.txt
src/mdcath.egg-info/requires.txt
src/mdcath.egg-info/top_level.txt
src/mdcath/config/__init__.py

===== FILE: ./src/mdcath.egg-info/top_level.txt =====
mdcath

===== FILE: ./src/mdcath.egg-info/requires.txt =====
h5py
numpy
pandas
biopython
pyyaml
matplotlib
seaborn
tqdm

===== FILE: ./src/mdcath.egg-info/PKG-INFO =====
Metadata-Version: 2.2
Name: mdcath
Version: 0.1.0
Summary: Process mdCATH dataset for ML applications
Author: Biochemistry Team
Author-email: info@example.com
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3

===== FILE: ./src/mdcath/processing/core_exterior.py =====
#!/usr/bin/env python3
"""
Processing module for core/exterior classification.
"""

import os
import logging
import subprocess
import tempfile
import pandas as pd

===== FILE: ./src/mdcath/processing/voxelizer.py =====
#!/usr/bin/env python3
"""
Processing module for voxelizing protein structures using aposteriori.
"""

import os
import logging
import subprocess
import traceback
import sys

===== FILE: ./src/mdcath/processing/__init__.py =====
"""
Data processing modules for mdCATH
"""

===== FILE: ./src/mdcath/processing/rmsf.py =====
#!/usr/bin/env python3
"""
Processing module for RMSF data extraction and averaging.
"""

import os
import logging
import numpy as np
import pandas as pd
from typing import List, Dict, Optional, Any, Union

===== FILE: ./src/mdcath/processing/pdb.py =====
#!/usr/bin/env python3
"""
Processing module for PDB data extraction and cleaning.
"""

import os
import logging
import numpy as np
from typing import Dict, Any, Optional, List, Tuple
from concurrent.futures import ProcessPoolExecutor, as_completed

===== FILE: ./src/mdcath/processing/features.py =====


#!/usr/bin/env python3
"""
Processing module for generating ML features.
"""

import os
import logging
import shutil  # <-- Added to fix "name 'shutil' is not defined" DSSP fallback error

===== FILE: ./src/mdcath/processing/visualization.py =====
#!/usr/bin/env python3
"""
Module for generating visualizations of processed mdCATH data.
"""

import os
import logging
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

===== FILE: ./src/mdcath/config/default_config.yaml =====
input:
  mdcath_folder: "/mnt/datasets/MD_CATH/data"  # Path to the mdCATH folder
  domain_ids: ["1a02F00", "1a0aA00"]   # Empty means process default domain (12asA00)

temperatures: [320, 348, 379, 413, 450]
num_replicas: 5  # Number of replicas to process per temperature

output:
  base_dir: "./outputs"


===== FILE: ./src/mdcath/config/__init__.py =====
"""
Configuration handling for mdCATH
"""

===== FILE: ./src/mdcath/__init__.py =====
"""
mdCATH - A package for processing mdCATH dataset for ML applications
"""

__version__ = '0.1.0'

===== FILE: ./src/mdcath/core/data_loader.py =====


#!/usr/bin/env python3
"""
Core functionality for loading and processing H5 data from mdCATH dataset.
"""

import os
import h5py
import logging

===== FILE: ./src/mdcath/core/__init__.py =====
"""
Core data loading and processing functions
"""

===== FILE: ./check_environment.py =====
#!/usr/bin/env python3
"""
Check environment setup for mdCATH processing.
"""

import os
import sys
import subprocess
import shutil
from colorama import init, Fore, Style

===== FILE: ./test_h5_loading.py =====
#!/usr/bin/env python3
"""
inspect_hdf5.py

Enhanced script to inspect and compare the contents of mdCATH .h5 files.
"""

import os
import sys
import h5py

===== FILE: ./README.md =====
# mdCATH Dataset Processing Project for RMSF Prediction

## Overview

This project provides a comprehensive data processing pipeline for the mdCATH protein dynamics dataset. It extracts, transforms, and organizes the data into formats optimized for training machine learning models that predict Root Mean Square Fluctuation (RMSF) from protein structure information.

The resulting datasets enable the development of ML architectures that can accurately predict protein dynamics from structural features.

## Features


===== FILE: ./requirements.txt =====
h5py>=3.1.0
numpy>=1.19.0
pandas>=1.1.0
biopython>=1.78
pyyaml>=5.4.0
matplotlib>=3.3.0
seaborn>=0.11.0
tqdm>=4.50.0
pdbUtils
# Install aposteriori separately via pip

===== FILE: ./main.py =====
#!/usr/bin/env python3
"""
Main entry point for mdCATH dataset processing.
"""

import os
import sys
import logging
import argparse
import yaml

